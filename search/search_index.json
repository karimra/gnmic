{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"gnmic (pronoun.: gee\u00b7en\u00b7em\u00b7eye\u00b7see) is a gNMI CLI client that provides full support for Capabilities, Get, Set and Subscribe RPCs with collector capabilities. Features # Full support for gNMI RPCs Every gNMI RPC has a corresponding command with all of the RPC options configurable by means of the local and global flags. Flexible collector deployment gnmic can be deployed as a gNMI collector that supports multiple output types ( NATS , Kafka , Prometheus , InfluxDB ,...). The collector can be deployed either as a single instance , as part of a cluster , or used to form data pipelines . gNMI data manipulation gnmic collector supports data transformation capabilities that can be used to adapt the collected data to your specific use case. Dynamic targets loading gnmic support target loading at runtime based on input from external systems. YANG-based path suggestions Your CLI magically becomes a YANG browser when gnmic is executed in prompt mode. In this mode the flags that take XPATH values will get auto-suggestions based on the provided YANG modules. In other words - voodoo magic Multiple configuration sources gnmic supports flags , environment variables as well as file based configurations. Multi-target operations Commands can operate on multiple gNMI targets for bulk configuration/retrieval/subscription. Multiple subscriptions With file based configuration it is possible to define and configure multiple subscriptions which can be independently associated with gNMI targets. Inspect gNMI messages With the textproto output format and the logging capabilities of gnmic you can see the actual gNMI messages being sent/received. Its like having a gNMI looking glass! Configurable TLS enforcement gNMI client supports both TLS and non-TLS transports so you can start using it in a lab environment without having to care about the PKI. Dial-out telemetry The dial-out telemetry server is provided for Nokia SR OS. Pre-built multi-platform binaries Statically linked binaries made in our release pipeline are available for major operating systems and architectures. Making installation a breeze! Extensive and friendly documentation You won't be in need to dive into the source code to understand how gnimc works, our documentation site has you covered. Quick start guide # Installation # bash -c \"$(curl -sL https://get-gnmic.kmrd.dev)\" Capabilities request # gnmic -a 10.1.0.11:57400 -u admin -p admin --insecure capabilities Get request # gnmic -a 10.1.0.11:57400 -u admin -p admin --insecure \\ get --path /state/system/platform Set request # gnmic -a 10.1.0.11:57400 -u admin -p admin --insecure \\ set --update-path /configure/system/name \\ --update-value gnmic_demo Subscribe request # gnmic -a 10.1.0.11:57400 -u admin -p admin --insecure \\ sub --path \"/state/port[port-id=1/1/c1/1]/statistics/in-packets\"","title":"Home"},{"location":"#features","text":"Full support for gNMI RPCs Every gNMI RPC has a corresponding command with all of the RPC options configurable by means of the local and global flags. Flexible collector deployment gnmic can be deployed as a gNMI collector that supports multiple output types ( NATS , Kafka , Prometheus , InfluxDB ,...). The collector can be deployed either as a single instance , as part of a cluster , or used to form data pipelines . gNMI data manipulation gnmic collector supports data transformation capabilities that can be used to adapt the collected data to your specific use case. Dynamic targets loading gnmic support target loading at runtime based on input from external systems. YANG-based path suggestions Your CLI magically becomes a YANG browser when gnmic is executed in prompt mode. In this mode the flags that take XPATH values will get auto-suggestions based on the provided YANG modules. In other words - voodoo magic Multiple configuration sources gnmic supports flags , environment variables as well as file based configurations. Multi-target operations Commands can operate on multiple gNMI targets for bulk configuration/retrieval/subscription. Multiple subscriptions With file based configuration it is possible to define and configure multiple subscriptions which can be independently associated with gNMI targets. Inspect gNMI messages With the textproto output format and the logging capabilities of gnmic you can see the actual gNMI messages being sent/received. Its like having a gNMI looking glass! Configurable TLS enforcement gNMI client supports both TLS and non-TLS transports so you can start using it in a lab environment without having to care about the PKI. Dial-out telemetry The dial-out telemetry server is provided for Nokia SR OS. Pre-built multi-platform binaries Statically linked binaries made in our release pipeline are available for major operating systems and architectures. Making installation a breeze! Extensive and friendly documentation You won't be in need to dive into the source code to understand how gnimc works, our documentation site has you covered.","title":"Features"},{"location":"#quick-start-guide","text":"","title":"Quick start guide"},{"location":"#installation","text":"bash -c \"$(curl -sL https://get-gnmic.kmrd.dev)\"","title":"Installation"},{"location":"#capabilities-request","text":"gnmic -a 10.1.0.11:57400 -u admin -p admin --insecure capabilities","title":"Capabilities request"},{"location":"#get-request","text":"gnmic -a 10.1.0.11:57400 -u admin -p admin --insecure \\ get --path /state/system/platform","title":"Get request"},{"location":"#set-request","text":"gnmic -a 10.1.0.11:57400 -u admin -p admin --insecure \\ set --update-path /configure/system/name \\ --update-value gnmic_demo","title":"Set request"},{"location":"#subscribe-request","text":"gnmic -a 10.1.0.11:57400 -u admin -p admin --insecure \\ sub --path \"/state/port[port-id=1/1/c1/1]/statistics/in-packets\"","title":"Subscribe request"},{"location":"basic_usage/","text":"The following examples demonstrate the basic usage of the gnmic in a scenario where the remote target runs insecure (not TLS enabled) gNMI server. The admin:admin credentials are used to connect to the gNMI server running at 10.1.0.11:57400 address. Info For the complete command usage examples, refer to the \"Command reference\" menu. Capabilities RPC # Getting the device's capabilities is done with capabilities command: gnmic -a 10 .1.0.11:57400 -u admin -p admin --insecure capabilities gNMI_Version: 0 .7.0 supported models: - nokia-conf, Nokia, 19 .10.R2 - nokia-state, Nokia, 19 .10.R2 - nokia-li-state, Nokia, 19 .10.R2 - nokia-li-conf, Nokia, 19 .10.R2 << SNIPPED >> supported encodings: - JS ON - BYTES Get RPC # Retrieving the data snapshot from the target device is done with get command: gnmic -a 10 .1.0.11:57400 -u admin -p admin --insecure \\ get --path /state/system/platform { \"source\" : \"10.1.0.11:57400\" , \"timestamp\" : 1592829586901061761 , \"time\" : \"2020-06-22T14:39:46.901061761+02:00\" , \"updates\" : [ { \"Path\" : \"state/system/platform\" , \"values\" : { \"state/system/platform\" : \"7750 SR-1s\" } } ] } Set RPC # Modifying state of the target device is done with set command: gnmic -a 10 .1.0.11:57400 -u admin -p admin --insecure \\ set --update-path /configure/system/name \\ --update-value gnmic_demo { \"source\" : \"0.tcp.eu.ngrok.io:12267\" , \"timestamp\" : 1592831593821038738 , \"time\" : \"2020-06-22T15:13:13.821038738+02:00\" , \"results\" : [ { \"operation\" : \"UPDATE\" , \"path\" : \"configure/system/name\" } ] } Subscribe RPC # Subscription to the gNMI telemetry data can be done with subscribe command: gnmic -a 10 .1.0.11:57400 -u admin -p admin --insecure \\ sub --path \"/state/port[port-id=1/1/c1/1]/statistics/in-packets\" { \"source\" : \"0.tcp.eu.ngrok.io:12267\" , \"timestamp\" : 1592832965197288856 , \"time\" : \"2020-06-22T15:36:05.197288856+02:00\" , \"prefix\" : \"state/port[port-id=1/1/c1/1]/statistics\" , \"updates\" : [ { \"Path\" : \"in-packets\" , \"values\" : { \"in-packets\" : \"12142\" } } ] } YANG path browser # gnmic can produce a list of XPATH/gNMI paths for a given YANG model with its path command. The paths in that list can be used as the --path values for the Get/Set/Subscribe commands. # nokia model gnmic path -m nokia-state --file nokia-state-combined.yang | head -10 /state/aaa/radius/statistics/coa/dropped/bad-authentication /state/aaa/radius/statistics/coa/dropped/missing-auth-policy /state/aaa/radius/statistics/coa/dropped/invalid /state/aaa/radius/statistics/coa/dropped/missing-resource /state/aaa/radius/statistics/coa/received /state/aaa/radius/statistics/coa/accepted /state/aaa/radius/statistics/coa/rejected /state/aaa/radius/statistics/disconnect-messages/dropped/bad-authentication /state/aaa/radius/statistics/disconnect-messages/dropped/missing-auth-policy /state/aaa/radius/statistics/disconnect-messages/dropped/invalid","title":"Basic usage"},{"location":"basic_usage/#capabilities-rpc","text":"Getting the device's capabilities is done with capabilities command: gnmic -a 10 .1.0.11:57400 -u admin -p admin --insecure capabilities gNMI_Version: 0 .7.0 supported models: - nokia-conf, Nokia, 19 .10.R2 - nokia-state, Nokia, 19 .10.R2 - nokia-li-state, Nokia, 19 .10.R2 - nokia-li-conf, Nokia, 19 .10.R2 << SNIPPED >> supported encodings: - JS ON - BYTES","title":"Capabilities RPC"},{"location":"basic_usage/#get-rpc","text":"Retrieving the data snapshot from the target device is done with get command: gnmic -a 10 .1.0.11:57400 -u admin -p admin --insecure \\ get --path /state/system/platform { \"source\" : \"10.1.0.11:57400\" , \"timestamp\" : 1592829586901061761 , \"time\" : \"2020-06-22T14:39:46.901061761+02:00\" , \"updates\" : [ { \"Path\" : \"state/system/platform\" , \"values\" : { \"state/system/platform\" : \"7750 SR-1s\" } } ] }","title":"Get RPC"},{"location":"basic_usage/#set-rpc","text":"Modifying state of the target device is done with set command: gnmic -a 10 .1.0.11:57400 -u admin -p admin --insecure \\ set --update-path /configure/system/name \\ --update-value gnmic_demo { \"source\" : \"0.tcp.eu.ngrok.io:12267\" , \"timestamp\" : 1592831593821038738 , \"time\" : \"2020-06-22T15:13:13.821038738+02:00\" , \"results\" : [ { \"operation\" : \"UPDATE\" , \"path\" : \"configure/system/name\" } ] }","title":"Set RPC"},{"location":"basic_usage/#subscribe-rpc","text":"Subscription to the gNMI telemetry data can be done with subscribe command: gnmic -a 10 .1.0.11:57400 -u admin -p admin --insecure \\ sub --path \"/state/port[port-id=1/1/c1/1]/statistics/in-packets\" { \"source\" : \"0.tcp.eu.ngrok.io:12267\" , \"timestamp\" : 1592832965197288856 , \"time\" : \"2020-06-22T15:36:05.197288856+02:00\" , \"prefix\" : \"state/port[port-id=1/1/c1/1]/statistics\" , \"updates\" : [ { \"Path\" : \"in-packets\" , \"values\" : { \"in-packets\" : \"12142\" } } ] }","title":"Subscribe RPC"},{"location":"basic_usage/#yang-path-browser","text":"gnmic can produce a list of XPATH/gNMI paths for a given YANG model with its path command. The paths in that list can be used as the --path values for the Get/Set/Subscribe commands. # nokia model gnmic path -m nokia-state --file nokia-state-combined.yang | head -10 /state/aaa/radius/statistics/coa/dropped/bad-authentication /state/aaa/radius/statistics/coa/dropped/missing-auth-policy /state/aaa/radius/statistics/coa/dropped/invalid /state/aaa/radius/statistics/coa/dropped/missing-resource /state/aaa/radius/statistics/coa/received /state/aaa/radius/statistics/coa/accepted /state/aaa/radius/statistics/coa/rejected /state/aaa/radius/statistics/disconnect-messages/dropped/bad-authentication /state/aaa/radius/statistics/disconnect-messages/dropped/missing-auth-policy /state/aaa/radius/statistics/disconnect-messages/dropped/invalid","title":"YANG path browser"},{"location":"changelog/","text":"Changelog # v0.26.0 - June 28 th 2022 # Outputs Add Prometheus Remote Write output , this output type can be used to push metrics to various systems like Mimir , CortexMetrics , VictoriaMetrics , Thanos ... Add NATS Jetstream output , it allows to write metrics to NATS jetstream which supports persistency and filtering. gNMI historical subscriptions gNMIc now support historical subscription using the gNMI history extension v0.25.1 - June 13 th 2022 # Upgrade Go version to go1.18.1. Fix running gnmic subscribe with only Inputs and Outputs configured (no subscriptions or targets). v0.25.0 - June 11 th 2022 # Processors Strings replace processor supports replaces using regular expressions. Processors are now supported when collecting telemetry using listen command (Nokia SROS specific) New Processors Data convert Duration convert Value tag Clustering gNMIc supports kubernetes based clustering, i.e you can build gNMIc clusters on kubernetes without the need for Consul cluster. Yang path generation The command gnmic generate path supports generating paths for YANG containers. In earlier versions, the paths generation was done for YANG leaves only. Internal gNMIc Prometheus metrics gNMIc exposes additional internal metrics available to be scraped using Prometheus. Static tags from target configuration It is now possible to set static tags on events by configuring them under each target. Influxdb cache The InfluxDB output now supports gNMI based caching, allowing to apply processors on multiple event messages at once and batching the written points to InfluxDB. v0.24.0 - March 13 th 2022 # gRPC Tunnel Support Add support for gNMI RPC using a gRPC tunnel, gNMIc runs as a collector with an embedded tunnel server. v0.23.0 - February 24 th 2022 # Docker image: The published gnmic docker image is now based on alpine instead of an empty container. A from scratch image is published and can be obtained using the command: docker pull ghcr.io/karimra/gnmic:latest-scratch docker pull ghcr.io/karimra/gnmic:v0.23.0-scratch gNMIc Golang API : Add gNMI responses constructors Add gRPC tunnel proto messages constructors Target Discovery : Add the option to transform the loaded targets format using a Go text template for file and HTTP loaders Poll based target loaders (file, HTTP and docker) now support a startup delay timer v0.22.1 - February 2 nd 2022 # Fix a Prometheus output issue when using gNMI cache that causes events to be missing from the metrics. v0.22.0 - February 1 st 2022 # gNMIc Golang API : Added the github.com/karimra/gnmic/api golang package. It can be imported by other Golang programs to ease the creation of gNMI targets and gNMI Requests. v0.21.0 - January 23 rd 2022 # Generate Cmd : Add YANG module namespace to generated paths. Outputs: Outputs File , NATS and Kafka now support a msg-template field to customize the written messages using Go templates. API: Add Cluster API endpoints. Actions: Add Template action. Add Subscribe ONCE RPC to gNMI action. Allow gNMI action on multiple targets. Add Script action. Get Cmd : Implement Format event for GetResponse messages. Add the ability to execute processors with Get command flag --processor on GetResponse messages. Target Discovery : Add the ability to run actions on target discovery or deletion. Set Cmd : Add --dry-run flag which runs the set request templates and prints their output without sending the SetRequest to the targets. TLS: Add pre-master key logging for TLS connections using the flag --log-tls-secret . The key can be used to decrypt encrypted gNMI messages using wireshark. Target: Add target.Stop() method to gracefully close the target underlying gRPC connection. v0.20.0 - October 19 th 2021 # Add gomplate template functions to all templates rendered by gnmic . Path generation : gnmic generate path supports generating paths with type and description in JSON format. Set RPC template : Set RPC supports multiple template files in a single command. Clustering : gnmic clusters can be formed using secure (HTTPS) API endpoints. Configuration payload generation : Configuration keys can now be formatted as camelCase or snake_case strings v0.19.1 - October 7 th 2021 # Path search Do not enter search mode if not paths are found. Prometheus Output Change the default service name when registering with a Consul server v0.19.0 - September 16 th 2021 # Event Processors Event Convert now converts binary float notation to float Target Loaders: HTTP Loader gNMIc can now dynamically discover targets from a remote HTTP server. HTTP Loader is now properly instrumented using Prometheus metrics. File Loader Supports remote files (ftp, sftp, http(s)) in addition to local file system files. File loader is now properly instrumented using Prometheus metrics. Consul Loader Consul Loader is now properly instrumented using Prometheus metrics. Docker Loader Docker Loader is now properly instrumented using Prometheus metrics. gRPC gNMIc now adds its version as part of the user-agent HTTP header. v0.18.0 - August 17 th 2021 # gNMI Server : Add support for a global gNMI server. It supports all types of subscriptions, ran against a local cache build out the configured subscriptions. It support Get and Set RPCs as well, those are run against the configured targets. The gNMI server supports Consul based service registration. Outputs: Add support for gNMI server output type Target configuration : Support multiple IP addresses per target, all addresses are tried simultaneously. The first successful gRPC connection is used. Prometheus Output : Add the option of generating Prometheus metrics on-scrape, instead of on-reception. The gNMI notifications are stored in a local cache and used to generate metrics when a Prometheus server sends a scrape request. Event Processors: Add group-by processor, it groups events together based on a given criteria. The events can belong to different gNMI notifications or even to different subscriptions. Event Processor Convert: Add support for boolean conversion Deployment Examples : Add containerlab based deployment examples. These deployment come with a router fabric built using Nokia's SRL API server : Add Secure API server configuration options Target Loaders: Consul loader update: Add support for gNMI target discovery from Consul services. Get Request: Add printing of Target as part of Path Prefix Set Request: Add printing of Target as part of Path Prefix v0.17.0 - July 14 th 2021 # Event Trigger: Enhance event-trigger to run multiple actions sequentially when an event occurs. The output of an action can be used in the following ones. Kafka output: Add SASL_SSL and SSL security protocols to kafka output. gRPC authentication: Add support for token based gRPC authentication. v0.16.2 - July 13 th 2021 # Fix nil pointer dereference in case a subscription has suppress-redundant but no heartbeat-interval . v0.16.1 - July 12 th 2021 # Bump github.com/openconfig/goyang version to v0.2.7 v0.16.0 - June 14 th 2021 # Target Discovery: Add Docker Engine target loader, gnmic can dynamically discover gNMI targets running as docker containers. Event Trigger: gNMI action Enhance gNMI action to take external variables as input, in addition to the received gNMI update. v0.15.0 - June 7 th 2021 # Subscription: Add field set-target under subscription config, a boolean that enables setting the target name as a gNMI prefix target. Outputs: Add add-target and target-template fields under all outputs, Enables adding the target value as a tag/label based on the subscription and target metadata v0.14.3 - June 6 th 2021 # Set command: Fix ascii values encoding if used with --request-file flag. v0.14.2 - June 3 rd 2021 # Fix event-convert processor when the conversion is between integer types. Add an implicit conversion of uint to int if the influxdb output version is 1.8.x. This is a workaround for the limited support of influx APIv2 by influxDB1.8 v0.14.1 - May 31 st 2021 # Fix OverrideTS processor Add override-timestamps option under outputs, to override the message timestamps regardless of the message output format v0.14.0 - May 28 th 2021 # New Output format flat This format prints the Get and Subscribe RPCs as a list of xpath: value , where the xpath points to a leaf value. New gnmic diff command: This command prints the difference in responses between a reference target --ref and one or more targets to be compared to the reference --compare . The output is printed as flat format results. v0.13.0 - May 10 th 2021 # New gnmic generate Command: Given a set of yang models and an xpath, gnmic generate generates a JSON/YAML representation of the YANG object the given path points to. Given a set of yang models and an set of xpaths (with --update or --replace ), gnmic generate set-request generates a set request file that can be filled with the desired values and used with gnmic set --request-file The sub-command gnmic generate path is an alias to gnmic path Path Command: add flag --desc which, if present, prints the YANG leaf description together with the generated paths. add flag --config-only which, if present, only generates paths pointing to YANG leaves representing config data. add flag --state-only which, if present, only generates paths pointing to a YANG leaf representing state data. v0.12.2 - April 24 th 2021 # Fix a bug that cause gNMIc to crash if certain processors are used. v0.12.1 - April 21 st 2021 # Fix parsing of stringArray flags containing a space. v0.12.0 - April 20 th 2021 # Outputs: InfluxDB and Prometheus outputs: Convert gNMI Decimal64 values to Float64. Set Command: Add the ability to run a Set command using a single file, including replaces , updates and deletes . The request file --request-file is either a static file or a Golang Text Template rendered separately for each target. The template input is read from a file referenced by the flag --request-vars . v0.11.0 - April 15 th 2021 # Processors: Add event-allow processor, basically an allow ACL based on jq condition or regular expressions. Add event-extract-tags processor, it adds tags based on regex named groups from tag names, tag values, value names, or values. Add gnmi-action to event-trigger processor, the action runs a gNMI Set or Get if the trigger condition is met. Set Command: Improve usability by supporting reading values (--update-file and --replace-file) from standard input. v0.10.0 - April 8 th 2021 # New command: getset command: This command conditionally executes both a Get and a Set RPC, the GetResponse is used to evaluate a condition which if met triggers the execution of the Set RPC. Processors: Some processors' apply condition can be expressed using jq instead of regular expressions. v0.9.1 - March 23 rd 2021 # Processors: Add event-trigger processor: This processor is used to trigger a predefined action if a condition is met. New processor event-jq which applies a transformation on the messages expressed as a jq expression. Shell autocompletion: Shell (bash, zsh and fish) autocompletion scripts can be generated using gnmic completion [bash|zsh|fish] . gRPC gzip compression: gnmic supports gzip compression on gRPC connections. v0.9.0 - March 11 th 2021 # Clustered Prometheus output: When deployed as a cluster, it is possible to register only one of the prometheus outputs in Consul. This is handy in the case of a cluster with data replication. Proto file loading at runtime (Nokia SROS): gnmic supports loading SROS proto files at runtime to decode gNMI updates with proto encoding Kafka Output: Kafka SASL support: PLAIN, SCRAM SHA256/SHA512 OAuth mechanisms are supported. Configuration: gnmic supports configuration using environment variables. Processors: add event-merge processor. Target Loaders: gnmic supports target loaders at runtime, new targets can be added to the configuration from a file that gnmic watches or from Consul v0.8.0 - March 2 nd 2021 # Inputs: Processors can now be applied by the input plugins. Prometheus output: The Prometheus output can now register as a service in Consul, a Prometheus client can discover the output using consul service discovery. Clustering: gnmic can now run as a cluster, this requires a running Consul instance that will be used by the gnmic instance for leader election and target load sharing. Configuration file: The default configuration file placement now follows XDG recommendations CLI exit status: Failure of most commands is properly reflected in the cli exit status. Configuration: Configuration fields that are OS paths are expanded by gnmic Deployment examples: A set of deployment examples is added to the repo and the docs. v0.7.0 - January 28 th 2021 # Prometheus output metrics customization: metric-prefix and append-subscription-name can be used to change the default metric prefix and append the subscription name to the metric name. export-timestamps : enables/disables the export of timestamps together with the metric. strings-as-labels : enables/disables automatically adding paths with a value of type string as a metric label. NATS output: allow multiple NATS workers under NATS output via field num-workers . add NATS prometheus internal metrics. STAN output: allow multiple STAN workers under STAN output via field num-workers . add NATS prometheus internal metrics. File output: add File prometheus metrics. Inputs: support ingesting gNMI data from NATS, STAN or a Kafka message bus. v0.6.0 - December 14 th 2020 # Processors: Added processors to gnmic , a set of basic processors can be used to manipulate gNMI data flowing through gnmic . These processors are applied by the output plugins Upgrade command: gnmic can be upgraded using gnmic version upgrade command. v0.5.2 - December 1 st 2020 # Outputs: Improve outputs logging Add Prometheus metrics to Kafka output v0.5.1 - November 28 th 2020 # Prompt Mode: Fix subscribe RPC behavior QoS: Do not populate QoS field if not set via config file or flag. Outputs: add configurable number of workers to some outputs. v0.5.0 - November 25 th 2020 # Prompt Mode: Add prompt sub commands. XPATH parsing: Add custom xpath parsingto gnmi.Path to allow for paths including column : . TLS: Allow configurable TLS versions per target, the minimum, the maximum and the preferred TLS versions ca be configured. v0.4.3 - November 10 th 2020 # Missing path: Initialize the path field if not present in SubscribeResponse v0.4.2 - November 5 th 2020 # YANG: Prompt command flags --file and --dir support globs. Subscribe: added flags --output that allows to choose a single output for subscribe updates Prompt: Max suggestions is automatically adjusted based on the terminal height. Add suggestions for address and subscriptions. v0.4.1 - October 22 nd 2020 # Prompt: Add suggestions of xpath with origin, --suggest-with-origin . v0.4.0 - October 21 st 2020 # New Command: Add new command prompt Prompt: Add ctrl+z key bind to delete a single path element. Add YANG info to xpath suggestions. Add GoLeft, GoRight key binds. Sort xpaths and prefixes suggestions. xpaths suggestions are properly generated if a prefix is present. flag --suggest-all-flags allows adding global flags suggestion in prompt mode. Prometheus output: Add support for Prometheus output plugin. v0.3.0 - October 1 st 2020 # InfluxDB output: Add support for influxDB output plugin. v0.2.3 - September 18 th 2020 # Retry Add basic RPC retry mechanism. ONCE mode subscription: Handle targets that send an EOF error instead of a SyncResponse to signify the end of ONCE subscriptions. Docker image: Docker images added to ghcr.io as well as docker hub. v0.2.2 - September 3 rd 2020 # CLI: Properly handle paths that include quotes. Unix Socket: Allow send/rcv of gNMI data to/from a unix socket. Outputs: Add TCP output plugin. v0.2.1 - August 11 th 2020 # Releases: Add .deb. and .rpm packages to releases. Outputs: Add UDP output plugin. v0.2.0 - August 7 th 2020 # Releases: Add ARM releases. Push docker image to docker hub. v0.1.1 - July 23 rd 2020 # Set Cmd: Support json_ietf encoding when the value is specified from a file. v0.1.0 - July 16 th 2020 # Outputs: Allow NATS/STAN output subject customization. v0.0.7 - July 16 th 2020 # gNMI Target: Add support for gNMI Target field. gNMI Origin: Add support for gNMI Origin field. Prometheus internal metrics: Add support for gnmic internal metrics via a Prometheus server. Outputs: Add support for multiple output plugins (file, NATS, STAN, Kafka) Targets: Support target specific configuration. Poll Subscription: Allow selecting polled targets and subscription using a CLI select menu. gNMI Models: Support multiple Models in Get and Subscribe RPCs. v0.0.6 - June 2 nd 2020 # Nokia Dialout: Add Support for Nokia Dialout telemetry. Printing: Convert timestamps to Time. v0.0.5 - May 18 th 2020 # Formatting: Add textproto format. v0.0.4 - May 11 th 2020 # Logging: Support logging to file instead of Stderr. Set Command: support Set values from YAML file. v0.0.3 - April 23 rd 2020 # Proxy: Allow usage of ENV proxy values for gRPC connections. Installation: Add installation script. v0.0.2 - April 13 th 2020 # Terminal printing clean up. Path Command: Add search option. v0.0.1 - March 24 th 2020 # Capabilities RPC Command. Get RPC Command. Subscribe RPC Command. Set RPC Command. TLS support. Version Command. Path Commnd. initial Commit - February 20 th 2020 #","title":"Changelog"},{"location":"changelog/#changelog","text":"","title":"Changelog"},{"location":"changelog/#v0260-june-28th-2022","text":"Outputs Add Prometheus Remote Write output , this output type can be used to push metrics to various systems like Mimir , CortexMetrics , VictoriaMetrics , Thanos ... Add NATS Jetstream output , it allows to write metrics to NATS jetstream which supports persistency and filtering. gNMI historical subscriptions gNMIc now support historical subscription using the gNMI history extension","title":"v0.26.0 - June 28th 2022"},{"location":"changelog/#v0251-june-13th-2022","text":"Upgrade Go version to go1.18.1. Fix running gnmic subscribe with only Inputs and Outputs configured (no subscriptions or targets).","title":"v0.25.1 - June 13th 2022"},{"location":"changelog/#v0250-june-11th-2022","text":"Processors Strings replace processor supports replaces using regular expressions. Processors are now supported when collecting telemetry using listen command (Nokia SROS specific) New Processors Data convert Duration convert Value tag Clustering gNMIc supports kubernetes based clustering, i.e you can build gNMIc clusters on kubernetes without the need for Consul cluster. Yang path generation The command gnmic generate path supports generating paths for YANG containers. In earlier versions, the paths generation was done for YANG leaves only. Internal gNMIc Prometheus metrics gNMIc exposes additional internal metrics available to be scraped using Prometheus. Static tags from target configuration It is now possible to set static tags on events by configuring them under each target. Influxdb cache The InfluxDB output now supports gNMI based caching, allowing to apply processors on multiple event messages at once and batching the written points to InfluxDB.","title":"v0.25.0 - June 11th 2022"},{"location":"changelog/#v0240-march-13th-2022","text":"gRPC Tunnel Support Add support for gNMI RPC using a gRPC tunnel, gNMIc runs as a collector with an embedded tunnel server.","title":"v0.24.0 - March 13th 2022"},{"location":"changelog/#v0230-february-24th-2022","text":"Docker image: The published gnmic docker image is now based on alpine instead of an empty container. A from scratch image is published and can be obtained using the command: docker pull ghcr.io/karimra/gnmic:latest-scratch docker pull ghcr.io/karimra/gnmic:v0.23.0-scratch gNMIc Golang API : Add gNMI responses constructors Add gRPC tunnel proto messages constructors Target Discovery : Add the option to transform the loaded targets format using a Go text template for file and HTTP loaders Poll based target loaders (file, HTTP and docker) now support a startup delay timer","title":"v0.23.0 - February 24th 2022"},{"location":"changelog/#v0221-february-2nd-2022","text":"Fix a Prometheus output issue when using gNMI cache that causes events to be missing from the metrics.","title":"v0.22.1 - February 2nd 2022"},{"location":"changelog/#v0220-february-1st-2022","text":"gNMIc Golang API : Added the github.com/karimra/gnmic/api golang package. It can be imported by other Golang programs to ease the creation of gNMI targets and gNMI Requests.","title":"v0.22.0 - February 1st 2022"},{"location":"changelog/#v0210-january-23rd-2022","text":"Generate Cmd : Add YANG module namespace to generated paths. Outputs: Outputs File , NATS and Kafka now support a msg-template field to customize the written messages using Go templates. API: Add Cluster API endpoints. Actions: Add Template action. Add Subscribe ONCE RPC to gNMI action. Allow gNMI action on multiple targets. Add Script action. Get Cmd : Implement Format event for GetResponse messages. Add the ability to execute processors with Get command flag --processor on GetResponse messages. Target Discovery : Add the ability to run actions on target discovery or deletion. Set Cmd : Add --dry-run flag which runs the set request templates and prints their output without sending the SetRequest to the targets. TLS: Add pre-master key logging for TLS connections using the flag --log-tls-secret . The key can be used to decrypt encrypted gNMI messages using wireshark. Target: Add target.Stop() method to gracefully close the target underlying gRPC connection.","title":"v0.21.0 - January 23rd 2022"},{"location":"changelog/#v0200-october-19th-2021","text":"Add gomplate template functions to all templates rendered by gnmic . Path generation : gnmic generate path supports generating paths with type and description in JSON format. Set RPC template : Set RPC supports multiple template files in a single command. Clustering : gnmic clusters can be formed using secure (HTTPS) API endpoints. Configuration payload generation : Configuration keys can now be formatted as camelCase or snake_case strings","title":"v0.20.0 - October 19th 2021"},{"location":"changelog/#v0191-october-7th-2021","text":"Path search Do not enter search mode if not paths are found. Prometheus Output Change the default service name when registering with a Consul server","title":"v0.19.1 - October 7th 2021"},{"location":"changelog/#v0190-september-16th-2021","text":"Event Processors Event Convert now converts binary float notation to float Target Loaders: HTTP Loader gNMIc can now dynamically discover targets from a remote HTTP server. HTTP Loader is now properly instrumented using Prometheus metrics. File Loader Supports remote files (ftp, sftp, http(s)) in addition to local file system files. File loader is now properly instrumented using Prometheus metrics. Consul Loader Consul Loader is now properly instrumented using Prometheus metrics. Docker Loader Docker Loader is now properly instrumented using Prometheus metrics. gRPC gNMIc now adds its version as part of the user-agent HTTP header.","title":"v0.19.0 - September 16th 2021"},{"location":"changelog/#v0180-august-17th-2021","text":"gNMI Server : Add support for a global gNMI server. It supports all types of subscriptions, ran against a local cache build out the configured subscriptions. It support Get and Set RPCs as well, those are run against the configured targets. The gNMI server supports Consul based service registration. Outputs: Add support for gNMI server output type Target configuration : Support multiple IP addresses per target, all addresses are tried simultaneously. The first successful gRPC connection is used. Prometheus Output : Add the option of generating Prometheus metrics on-scrape, instead of on-reception. The gNMI notifications are stored in a local cache and used to generate metrics when a Prometheus server sends a scrape request. Event Processors: Add group-by processor, it groups events together based on a given criteria. The events can belong to different gNMI notifications or even to different subscriptions. Event Processor Convert: Add support for boolean conversion Deployment Examples : Add containerlab based deployment examples. These deployment come with a router fabric built using Nokia's SRL API server : Add Secure API server configuration options Target Loaders: Consul loader update: Add support for gNMI target discovery from Consul services. Get Request: Add printing of Target as part of Path Prefix Set Request: Add printing of Target as part of Path Prefix","title":"v0.18.0 - August 17th 2021"},{"location":"changelog/#v0170-july-14th-2021","text":"Event Trigger: Enhance event-trigger to run multiple actions sequentially when an event occurs. The output of an action can be used in the following ones. Kafka output: Add SASL_SSL and SSL security protocols to kafka output. gRPC authentication: Add support for token based gRPC authentication.","title":"v0.17.0 - July 14th 2021"},{"location":"changelog/#v0162-july-13th-2021","text":"Fix nil pointer dereference in case a subscription has suppress-redundant but no heartbeat-interval .","title":"v0.16.2 - July 13th 2021"},{"location":"changelog/#v0161-july-12th-2021","text":"Bump github.com/openconfig/goyang version to v0.2.7","title":"v0.16.1 - July 12th 2021"},{"location":"changelog/#v0160-june-14th-2021","text":"Target Discovery: Add Docker Engine target loader, gnmic can dynamically discover gNMI targets running as docker containers. Event Trigger: gNMI action Enhance gNMI action to take external variables as input, in addition to the received gNMI update.","title":"v0.16.0 - June 14th 2021"},{"location":"changelog/#v0150-june-7th-2021","text":"Subscription: Add field set-target under subscription config, a boolean that enables setting the target name as a gNMI prefix target. Outputs: Add add-target and target-template fields under all outputs, Enables adding the target value as a tag/label based on the subscription and target metadata","title":"v0.15.0 - June 7th 2021"},{"location":"changelog/#v0143-june-6th-2021","text":"Set command: Fix ascii values encoding if used with --request-file flag.","title":"v0.14.3 - June 6th 2021"},{"location":"changelog/#v0142-june-3rd-2021","text":"Fix event-convert processor when the conversion is between integer types. Add an implicit conversion of uint to int if the influxdb output version is 1.8.x. This is a workaround for the limited support of influx APIv2 by influxDB1.8","title":"v0.14.2 - June 3rd 2021"},{"location":"changelog/#v0141-may-31st-2021","text":"Fix OverrideTS processor Add override-timestamps option under outputs, to override the message timestamps regardless of the message output format","title":"v0.14.1 - May 31st 2021"},{"location":"changelog/#v0140-may-28th-2021","text":"New Output format flat This format prints the Get and Subscribe RPCs as a list of xpath: value , where the xpath points to a leaf value. New gnmic diff command: This command prints the difference in responses between a reference target --ref and one or more targets to be compared to the reference --compare . The output is printed as flat format results.","title":"v0.14.0 - May 28th 2021"},{"location":"changelog/#v0130-may-10th-2021","text":"New gnmic generate Command: Given a set of yang models and an xpath, gnmic generate generates a JSON/YAML representation of the YANG object the given path points to. Given a set of yang models and an set of xpaths (with --update or --replace ), gnmic generate set-request generates a set request file that can be filled with the desired values and used with gnmic set --request-file The sub-command gnmic generate path is an alias to gnmic path Path Command: add flag --desc which, if present, prints the YANG leaf description together with the generated paths. add flag --config-only which, if present, only generates paths pointing to YANG leaves representing config data. add flag --state-only which, if present, only generates paths pointing to a YANG leaf representing state data.","title":"v0.13.0 - May 10th 2021"},{"location":"changelog/#v0122-april-24th-2021","text":"Fix a bug that cause gNMIc to crash if certain processors are used.","title":"v0.12.2 - April 24th 2021"},{"location":"changelog/#v0121-april-21st-2021","text":"Fix parsing of stringArray flags containing a space.","title":"v0.12.1 - April 21st 2021"},{"location":"changelog/#v0120-april-20th-2021","text":"Outputs: InfluxDB and Prometheus outputs: Convert gNMI Decimal64 values to Float64. Set Command: Add the ability to run a Set command using a single file, including replaces , updates and deletes . The request file --request-file is either a static file or a Golang Text Template rendered separately for each target. The template input is read from a file referenced by the flag --request-vars .","title":"v0.12.0 - April 20th 2021"},{"location":"changelog/#v0110-april-15th-2021","text":"Processors: Add event-allow processor, basically an allow ACL based on jq condition or regular expressions. Add event-extract-tags processor, it adds tags based on regex named groups from tag names, tag values, value names, or values. Add gnmi-action to event-trigger processor, the action runs a gNMI Set or Get if the trigger condition is met. Set Command: Improve usability by supporting reading values (--update-file and --replace-file) from standard input.","title":"v0.11.0 - April 15th 2021"},{"location":"changelog/#v0100-april-8th-2021","text":"New command: getset command: This command conditionally executes both a Get and a Set RPC, the GetResponse is used to evaluate a condition which if met triggers the execution of the Set RPC. Processors: Some processors' apply condition can be expressed using jq instead of regular expressions.","title":"v0.10.0 - April 8th 2021"},{"location":"changelog/#v091-march-23rd-2021","text":"Processors: Add event-trigger processor: This processor is used to trigger a predefined action if a condition is met. New processor event-jq which applies a transformation on the messages expressed as a jq expression. Shell autocompletion: Shell (bash, zsh and fish) autocompletion scripts can be generated using gnmic completion [bash|zsh|fish] . gRPC gzip compression: gnmic supports gzip compression on gRPC connections.","title":"v0.9.1 - March 23rd 2021"},{"location":"changelog/#v090-march-11th-2021","text":"Clustered Prometheus output: When deployed as a cluster, it is possible to register only one of the prometheus outputs in Consul. This is handy in the case of a cluster with data replication. Proto file loading at runtime (Nokia SROS): gnmic supports loading SROS proto files at runtime to decode gNMI updates with proto encoding Kafka Output: Kafka SASL support: PLAIN, SCRAM SHA256/SHA512 OAuth mechanisms are supported. Configuration: gnmic supports configuration using environment variables. Processors: add event-merge processor. Target Loaders: gnmic supports target loaders at runtime, new targets can be added to the configuration from a file that gnmic watches or from Consul","title":"v0.9.0 - March 11th 2021"},{"location":"changelog/#v080-march-2nd-2021","text":"Inputs: Processors can now be applied by the input plugins. Prometheus output: The Prometheus output can now register as a service in Consul, a Prometheus client can discover the output using consul service discovery. Clustering: gnmic can now run as a cluster, this requires a running Consul instance that will be used by the gnmic instance for leader election and target load sharing. Configuration file: The default configuration file placement now follows XDG recommendations CLI exit status: Failure of most commands is properly reflected in the cli exit status. Configuration: Configuration fields that are OS paths are expanded by gnmic Deployment examples: A set of deployment examples is added to the repo and the docs.","title":"v0.8.0 - March 2nd 2021"},{"location":"changelog/#v070-january-28th-2021","text":"Prometheus output metrics customization: metric-prefix and append-subscription-name can be used to change the default metric prefix and append the subscription name to the metric name. export-timestamps : enables/disables the export of timestamps together with the metric. strings-as-labels : enables/disables automatically adding paths with a value of type string as a metric label. NATS output: allow multiple NATS workers under NATS output via field num-workers . add NATS prometheus internal metrics. STAN output: allow multiple STAN workers under STAN output via field num-workers . add NATS prometheus internal metrics. File output: add File prometheus metrics. Inputs: support ingesting gNMI data from NATS, STAN or a Kafka message bus.","title":"v0.7.0 - January 28th 2021"},{"location":"changelog/#v060-december-14th-2020","text":"Processors: Added processors to gnmic , a set of basic processors can be used to manipulate gNMI data flowing through gnmic . These processors are applied by the output plugins Upgrade command: gnmic can be upgraded using gnmic version upgrade command.","title":"v0.6.0 - December 14th 2020"},{"location":"changelog/#v052-december-1st-2020","text":"Outputs: Improve outputs logging Add Prometheus metrics to Kafka output","title":"v0.5.2 - December 1st 2020"},{"location":"changelog/#v051-november-28th-2020","text":"Prompt Mode: Fix subscribe RPC behavior QoS: Do not populate QoS field if not set via config file or flag. Outputs: add configurable number of workers to some outputs.","title":"v0.5.1 - November 28th 2020"},{"location":"changelog/#v050-november-25th-2020","text":"Prompt Mode: Add prompt sub commands. XPATH parsing: Add custom xpath parsingto gnmi.Path to allow for paths including column : . TLS: Allow configurable TLS versions per target, the minimum, the maximum and the preferred TLS versions ca be configured.","title":"v0.5.0 - November 25th 2020"},{"location":"changelog/#v043-november-10th-2020","text":"Missing path: Initialize the path field if not present in SubscribeResponse","title":"v0.4.3 - November 10th 2020"},{"location":"changelog/#v042-november-5th-2020","text":"YANG: Prompt command flags --file and --dir support globs. Subscribe: added flags --output that allows to choose a single output for subscribe updates Prompt: Max suggestions is automatically adjusted based on the terminal height. Add suggestions for address and subscriptions.","title":"v0.4.2 - November 5th 2020"},{"location":"changelog/#v041-october-22nd-2020","text":"Prompt: Add suggestions of xpath with origin, --suggest-with-origin .","title":"v0.4.1 - October 22nd 2020"},{"location":"changelog/#v040-october-21st-2020","text":"New Command: Add new command prompt Prompt: Add ctrl+z key bind to delete a single path element. Add YANG info to xpath suggestions. Add GoLeft, GoRight key binds. Sort xpaths and prefixes suggestions. xpaths suggestions are properly generated if a prefix is present. flag --suggest-all-flags allows adding global flags suggestion in prompt mode. Prometheus output: Add support for Prometheus output plugin.","title":"v0.4.0 - October 21st 2020"},{"location":"changelog/#v030-october-1st-2020","text":"InfluxDB output: Add support for influxDB output plugin.","title":"v0.3.0 - October 1st 2020"},{"location":"changelog/#v023-september-18th-2020","text":"Retry Add basic RPC retry mechanism. ONCE mode subscription: Handle targets that send an EOF error instead of a SyncResponse to signify the end of ONCE subscriptions. Docker image: Docker images added to ghcr.io as well as docker hub.","title":"v0.2.3 - September 18th 2020"},{"location":"changelog/#v022-september-3rd-2020","text":"CLI: Properly handle paths that include quotes. Unix Socket: Allow send/rcv of gNMI data to/from a unix socket. Outputs: Add TCP output plugin.","title":"v0.2.2 - September 3rd 2020"},{"location":"changelog/#v021-august-11th-2020","text":"Releases: Add .deb. and .rpm packages to releases. Outputs: Add UDP output plugin.","title":"v0.2.1 - August 11th 2020"},{"location":"changelog/#v020-august-7th-2020","text":"Releases: Add ARM releases. Push docker image to docker hub.","title":"v0.2.0 - August 7th 2020"},{"location":"changelog/#v011-july-23rd-2020","text":"Set Cmd: Support json_ietf encoding when the value is specified from a file.","title":"v0.1.1 - July 23rd 2020"},{"location":"changelog/#v010-july-16th-2020","text":"Outputs: Allow NATS/STAN output subject customization.","title":"v0.1.0 - July 16th 2020"},{"location":"changelog/#v007-july-16th-2020","text":"gNMI Target: Add support for gNMI Target field. gNMI Origin: Add support for gNMI Origin field. Prometheus internal metrics: Add support for gnmic internal metrics via a Prometheus server. Outputs: Add support for multiple output plugins (file, NATS, STAN, Kafka) Targets: Support target specific configuration. Poll Subscription: Allow selecting polled targets and subscription using a CLI select menu. gNMI Models: Support multiple Models in Get and Subscribe RPCs.","title":"v0.0.7 - July 16th 2020"},{"location":"changelog/#v006-june-2nd-2020","text":"Nokia Dialout: Add Support for Nokia Dialout telemetry. Printing: Convert timestamps to Time.","title":"v0.0.6 - June 2nd 2020"},{"location":"changelog/#v005-may-18th-2020","text":"Formatting: Add textproto format.","title":"v0.0.5 - May 18th 2020"},{"location":"changelog/#v004-may-11th-2020","text":"Logging: Support logging to file instead of Stderr. Set Command: support Set values from YAML file.","title":"v0.0.4 - May 11th 2020"},{"location":"changelog/#v003-april-23rd-2020","text":"Proxy: Allow usage of ENV proxy values for gRPC connections. Installation: Add installation script.","title":"v0.0.3 - April 23rd 2020"},{"location":"changelog/#v002-april-13th-2020","text":"Terminal printing clean up. Path Command: Add search option.","title":"v0.0.2 - April 13th 2020"},{"location":"changelog/#v001-march-24th-2020","text":"Capabilities RPC Command. Get RPC Command. Subscribe RPC Command. Set RPC Command. TLS support. Version Command. Path Commnd.","title":"v0.0.1 - March 24th 2020"},{"location":"changelog/#initial-commit-february-20th-2020","text":"","title":"initial Commit - February 20th 2020"},{"location":"global_flags/","text":"address # The address flag [-a | --address] is used to specify the target's gNMI server address in address:port format, for e.g: 192.168.113.11:57400 Multiple target addresses can be specified, either as comma separated values: gnmic --address 192 .168.113.11:57400,192.168.113.12:57400 or by using the --address flag multiple times: gnmic -a 192 .168.113.11:57400 --address 192 .168.113.12:57400 cluster-name # The [--cluster-name] flag is used to specify the cluster name the gnmic instance will join. The cluster name is used as part of the locked keys to share targets between multiple gnmic instances. Defaults to default-cluster config # The --config flag specifies the location of a configuration file that gnmic will read. If not specified, gnmic searches for a file named .gnmic with extensions yaml, yml, toml or json in the following locations: $PWD $HOME $XDG_CONFIG_HOME $XDG_CONFIG_HOME/gnmic debug # The debug flag [-d | --debug] enables the printing of extra information when sending/receiving an RPC dir # A path to a directory which gnmic would recursively traverse in search for the additional YANG files which may be required by YANG files specified with --file to build the YANG tree. Can also point to a single YANG file instead of a directory. Multiple --dir flags can be supplied. encoding # The encoding flag [-e | --encoding] is used to specify the gNMI encoding of the Update part of a Notification message. It is case insensitive and must be one of: JSON, BYTES, PROTO, ASCII, JSON_IETF exclude # The --exclude flag specifies the YANG module names to be excluded from the tree generation when YANG modules names clash. Multiple --exclude flags can be supplied. file # A path to a YANG file or a directory with YANG files which gnmic will use with prompt, generate and path commands. Multiple --file flags can be supplied. format # Five output formats can be configured by means of the --format flag. [proto, protojson, prototext, json, event] The default format is json . The proto format outputs the gnmi message as raw bytes, this value is not allowed when the output type is file (file system, stdout or stderr) see outputs The prototext and protojson formats are the message representation as defined in prototext and protojson The event format emits the received gNMI SubscribeResponse updates and deletes as a list of events tagged with the keys present in the subscribe path (as well as some metadata) and a timestamp Here goes an example of the same response emitted to stdout in the respective formats: protojson { \"update\" : { \"timestamp\" : \"1595584408456503938\" , \"prefix\" : { \"elem\" : [ { \"name\" : \"state\" }, { \"name\" : \"system\" }, { \"name\" : \"version\" } ] }, \"update\" : [ { \"path\" : { \"elem\" : [ { \"name\" : \"version-string\" } ] }, \"val\" : { \"stringVal\" : \"TiMOS-B-20.5.R1 both/x86_64 Nokia 7750 SR Copyright (c) 2000-2020 Nokia.\\r\\nAll rights reserved. All use subject to applicable license agreements.\\r\\nBuilt on Wed May 13 14:08:50 PDT 2020 by builder in /builds/c/205B/R1/panos/main/sros\" } } ] } } prototext update : { timestamp : 1595584168675434221 prefix : { elem : { name : \"state\" } elem : { name : \"system\" } elem : { name : \"version\" } } update : { path : { elem : { name : \"version-string\" } } val : { string_val : \"TiMOS-B-20.5.R1 both/x86_64 Nokia 7750 SR Copyright (c) 2000-2020 Nokia.\\r\\nAll rights reserved. All use subject to applicable license agreements.\\r\\nBuilt on Wed May 13 14:08:50 PDT 2020 by builder in /builds/c/205B/R1/panos/main/sros\" } } } json { \"source\" : \"172.17.0.100:57400\" , \"subscription-name\" : \"default\" , \"timestamp\" : 1595584326775141151 , \"time\" : \"2020-07-24T17:52:06.775141151+08:00\" , \"prefix\" : \"state/system/version\" , \"updates\" : [ { \"Path\" : \"version-string\" , \"values\" : { \"version-string\" : \"TiMOS-B-20.5.R1 both/x86_64 Nokia 7750 SR Copyright (c) 2000-2020 Nokia.\\r\\nAll rights reserved. All use subject to applicable license agreements.\\r\\nBuilt on Wed May 13 14:08:50 PDT 2020 by builder in /builds/c/205B/R1/panos/main/sros\" } } ] } event [ { \"name\" : \"default\" , \"timestamp\" : 1595584587725708234 , \"tags\" : { \"source\" : \"172.17.0.100:57400\" , \"subscription-name\" : \"default\" }, \"values\" : { \"/state/system/version/version-string\" : \"TiMOS-B-20.5.R1 both/x86_64 Nokia 7750 SR Copyright (c) 2000-2020 Nokia.\\r\\nAll rights reserved. All use subject to applicable license agreements.\\r\\nBuilt on Wed May 13 14:08:50 PDT 2020 by builder in /builds/c/205B/R1/panos/main/sros\" } } ] gzip # The [--gzip] flag enables gRPC gzip compression. insecure # The insecure flag [--insecure] is used to indicate that the client wishes to establish an non-TLS enabled gRPC connection. To disable certificate validation in a TLS-enabled connection use skip-verify flag. instance-name # The [--instance-name] flag is used to give a unique name to the running gnmic instance. This is useful when there are multiple instances of gnmic running at the same time, either for high-availability and/or scalability log # The --log flag enables log messages to appear on stderr output. By default logging is disabled. log-file # The log-file flag [--log-file <path>] sets the log output to a file referenced by the path. This flag supersede the --log flag no-prefix # The no prefix flag [--no-prefix] disables prefixing the json formatted responses with [ip:port] string. Note that in case a single target is specified, the prefix is not added. password # The password flag [-p | --password] is used to specify the target password as part of the user credentials. If omitted, the password input prompt is used to provide the password. Note that in case multiple targets are used, all should use the same credentials. proto-dir # The [--proto-dir] flag is used to specify a list of directories where gnmic will search for the proto file names specified with --proto-file . proto-file # The [--proto-file] flag is used to specify a list of proto file names that gnmic will use to decode ProtoBytes values. only Nokia SROS proto is currently supported. proxy-from-env # The proxy-from-env flag [--proxy-from-env] indicates that the gnmic should use the HTTP/HTTPS proxy addresses defined in the environment variables http_proxy and https_proxy to reach the targets specified using the --address flag. retry # The retry flag `[--retry] specifies the wait time before each retry. Valid formats: 10s, 1m30s, 1h. Defaults to 10s skip-verify # The skip verify flag [--skip-verify] indicates that the target should skip the signature verification steps, in case a secure connection is used. targets-file # The [--targets-file] flag is used to configure a file target loader timeout # The timeout flag [--timeout] specifies the gRPC timeout after which the connection attempt fails. Valid formats: 10s, 1m30s, 1h. Defaults to 10s tls-ca # The TLS CA flag [--tls-ca] specifies the root certificates for verifying server certificates encoded in PEM format. tls-cert # The tls cert flag [--tls-cert] specifies the public key for the client encoded in PEM format. tls-key # The tls key flag [--tls-key] specifies the private key for the client encoded in PEM format. tls-max-version # The tls max version flag [--tls-max-version] specifies the maximum supported TLS version supported by gNMIc when creating a secure gRPC connection. tls-min-version # The tls min version flag [--tls-min-version] specifies the minimum supported TLS version supported by gNMIc when creating a secure gRPC connection. tls-version # The tls version flag [--tls-version] specifies a single supported TLS version gNMIc when creating a secure gRPC connection. This flag overwrites the previously listed flags --tls-max-version and --tls-min-version . log-tls-secret # The log TLS secret flag [--log-tls-secret] makes gnmic to log the per-session pre-master secret so that it can be used to decrypt TLS secured gNMI communications with, for example, Wireshark. The secret will be saved to a file named <target-name>.tlssecret.log . token # The token flag [--token] sets a token value to be added to each RPC as an Authorization Bearer Token. Applied only in the case of a secure gRPC connection. username # The username flag [-u | --username] is used to specify the target username as part of the user credentials. If omitted, the input prompt is used to provide the username.","title":"Global flags"},{"location":"global_flags/#address","text":"The address flag [-a | --address] is used to specify the target's gNMI server address in address:port format, for e.g: 192.168.113.11:57400 Multiple target addresses can be specified, either as comma separated values: gnmic --address 192 .168.113.11:57400,192.168.113.12:57400 or by using the --address flag multiple times: gnmic -a 192 .168.113.11:57400 --address 192 .168.113.12:57400","title":"address"},{"location":"global_flags/#cluster-name","text":"The [--cluster-name] flag is used to specify the cluster name the gnmic instance will join. The cluster name is used as part of the locked keys to share targets between multiple gnmic instances. Defaults to default-cluster","title":"cluster-name"},{"location":"global_flags/#config","text":"The --config flag specifies the location of a configuration file that gnmic will read. If not specified, gnmic searches for a file named .gnmic with extensions yaml, yml, toml or json in the following locations: $PWD $HOME $XDG_CONFIG_HOME $XDG_CONFIG_HOME/gnmic","title":"config"},{"location":"global_flags/#debug","text":"The debug flag [-d | --debug] enables the printing of extra information when sending/receiving an RPC","title":"debug"},{"location":"global_flags/#dir","text":"A path to a directory which gnmic would recursively traverse in search for the additional YANG files which may be required by YANG files specified with --file to build the YANG tree. Can also point to a single YANG file instead of a directory. Multiple --dir flags can be supplied.","title":"dir"},{"location":"global_flags/#encoding","text":"The encoding flag [-e | --encoding] is used to specify the gNMI encoding of the Update part of a Notification message. It is case insensitive and must be one of: JSON, BYTES, PROTO, ASCII, JSON_IETF","title":"encoding"},{"location":"global_flags/#exclude","text":"The --exclude flag specifies the YANG module names to be excluded from the tree generation when YANG modules names clash. Multiple --exclude flags can be supplied.","title":"exclude"},{"location":"global_flags/#file","text":"A path to a YANG file or a directory with YANG files which gnmic will use with prompt, generate and path commands. Multiple --file flags can be supplied.","title":"file"},{"location":"global_flags/#format","text":"Five output formats can be configured by means of the --format flag. [proto, protojson, prototext, json, event] The default format is json . The proto format outputs the gnmi message as raw bytes, this value is not allowed when the output type is file (file system, stdout or stderr) see outputs The prototext and protojson formats are the message representation as defined in prototext and protojson The event format emits the received gNMI SubscribeResponse updates and deletes as a list of events tagged with the keys present in the subscribe path (as well as some metadata) and a timestamp Here goes an example of the same response emitted to stdout in the respective formats: protojson { \"update\" : { \"timestamp\" : \"1595584408456503938\" , \"prefix\" : { \"elem\" : [ { \"name\" : \"state\" }, { \"name\" : \"system\" }, { \"name\" : \"version\" } ] }, \"update\" : [ { \"path\" : { \"elem\" : [ { \"name\" : \"version-string\" } ] }, \"val\" : { \"stringVal\" : \"TiMOS-B-20.5.R1 both/x86_64 Nokia 7750 SR Copyright (c) 2000-2020 Nokia.\\r\\nAll rights reserved. All use subject to applicable license agreements.\\r\\nBuilt on Wed May 13 14:08:50 PDT 2020 by builder in /builds/c/205B/R1/panos/main/sros\" } } ] } } prototext update : { timestamp : 1595584168675434221 prefix : { elem : { name : \"state\" } elem : { name : \"system\" } elem : { name : \"version\" } } update : { path : { elem : { name : \"version-string\" } } val : { string_val : \"TiMOS-B-20.5.R1 both/x86_64 Nokia 7750 SR Copyright (c) 2000-2020 Nokia.\\r\\nAll rights reserved. All use subject to applicable license agreements.\\r\\nBuilt on Wed May 13 14:08:50 PDT 2020 by builder in /builds/c/205B/R1/panos/main/sros\" } } } json { \"source\" : \"172.17.0.100:57400\" , \"subscription-name\" : \"default\" , \"timestamp\" : 1595584326775141151 , \"time\" : \"2020-07-24T17:52:06.775141151+08:00\" , \"prefix\" : \"state/system/version\" , \"updates\" : [ { \"Path\" : \"version-string\" , \"values\" : { \"version-string\" : \"TiMOS-B-20.5.R1 both/x86_64 Nokia 7750 SR Copyright (c) 2000-2020 Nokia.\\r\\nAll rights reserved. All use subject to applicable license agreements.\\r\\nBuilt on Wed May 13 14:08:50 PDT 2020 by builder in /builds/c/205B/R1/panos/main/sros\" } } ] } event [ { \"name\" : \"default\" , \"timestamp\" : 1595584587725708234 , \"tags\" : { \"source\" : \"172.17.0.100:57400\" , \"subscription-name\" : \"default\" }, \"values\" : { \"/state/system/version/version-string\" : \"TiMOS-B-20.5.R1 both/x86_64 Nokia 7750 SR Copyright (c) 2000-2020 Nokia.\\r\\nAll rights reserved. All use subject to applicable license agreements.\\r\\nBuilt on Wed May 13 14:08:50 PDT 2020 by builder in /builds/c/205B/R1/panos/main/sros\" } } ]","title":"format"},{"location":"global_flags/#gzip","text":"The [--gzip] flag enables gRPC gzip compression.","title":"gzip"},{"location":"global_flags/#insecure","text":"The insecure flag [--insecure] is used to indicate that the client wishes to establish an non-TLS enabled gRPC connection. To disable certificate validation in a TLS-enabled connection use skip-verify flag.","title":"insecure"},{"location":"global_flags/#instance-name","text":"The [--instance-name] flag is used to give a unique name to the running gnmic instance. This is useful when there are multiple instances of gnmic running at the same time, either for high-availability and/or scalability","title":"instance-name"},{"location":"global_flags/#log","text":"The --log flag enables log messages to appear on stderr output. By default logging is disabled.","title":"log"},{"location":"global_flags/#log-file","text":"The log-file flag [--log-file <path>] sets the log output to a file referenced by the path. This flag supersede the --log flag","title":"log-file"},{"location":"global_flags/#no-prefix","text":"The no prefix flag [--no-prefix] disables prefixing the json formatted responses with [ip:port] string. Note that in case a single target is specified, the prefix is not added.","title":"no-prefix"},{"location":"global_flags/#password","text":"The password flag [-p | --password] is used to specify the target password as part of the user credentials. If omitted, the password input prompt is used to provide the password. Note that in case multiple targets are used, all should use the same credentials.","title":"password"},{"location":"global_flags/#proto-dir","text":"The [--proto-dir] flag is used to specify a list of directories where gnmic will search for the proto file names specified with --proto-file .","title":"proto-dir"},{"location":"global_flags/#proto-file","text":"The [--proto-file] flag is used to specify a list of proto file names that gnmic will use to decode ProtoBytes values. only Nokia SROS proto is currently supported.","title":"proto-file"},{"location":"global_flags/#proxy-from-env","text":"The proxy-from-env flag [--proxy-from-env] indicates that the gnmic should use the HTTP/HTTPS proxy addresses defined in the environment variables http_proxy and https_proxy to reach the targets specified using the --address flag.","title":"proxy-from-env"},{"location":"global_flags/#retry","text":"The retry flag `[--retry] specifies the wait time before each retry. Valid formats: 10s, 1m30s, 1h. Defaults to 10s","title":"retry"},{"location":"global_flags/#skip-verify","text":"The skip verify flag [--skip-verify] indicates that the target should skip the signature verification steps, in case a secure connection is used.","title":"skip-verify"},{"location":"global_flags/#targets-file","text":"The [--targets-file] flag is used to configure a file target loader","title":"targets-file"},{"location":"global_flags/#timeout","text":"The timeout flag [--timeout] specifies the gRPC timeout after which the connection attempt fails. Valid formats: 10s, 1m30s, 1h. Defaults to 10s","title":"timeout"},{"location":"global_flags/#tls-ca","text":"The TLS CA flag [--tls-ca] specifies the root certificates for verifying server certificates encoded in PEM format.","title":"tls-ca"},{"location":"global_flags/#tls-cert","text":"The tls cert flag [--tls-cert] specifies the public key for the client encoded in PEM format.","title":"tls-cert"},{"location":"global_flags/#tls-key","text":"The tls key flag [--tls-key] specifies the private key for the client encoded in PEM format.","title":"tls-key"},{"location":"global_flags/#tls-max-version","text":"The tls max version flag [--tls-max-version] specifies the maximum supported TLS version supported by gNMIc when creating a secure gRPC connection.","title":"tls-max-version"},{"location":"global_flags/#tls-min-version","text":"The tls min version flag [--tls-min-version] specifies the minimum supported TLS version supported by gNMIc when creating a secure gRPC connection.","title":"tls-min-version"},{"location":"global_flags/#tls-version","text":"The tls version flag [--tls-version] specifies a single supported TLS version gNMIc when creating a secure gRPC connection. This flag overwrites the previously listed flags --tls-max-version and --tls-min-version .","title":"tls-version"},{"location":"global_flags/#log-tls-secret","text":"The log TLS secret flag [--log-tls-secret] makes gnmic to log the per-session pre-master secret so that it can be used to decrypt TLS secured gNMI communications with, for example, Wireshark. The secret will be saved to a file named <target-name>.tlssecret.log .","title":"log-tls-secret"},{"location":"global_flags/#token","text":"The token flag [--token] sets a token value to be added to each RPC as an Authorization Bearer Token. Applied only in the case of a secure gRPC connection.","title":"token"},{"location":"global_flags/#username","text":"The username flag [-u | --username] is used to specify the target username as part of the user credentials. If omitted, the input prompt is used to provide the username.","title":"username"},{"location":"install/","text":"gnmic is a single binary built for the Linux, Mac OS and Windows operating systems distributed via Github releases . Linux/Mac OS # To download & install the latest release the following automated installation script can be used: bash -c \" $( curl -sL https://get-gnmic.kmrd.dev ) \" As a result, the latest gnmic version will be installed in the /usr/local/bin directory and the version information will be printed out. Downloading gnmic_0.0.3_Darwin_x86_64.tar.gz... Moving gnmic to /usr/local/bin version : 0.0.3 commit : f541948 date : 2020-04-23T12:06:07Z gitURL : https://github.com/karimra/gnmic.git docs : https://gnmic.kmrd.dev Installation complete! To install a specific version of gnmic , provide the version with -v flag to the installation script: bash -c \" $( curl -sL https://get-gnmic.kmrd.dev ) \" -- -v 0 .5.0 Packages # Linux users running distributions with support for deb / rpm packages can install gnmic using pre-built packages: bash -c \" $( curl -sL https://get-gnmic.kmrd.dev ) \" -- --use-pkg Upgrade # To upgrade gnmic to the latest version use the upgrade command: # upgrade using binary file gnmic version upgrade # upgrade using package gnmic version upgrade --use-pkg Windows # Windows users should use WSL on Windows and install the linux version of the tool. Docker # The gnmic container image can be pulled from Dockerhub or GitHub container registries. The tag of the image corresponds to the release version and latest tag points to the latest available release: # pull latest release from dockerhub docker pull gnmic/gnmic:latest # pull a specific release from dockerhub docker pull gnmic/gnmic:0.7.0 # pull latest release from github registry docker pull ghcr.io/karimra/gnmic:latest # pull a specific release from github registry docker pull ghcr.io/karimra/gnmic:0.5.2 Example running gnmic get command using the docker image: docker run \\ --network host \\ --rm ghcr.io/karimra/gnmic get --log --username admin --password admin --insecure --address router1.local --path /interfaces Docker Compose # gnmic docker-compose file example: version : '2' networks : gnmic-net : driver : bridge services : gnmic-1 : image : ghcr.io/karimra/gnmic:latest container_name : gnmic-1 networks : - gnmic-net volumes : - ./gnmic.yaml:/app/gnmic.yaml command : \"subscribe --config /app/gnmic.yaml\" See here for more deployment options","title":"Installation"},{"location":"install/#linuxmac-os","text":"To download & install the latest release the following automated installation script can be used: bash -c \" $( curl -sL https://get-gnmic.kmrd.dev ) \" As a result, the latest gnmic version will be installed in the /usr/local/bin directory and the version information will be printed out. Downloading gnmic_0.0.3_Darwin_x86_64.tar.gz... Moving gnmic to /usr/local/bin version : 0.0.3 commit : f541948 date : 2020-04-23T12:06:07Z gitURL : https://github.com/karimra/gnmic.git docs : https://gnmic.kmrd.dev Installation complete! To install a specific version of gnmic , provide the version with -v flag to the installation script: bash -c \" $( curl -sL https://get-gnmic.kmrd.dev ) \" -- -v 0 .5.0","title":"Linux/Mac OS"},{"location":"install/#packages","text":"Linux users running distributions with support for deb / rpm packages can install gnmic using pre-built packages: bash -c \" $( curl -sL https://get-gnmic.kmrd.dev ) \" -- --use-pkg","title":"Packages"},{"location":"install/#upgrade","text":"To upgrade gnmic to the latest version use the upgrade command: # upgrade using binary file gnmic version upgrade # upgrade using package gnmic version upgrade --use-pkg","title":"Upgrade"},{"location":"install/#windows","text":"Windows users should use WSL on Windows and install the linux version of the tool.","title":"Windows"},{"location":"install/#docker","text":"The gnmic container image can be pulled from Dockerhub or GitHub container registries. The tag of the image corresponds to the release version and latest tag points to the latest available release: # pull latest release from dockerhub docker pull gnmic/gnmic:latest # pull a specific release from dockerhub docker pull gnmic/gnmic:0.7.0 # pull latest release from github registry docker pull ghcr.io/karimra/gnmic:latest # pull a specific release from github registry docker pull ghcr.io/karimra/gnmic:0.5.2 Example running gnmic get command using the docker image: docker run \\ --network host \\ --rm ghcr.io/karimra/gnmic get --log --username admin --password admin --insecure --address router1.local --path /interfaces","title":"Docker"},{"location":"install/#docker-compose","text":"gnmic docker-compose file example: version : '2' networks : gnmic-net : driver : bridge services : gnmic-1 : image : ghcr.io/karimra/gnmic:latest container_name : gnmic-1 networks : - gnmic-net volumes : - ./gnmic.yaml:/app/gnmic.yaml command : \"subscribe --config /app/gnmic.yaml\" See here for more deployment options","title":"Docker Compose"},{"location":"blog/","text":"Coming soon","title":"Index"},{"location":"cmd/capabilities/","text":"Description # The [cap | capabilities] command represents the gNMI Capabilities RPC . It is used to send a Capability Request to the specified target(s) and expects one Capability Response per target. Capabilities allows the client to retrieve the set of capabilities that is supported by the target: gNMI version available data models supported encodings gNMI extensions This allows the client to, for example, validate the service version that is implemented and retrieve the set of models that the target supports. The models can then be specified in subsequent Get/Subscribe RPCs to precisely tell the target which models to use. Usage # gnmic [global-flags] capabilities [local-flags] Examples # single host # gnmic -a <ip:port> --username <user> --password <password> \\ --insecure capabilities gNMI_Version: 0.7.0 supported models: - nokia-conf, Nokia, 19.10.R2 - nokia-state, Nokia, 19.10.R2 - nokia-li-state, Nokia, 19.10.R2 - nokia-li-conf, Nokia, 19.10.R2 << SNIPPED >> supported encodings: - JSON - BYTES multiple hosts # gnmic -a <ip:port>,<ip:port> -u <user> -p <password> \\ --insecure cap","title":"Capabilities"},{"location":"cmd/capabilities/#description","text":"The [cap | capabilities] command represents the gNMI Capabilities RPC . It is used to send a Capability Request to the specified target(s) and expects one Capability Response per target. Capabilities allows the client to retrieve the set of capabilities that is supported by the target: gNMI version available data models supported encodings gNMI extensions This allows the client to, for example, validate the service version that is implemented and retrieve the set of models that the target supports. The models can then be specified in subsequent Get/Subscribe RPCs to precisely tell the target which models to use.","title":"Description"},{"location":"cmd/capabilities/#usage","text":"gnmic [global-flags] capabilities [local-flags]","title":"Usage"},{"location":"cmd/capabilities/#examples","text":"","title":"Examples"},{"location":"cmd/capabilities/#single-host","text":"gnmic -a <ip:port> --username <user> --password <password> \\ --insecure capabilities gNMI_Version: 0.7.0 supported models: - nokia-conf, Nokia, 19.10.R2 - nokia-state, Nokia, 19.10.R2 - nokia-li-state, Nokia, 19.10.R2 - nokia-li-conf, Nokia, 19.10.R2 << SNIPPED >> supported encodings: - JSON - BYTES","title":"single host"},{"location":"cmd/capabilities/#multiple-hosts","text":"gnmic -a <ip:port>,<ip:port> -u <user> -p <password> \\ --insecure cap","title":"multiple hosts"},{"location":"cmd/diff/","text":"Description # The diff command is similar to a get or subscribe (mode ONCE) commands ran against at least 2 targets, a reference and one or more compared targets. The command will compare the returned responses from the compared targets to the ones returned from the reference target and only print the difference between them. The output is printed as a list \"flattened\" gNMI updates, each line containing an XPath pointing to a leaf followed by its value. Each line is preceded with either signs + or - : + means the leaf and its value are present in the compared target but not in the reference target. - means the leaf and its value are present in the reference target but not in the compared target. e.g: + network-instance[name=default]/interface[name=ethernet-1/36.0]: {} - network-instance[name=default]/protocols/bgp/autonomous-system: 101 The output above indicates: The compared target has interface ethernet-1/36.0 added to network instance default while the reference doesn't. The compared target is missing the autonomous-system 101 configuration under network-instance default protocols/bgp compared to the reference. The data to be compared is specified with the flag --path , which can be set multiple times to compare multiple data sets. By default, the data it is retrieved using a Get RPC , if the flag --sub is present, a Subscribe RPC with mode ONCE is used instead. Each of the get and subscribe methods has pros and cons, with the get method you can choose to compare CONFIG or STATE only, via the flag --type . The subscribe method allows to stream the response(s) in case a larger data set needs to be compared. In addition to that, some routers support more encoding options when using the subscribe RPC Multiple targets can be compared to the reference at once, the printed output of each difference will start with the line \"$reference\" vs \"$compared\" Aliases: compare Usage # gnmic [global-flags] diff [local-flags] Flags # ref # The --ref flag is a mandatory flag that specifies the target to used as reference to compare other targets to. compare # The --compare flag is a mandatory flag that specifies the targets to compare to the reference target. prefix # As per path prefixes , the prefix [--prefix] flag represents a common prefix that is applied to all paths specified using the local --path flag. Defaults to \"\" . path # The mandatory path flag [--path] is used to specify the path(s) the client wants to receive a snapshot of. Multiple paths can be specified by using multiple --path flags: gnmic --insecure \\ --ref router1 --compare router2,router3 diff --path \"/state/ports[port-id=*]\" \\ --path \"/state/router[router-name=*]/interface[interface-name=*]\" If a user needs to provide origin information to the Path message, the following pattern should be used for the path string: \"origin:path\" : model # The optional model flag [--model] is used to specify the schema definition modules that the target should use when returning a GetResponse. The model name should match the names returned in Capabilities RPC. Currently only single model name is supported. target # With the optional [--target] flag it is possible to supply the path target information in the prefix field of the GetRequest message. type # The type flag [--type] is used to specify the data type requested from the server. One of: ALL, CONFIG, STATE, OPERATIONAL (defaults to \"ALL\") sub # When the flag --sub is present, gnmic will use a Subscribe RPC with mode ONCE, instead of a Get RPC to retrieve the data to be compared. Examples # gnmic diff -t config --skip-verify -e ascii \\ --ref clab-te-leaf1 \\ --compare clab-te-leaf2 \\ --path /network-instance \"clab-te-leaf1:57400\" vs \"clab-te-leaf2:57400\" + network-instance [ name = default ] /interface [ name = ethernet-1/36.0 ] : {} - network-instance [ name = default ] /protocols/bgp/autonomous-system : 101 + network-instance [ name = default ] /protocols/bgp/autonomous-system : 102 - network-instance [ name = default ] /protocols/bgp/neighbor [ peer-address = 2002 ::192:168:11:1 ] : {} - network-instance [ name = default ] /protocols/bgp/neighbor [ peer-address = 2002 ::192:168:11:1 ] /admin-state: enable - network-instance [ name = default ] /protocols/bgp/neighbor [ peer-address = 2002 ::192:168:11:1 ] /peer-as : 201 - network-instance [ name = default ] /protocols/bgp/neighbor [ peer-address = 2002 ::192:168:11:1 ] /peer-group : eBGPv6 - network-instance [ name = default ] /protocols/bgp/neighbor [ peer-address = 2002 ::192:168:12:1 ] : {} - network-instance [ name = default ] /protocols/bgp/neighbor [ peer-address = 2002 ::192:168:12:1 ] /admin-state: enable - network-instance [ name = default ] /protocols/bgp/neighbor [ peer-address = 2002 ::192:168:12:1 ] /peer-as : 202 - network-instance [ name = default ] /protocols/bgp/neighbor [ peer-address = 2002 ::192:168:12:1 ] /peer-group : eBGPv6 + network-instance [ name = default ] /protocols/bgp/neighbor [ peer-address = 2002 ::192:168:21:1 ] : {} + network-instance [ name = default ] /protocols/bgp/neighbor [ peer-address = 2002 ::192:168:21:1 ] /admin-state: enable + network-instance [ name = default ] /protocols/bgp/neighbor [ peer-address = 2002 ::192:168:21:1 ] /peer-as : 201 + network-instance [ name = default ] /protocols/bgp/neighbor [ peer-address = 2002 ::192:168:21:1 ] /peer-group : eBGPv6 + network-instance [ name = default ] /protocols/bgp/neighbor [ peer-address = 2002 ::192:168:22:1 ] : {} + network-instance [ name = default ] /protocols/bgp/neighbor [ peer-address = 2002 ::192:168:22:1 ] /admin-state: enable + network-instance [ name = default ] /protocols/bgp/neighbor [ peer-address = 2002 ::192:168:22:1 ] /peer-as : 202 + network-instance [ name = default ] /protocols/bgp/neighbor [ peer-address = 2002 ::192:168:22:1 ] /peer-group : eBGPv6 + network-instance [ name = default ] /protocols/bgp/router-id : 10 .0.1.2 - network-instance [ name = default ] /protocols/bgp/router-id : 10 .0.1.1 - network-instance [ name = myins ] : {} - network-instance [ name = myins ] /admin-state : enable - network-instance [ name = myins ] /description : desc1 - network-instance [ name = myins ] /interface [ name = ethernet-1/36.0 ] : {} - network-instance [ name = myins ] /type : ip-vrf","title":"Diff"},{"location":"cmd/diff/#description","text":"The diff command is similar to a get or subscribe (mode ONCE) commands ran against at least 2 targets, a reference and one or more compared targets. The command will compare the returned responses from the compared targets to the ones returned from the reference target and only print the difference between them. The output is printed as a list \"flattened\" gNMI updates, each line containing an XPath pointing to a leaf followed by its value. Each line is preceded with either signs + or - : + means the leaf and its value are present in the compared target but not in the reference target. - means the leaf and its value are present in the reference target but not in the compared target. e.g: + network-instance[name=default]/interface[name=ethernet-1/36.0]: {} - network-instance[name=default]/protocols/bgp/autonomous-system: 101 The output above indicates: The compared target has interface ethernet-1/36.0 added to network instance default while the reference doesn't. The compared target is missing the autonomous-system 101 configuration under network-instance default protocols/bgp compared to the reference. The data to be compared is specified with the flag --path , which can be set multiple times to compare multiple data sets. By default, the data it is retrieved using a Get RPC , if the flag --sub is present, a Subscribe RPC with mode ONCE is used instead. Each of the get and subscribe methods has pros and cons, with the get method you can choose to compare CONFIG or STATE only, via the flag --type . The subscribe method allows to stream the response(s) in case a larger data set needs to be compared. In addition to that, some routers support more encoding options when using the subscribe RPC Multiple targets can be compared to the reference at once, the printed output of each difference will start with the line \"$reference\" vs \"$compared\" Aliases: compare","title":"Description"},{"location":"cmd/diff/#usage","text":"gnmic [global-flags] diff [local-flags]","title":"Usage"},{"location":"cmd/diff/#flags","text":"","title":"Flags"},{"location":"cmd/diff/#ref","text":"The --ref flag is a mandatory flag that specifies the target to used as reference to compare other targets to.","title":"ref"},{"location":"cmd/diff/#compare","text":"The --compare flag is a mandatory flag that specifies the targets to compare to the reference target.","title":"compare"},{"location":"cmd/diff/#prefix","text":"As per path prefixes , the prefix [--prefix] flag represents a common prefix that is applied to all paths specified using the local --path flag. Defaults to \"\" .","title":"prefix"},{"location":"cmd/diff/#path","text":"The mandatory path flag [--path] is used to specify the path(s) the client wants to receive a snapshot of. Multiple paths can be specified by using multiple --path flags: gnmic --insecure \\ --ref router1 --compare router2,router3 diff --path \"/state/ports[port-id=*]\" \\ --path \"/state/router[router-name=*]/interface[interface-name=*]\" If a user needs to provide origin information to the Path message, the following pattern should be used for the path string: \"origin:path\" :","title":"path"},{"location":"cmd/diff/#model","text":"The optional model flag [--model] is used to specify the schema definition modules that the target should use when returning a GetResponse. The model name should match the names returned in Capabilities RPC. Currently only single model name is supported.","title":"model"},{"location":"cmd/diff/#target","text":"With the optional [--target] flag it is possible to supply the path target information in the prefix field of the GetRequest message.","title":"target"},{"location":"cmd/diff/#type","text":"The type flag [--type] is used to specify the data type requested from the server. One of: ALL, CONFIG, STATE, OPERATIONAL (defaults to \"ALL\")","title":"type"},{"location":"cmd/diff/#sub","text":"When the flag --sub is present, gnmic will use a Subscribe RPC with mode ONCE, instead of a Get RPC to retrieve the data to be compared.","title":"sub"},{"location":"cmd/diff/#examples","text":"gnmic diff -t config --skip-verify -e ascii \\ --ref clab-te-leaf1 \\ --compare clab-te-leaf2 \\ --path /network-instance \"clab-te-leaf1:57400\" vs \"clab-te-leaf2:57400\" + network-instance [ name = default ] /interface [ name = ethernet-1/36.0 ] : {} - network-instance [ name = default ] /protocols/bgp/autonomous-system : 101 + network-instance [ name = default ] /protocols/bgp/autonomous-system : 102 - network-instance [ name = default ] /protocols/bgp/neighbor [ peer-address = 2002 ::192:168:11:1 ] : {} - network-instance [ name = default ] /protocols/bgp/neighbor [ peer-address = 2002 ::192:168:11:1 ] /admin-state: enable - network-instance [ name = default ] /protocols/bgp/neighbor [ peer-address = 2002 ::192:168:11:1 ] /peer-as : 201 - network-instance [ name = default ] /protocols/bgp/neighbor [ peer-address = 2002 ::192:168:11:1 ] /peer-group : eBGPv6 - network-instance [ name = default ] /protocols/bgp/neighbor [ peer-address = 2002 ::192:168:12:1 ] : {} - network-instance [ name = default ] /protocols/bgp/neighbor [ peer-address = 2002 ::192:168:12:1 ] /admin-state: enable - network-instance [ name = default ] /protocols/bgp/neighbor [ peer-address = 2002 ::192:168:12:1 ] /peer-as : 202 - network-instance [ name = default ] /protocols/bgp/neighbor [ peer-address = 2002 ::192:168:12:1 ] /peer-group : eBGPv6 + network-instance [ name = default ] /protocols/bgp/neighbor [ peer-address = 2002 ::192:168:21:1 ] : {} + network-instance [ name = default ] /protocols/bgp/neighbor [ peer-address = 2002 ::192:168:21:1 ] /admin-state: enable + network-instance [ name = default ] /protocols/bgp/neighbor [ peer-address = 2002 ::192:168:21:1 ] /peer-as : 201 + network-instance [ name = default ] /protocols/bgp/neighbor [ peer-address = 2002 ::192:168:21:1 ] /peer-group : eBGPv6 + network-instance [ name = default ] /protocols/bgp/neighbor [ peer-address = 2002 ::192:168:22:1 ] : {} + network-instance [ name = default ] /protocols/bgp/neighbor [ peer-address = 2002 ::192:168:22:1 ] /admin-state: enable + network-instance [ name = default ] /protocols/bgp/neighbor [ peer-address = 2002 ::192:168:22:1 ] /peer-as : 202 + network-instance [ name = default ] /protocols/bgp/neighbor [ peer-address = 2002 ::192:168:22:1 ] /peer-group : eBGPv6 + network-instance [ name = default ] /protocols/bgp/router-id : 10 .0.1.2 - network-instance [ name = default ] /protocols/bgp/router-id : 10 .0.1.1 - network-instance [ name = myins ] : {} - network-instance [ name = myins ] /admin-state : enable - network-instance [ name = myins ] /description : desc1 - network-instance [ name = myins ] /interface [ name = ethernet-1/36.0 ] : {} - network-instance [ name = myins ] /type : ip-vrf","title":"Examples"},{"location":"cmd/generate/","text":"Description # Most gNMI targets use YANG as a modeling language for their datastores. It order to access and manipulate the stored data ( Get , Set , Subscribe ), a tool should be aware of the underlying YANG model, be able to generate paths pointing to the desired gNMI objects as well as building configuration payloads matching data instances on the targets. The generate command takes the target's YANG models as input and generates: Paths in xpath or gNMI formats. Configuration payloads that can be used as update or replace input files for the Set command. A Set request file that can be used as a template with the Set command. Aliases: gen Usage # gnmic [global-flags] generate [local-flags] or gnmic [global-flags] generate [local-flags] sub-command [sub-command-flags] Persistent Flags # output # The --output flag specifies the file to which the generated output will be written, defaults to stdout json # When used with generate command, the --json flag, if present changes the output format from YAML to JSON. When used with generate path command, it outputs the path, the leaf type , its description , its default value and if it is a state leaf or not in an array of JSON objects. Local Flags # path # The --path flag specifies the path whose payload (JSON/YAML) will be generated. Defaults to / config-only # The --config-only flag, if present instruct gnmic to generate JSON/YAML payloads from YANG nodes not marked as config false . camel-case # The --camel-case flag, if present allows to convert all the keys in the generated JSON/YAML paylod to CamelCase snake-case # The --snake-case flag, if present allows to convert all the keys in the generated JSON/YAML paylod to snake_case Sub Commands # Path # The path sub command is an alias for the gnmic path command. Set-request # The set-request sub command generates a Set request file given a list of update and/or replace paths. Examples # Openconfig # YANG repo: openconfig/public Clone the OpenConfig repository: git clone https://github.com/openconfig/public cd public gnmic --encoding json_ietf \\ generate \\ --file release/models \\ --dir third_party \\ --exclude ietf-interfaces \\ --path /interfaces/interface/subinterfaces/subinterface/ipv4/addresses/address - config : ip : \"\" prefix-length : \"\" ip : \"\" vrrp : vrrp-group : - config : accept-mode : \"false\" advertisement-interval : \"100\" preempt : \"true\" preempt-delay : \"0\" priority : \"100\" virtual-address : \"\" virtual-router-id : \"\" interface-tracking : config : priority-decrement : \"0\" track-interface : \"\" virtual-router-id : \"\"","title":"Generate"},{"location":"cmd/generate/#description","text":"Most gNMI targets use YANG as a modeling language for their datastores. It order to access and manipulate the stored data ( Get , Set , Subscribe ), a tool should be aware of the underlying YANG model, be able to generate paths pointing to the desired gNMI objects as well as building configuration payloads matching data instances on the targets. The generate command takes the target's YANG models as input and generates: Paths in xpath or gNMI formats. Configuration payloads that can be used as update or replace input files for the Set command. A Set request file that can be used as a template with the Set command. Aliases: gen","title":"Description"},{"location":"cmd/generate/#usage","text":"gnmic [global-flags] generate [local-flags] or gnmic [global-flags] generate [local-flags] sub-command [sub-command-flags]","title":"Usage"},{"location":"cmd/generate/#persistent-flags","text":"","title":"Persistent Flags"},{"location":"cmd/generate/#output","text":"The --output flag specifies the file to which the generated output will be written, defaults to stdout","title":"output"},{"location":"cmd/generate/#json","text":"When used with generate command, the --json flag, if present changes the output format from YAML to JSON. When used with generate path command, it outputs the path, the leaf type , its description , its default value and if it is a state leaf or not in an array of JSON objects.","title":"json"},{"location":"cmd/generate/#local-flags","text":"","title":"Local Flags"},{"location":"cmd/generate/#path","text":"The --path flag specifies the path whose payload (JSON/YAML) will be generated. Defaults to /","title":"path"},{"location":"cmd/generate/#config-only","text":"The --config-only flag, if present instruct gnmic to generate JSON/YAML payloads from YANG nodes not marked as config false .","title":"config-only"},{"location":"cmd/generate/#camel-case","text":"The --camel-case flag, if present allows to convert all the keys in the generated JSON/YAML paylod to CamelCase","title":"camel-case"},{"location":"cmd/generate/#snake-case","text":"The --snake-case flag, if present allows to convert all the keys in the generated JSON/YAML paylod to snake_case","title":"snake-case"},{"location":"cmd/generate/#sub-commands","text":"","title":"Sub Commands"},{"location":"cmd/generate/#path_1","text":"The path sub command is an alias for the gnmic path command.","title":"Path"},{"location":"cmd/generate/#set-request","text":"The set-request sub command generates a Set request file given a list of update and/or replace paths.","title":"Set-request"},{"location":"cmd/generate/#examples","text":"","title":"Examples"},{"location":"cmd/generate/#openconfig","text":"YANG repo: openconfig/public Clone the OpenConfig repository: git clone https://github.com/openconfig/public cd public gnmic --encoding json_ietf \\ generate \\ --file release/models \\ --dir third_party \\ --exclude ietf-interfaces \\ --path /interfaces/interface/subinterfaces/subinterface/ipv4/addresses/address - config : ip : \"\" prefix-length : \"\" ip : \"\" vrrp : vrrp-group : - config : accept-mode : \"false\" advertisement-interval : \"100\" preempt : \"true\" preempt-delay : \"0\" priority : \"100\" virtual-address : \"\" virtual-router-id : \"\" interface-tracking : config : priority-decrement : \"0\" track-interface : \"\" virtual-router-id : \"\"","title":"Openconfig"},{"location":"cmd/get/","text":"Description # The get command represents the gNMI Get RPC . It is used to send a GetRequest to the specified target(s) (using the global flag --address and expects one GetResponse per target, per path. The Get RPC is used to retrieve a snapshot of data from the target. It requests that the target snapshots a subset of the data tree as specified by the paths included in the message and serializes this to be returned to the client using the specified encoding. Usage # gnmic [global-flags] get [local-flags] Flags # prefix # As per path prefixes , the prefix [--prefix] flag represents a common prefix that is applied to all paths specified using the local --path flag. Defaults to \"\" . path # The mandatory path flag [--path] is used to specify the path(s) the client wants to receive a snapshot of. Multiple paths can be specified by using multiple --path flags: gnmic -a <ip:port> --insecure \\ get --path \"/state/ports[port-id=*]\" \\ --path \"/state/router[router-name=*]/interface[interface-name=*]\" If a user needs to provide origin information to the Path message, the following pattern should be used for the path string: \"origin:path\" : Note The path after the origin value has to start with a / gnmic -a <ip:port> --insecure \\ get --path \"openconfig-interfaces:/interfaces/interface\" model # The optional model flag [--model] is used to specify the schema definition modules that the target should use when returning a GetResponse. The model name should match the names returned in Capabilities RPC. Currently only single model name is supported. target # With the optional [--target] flag it is possible to supply the path target information in the prefix field of the GetRequest message. values-only # The flag [--values-only] allows to print only the values returned in a GetResponse. This is useful when only the value of a leaf is of interest, like check if a value was set correctly. type # The type flag [--type] is used to specify the data type requested from the server. One of: ALL, CONFIG, STATE, OPERATIONAL (defaults to \"ALL\") processor # The [--processor] flag allow to list event processor names to be run as a result of receiving the GetReponse messages. The processors are run in the order they are specified ( --processor proc1,proc2 or --processor proc1 --processor proc2 ). Examples # # simple Get RPC gnmic -a <ip:port> get --path \"/state/port[port-id=*]\" # Get RPC with multiple paths gnmic -a <ip:port> get --path \"/state/port[port-id=*]\" \\ --path \"/state/router[router-name=*]/interface[interface-name=*]\" # Get RPC with path prefix gnmic -a <ip:port> get --prefix \"/state\" \\ --path \"port[port-id=*]\" \\ --path \"router[router-name=*]/interface[interface-name=*]\"","title":"Get"},{"location":"cmd/get/#description","text":"The get command represents the gNMI Get RPC . It is used to send a GetRequest to the specified target(s) (using the global flag --address and expects one GetResponse per target, per path. The Get RPC is used to retrieve a snapshot of data from the target. It requests that the target snapshots a subset of the data tree as specified by the paths included in the message and serializes this to be returned to the client using the specified encoding.","title":"Description"},{"location":"cmd/get/#usage","text":"gnmic [global-flags] get [local-flags]","title":"Usage"},{"location":"cmd/get/#flags","text":"","title":"Flags"},{"location":"cmd/get/#prefix","text":"As per path prefixes , the prefix [--prefix] flag represents a common prefix that is applied to all paths specified using the local --path flag. Defaults to \"\" .","title":"prefix"},{"location":"cmd/get/#path","text":"The mandatory path flag [--path] is used to specify the path(s) the client wants to receive a snapshot of. Multiple paths can be specified by using multiple --path flags: gnmic -a <ip:port> --insecure \\ get --path \"/state/ports[port-id=*]\" \\ --path \"/state/router[router-name=*]/interface[interface-name=*]\" If a user needs to provide origin information to the Path message, the following pattern should be used for the path string: \"origin:path\" : Note The path after the origin value has to start with a / gnmic -a <ip:port> --insecure \\ get --path \"openconfig-interfaces:/interfaces/interface\"","title":"path"},{"location":"cmd/get/#model","text":"The optional model flag [--model] is used to specify the schema definition modules that the target should use when returning a GetResponse. The model name should match the names returned in Capabilities RPC. Currently only single model name is supported.","title":"model"},{"location":"cmd/get/#target","text":"With the optional [--target] flag it is possible to supply the path target information in the prefix field of the GetRequest message.","title":"target"},{"location":"cmd/get/#values-only","text":"The flag [--values-only] allows to print only the values returned in a GetResponse. This is useful when only the value of a leaf is of interest, like check if a value was set correctly.","title":"values-only"},{"location":"cmd/get/#type","text":"The type flag [--type] is used to specify the data type requested from the server. One of: ALL, CONFIG, STATE, OPERATIONAL (defaults to \"ALL\")","title":"type"},{"location":"cmd/get/#processor","text":"The [--processor] flag allow to list event processor names to be run as a result of receiving the GetReponse messages. The processors are run in the order they are specified ( --processor proc1,proc2 or --processor proc1 --processor proc2 ).","title":"processor"},{"location":"cmd/get/#examples","text":"# simple Get RPC gnmic -a <ip:port> get --path \"/state/port[port-id=*]\" # Get RPC with multiple paths gnmic -a <ip:port> get --path \"/state/port[port-id=*]\" \\ --path \"/state/router[router-name=*]/interface[interface-name=*]\" # Get RPC with path prefix gnmic -a <ip:port> get --prefix \"/state\" \\ --path \"port[port-id=*]\" \\ --path \"router[router-name=*]/interface[interface-name=*]\"","title":"Examples"},{"location":"cmd/getset/","text":"Description # The getset command is a combination of the gNMI Get RPC and the gNMI Set RPC . It allows to conditionally execute a Set RPC based on a condition evaluated against a GetResponse . The condition written as a jq expression , is specified using the flag --condition . The SetRPC is executed only if the condition evaluates to true Usage # gnmic [global-flags] getset [local-flags] gnmic [global-flags] gas [local-flags] gnmic [global-flags] gs [local-flags] Flags # prefix # As per path prefixes , the prefix [--prefix] flag represents a common prefix that is applied to all paths specified using the local --get , --update , --replace and --delete flags. Defaults to \"\" . get # The mandatory get flag [--get] is used to specify the single path used in the Get RPC. model # The optional model flag [--model] is used to specify the schema definition modules that the target should use when returning a GetResponse. The model name should match the names returned in Capabilities RPC. Currently only single model name is supported. target # With the optional [--target] flag it is possible to supply the path target information in the prefix field of the GetRequest message. type # The type flag [--type] is used to specify the data type requested from the server. One of: ALL, CONFIG, STATE, OPERATIONAL (defaults to \"ALL\") condition # The [--condition] is a jq expression that can be used to determine if the Set Request is executed based on the Get Response values. update # The [--update] specifies a jq expression used to build the Set Request update path. replace # The [--replace] specifies a jq expression used to build the Set Request replace path. delete # The [--delete] specifies a jq expression used to build the Set Request delete path. value # The [--value] specifies a jq expression used to build the Set Request value. Examples # The command in the below example does the following: gets the list of interface indexes to interface name mapping, checks if the interface index (ifindex) 70 exists, if it does, the set request changes the interface state to enable using the interface name. gnmic getset -a <ip:port> \\ --get /interface/ifindex \\ --condition '.[] | .updates[].values[\"\"][\"srl_nokia-interfaces:interface\"][] | select(.ifindex==70) | (.name != \"\" or .name !=null)' \\ --update '.[] | .updates[].values[\"\"][\"srl_nokia-interfaces:interface\"][] | select(.ifindex==70) | \"interface[name=\" + .name + \"]/admin-state\"' \\ --value enable","title":"GetSet"},{"location":"cmd/getset/#description","text":"The getset command is a combination of the gNMI Get RPC and the gNMI Set RPC . It allows to conditionally execute a Set RPC based on a condition evaluated against a GetResponse . The condition written as a jq expression , is specified using the flag --condition . The SetRPC is executed only if the condition evaluates to true","title":"Description"},{"location":"cmd/getset/#usage","text":"gnmic [global-flags] getset [local-flags] gnmic [global-flags] gas [local-flags] gnmic [global-flags] gs [local-flags]","title":"Usage"},{"location":"cmd/getset/#flags","text":"","title":"Flags"},{"location":"cmd/getset/#prefix","text":"As per path prefixes , the prefix [--prefix] flag represents a common prefix that is applied to all paths specified using the local --get , --update , --replace and --delete flags. Defaults to \"\" .","title":"prefix"},{"location":"cmd/getset/#get","text":"The mandatory get flag [--get] is used to specify the single path used in the Get RPC.","title":"get"},{"location":"cmd/getset/#model","text":"The optional model flag [--model] is used to specify the schema definition modules that the target should use when returning a GetResponse. The model name should match the names returned in Capabilities RPC. Currently only single model name is supported.","title":"model"},{"location":"cmd/getset/#target","text":"With the optional [--target] flag it is possible to supply the path target information in the prefix field of the GetRequest message.","title":"target"},{"location":"cmd/getset/#type","text":"The type flag [--type] is used to specify the data type requested from the server. One of: ALL, CONFIG, STATE, OPERATIONAL (defaults to \"ALL\")","title":"type"},{"location":"cmd/getset/#condition","text":"The [--condition] is a jq expression that can be used to determine if the Set Request is executed based on the Get Response values.","title":"condition"},{"location":"cmd/getset/#update","text":"The [--update] specifies a jq expression used to build the Set Request update path.","title":"update"},{"location":"cmd/getset/#replace","text":"The [--replace] specifies a jq expression used to build the Set Request replace path.","title":"replace"},{"location":"cmd/getset/#delete","text":"The [--delete] specifies a jq expression used to build the Set Request delete path.","title":"delete"},{"location":"cmd/getset/#value","text":"The [--value] specifies a jq expression used to build the Set Request value.","title":"value"},{"location":"cmd/getset/#examples","text":"The command in the below example does the following: gets the list of interface indexes to interface name mapping, checks if the interface index (ifindex) 70 exists, if it does, the set request changes the interface state to enable using the interface name. gnmic getset -a <ip:port> \\ --get /interface/ifindex \\ --condition '.[] | .updates[].values[\"\"][\"srl_nokia-interfaces:interface\"][] | select(.ifindex==70) | (.name != \"\" or .name !=null)' \\ --update '.[] | .updates[].values[\"\"][\"srl_nokia-interfaces:interface\"][] | select(.ifindex==70) | \"interface[name=\" + .name + \"]/admin-state\"' \\ --value enable","title":"Examples"},{"location":"cmd/listen/","text":"Description # gnmic can be used in a \"dial-out telemetry\" mode by means of the listen command. In the dial-out mode: a network element is configured with the telemetry paths a network element initiates a connection towards the server/collector ( gnmic acts as a server in that case) Info Currently gnmic only implements the dial-out support for Nokia 1 SR OS 20.5.r1+ routers. Usage # gnmic listen [ global flags ] [ local flags ] Flags # address # The address flag [-a | --address] tells gnmic which address to bind an internal server to in an address:port format, e.g.: 0.0.0.0:57400 . tls-cert # Path to the TLS certificate can be supplied with --tls-cert flag. tls-key # Path to the private key can be supplied with --tls-key flag. max-concurrent-streams # To limit the maximum number of concurrent HTTP2 streams use the --max-concurrent-streams flag, the default value is 256. prometheus-address # The prometheus-address flag [--prometheus-address] allows starting a prometheus server that can be scraped by a prometheus client. It exposes metrics like memory, CPU and file descriptor usage. Examples # TLS disabled server # To start gnmic as a server listening on all interfaces without TLS support is as simple as: gnmic listen -a 0 .0.0.0:57400 SR OS configuration for non TLS dialout connections /configure system telemetry destination-group \"dialout\" allow-unsecure-connection /configure system telemetry destination-group \"dialout\" destination 10.2.0.99 port 57400 router-instance \"management\" /configure system telemetry persistent-subscriptions { } /configure system telemetry persistent-subscriptions subscription \"dialout\" admin-state enable /configure system telemetry persistent-subscriptions subscription \"dialout\" sensor-group \"port_stats\" /configure system telemetry persistent-subscriptions subscription \"dialout\" mode sample /configure system telemetry persistent-subscriptions subscription \"dialout\" sample-interval 1000 /configure system telemetry persistent-subscriptions subscription \"dialout\" destination-group \"dialout\" /configure system telemetry persistent-subscriptions subscription \"dialout\" encoding bytes /configure system telemetry sensor-groups { } /configure system telemetry sensor-groups { sensor-group \"port_stats\" } /configure system telemetry sensor-groups { sensor-group \"port_stats\" path \"/state/port[port-id=1/1/c1/1]/statistics/in-octets\" } TLS enabled server # By using tls-cert and tls-key flags it is possible to run gnmic with TLS. gnmic listen -a 0 .0.0.0:57400 --tls-cert gnmic.pem --tls-key gnmic-key.pem SR OS configuration for a TLS enabled dialout connections The configuration below does not utilise router-side certificates and uses the certificate provided by the server (gnmic). The router will also not verify the certificate. /configure system telemetry destination-group \"dialout\" tls-client-profile \"client-tls\" /configure system telemetry destination-group \"dialout\" destination 10.2.0.99 port 57400 router-instance \"management\" /configure system telemetry persistent-subscriptions { } /configure system telemetry persistent-subscriptions subscription \"dialout\" admin-state enable /configure system telemetry persistent-subscriptions subscription \"dialout\" sensor-group \"port_stats\" /configure system telemetry persistent-subscriptions subscription \"dialout\" mode sample /configure system telemetry persistent-subscriptions subscription \"dialout\" sample-interval 1000 /configure system telemetry persistent-subscriptions subscription \"dialout\" destination-group \"dialout\" /configure system telemetry persistent-subscriptions subscription \"dialout\" encoding bytes /configure system telemetry sensor-groups { } /configure system telemetry sensor-groups { sensor-group \"port_stats\" } /configure system telemetry sensor-groups { sensor-group \"port_stats\" path \"/state/port[port-id=1/1/c1/1]/statistics/in-octets\" } /configure system security tls client-cipher-list \"client-ciphers\" { } /configure system security tls client-cipher-list \"client-ciphers\" cipher 1 name tls-rsa-with-aes128-cbc-sha /configure system security tls client-cipher-list \"client-ciphers\" cipher 2 name tls-rsa-with-aes128-cbc-sha256 /configure system security tls client-cipher-list \"client-ciphers\" cipher 3 name tls-rsa-with-aes256-cbc-sha /configure system security tls client-cipher-list \"client-ciphers\" cipher 4 name tls-rsa-with-aes256-cbc-sha256 /configure system security tls client-tls-profile \"client-tls\" admin-state enable /configure system security tls client-tls-profile \"client-tls\" cipher-list \"client-ciphers\" Nokia dial-out proto definition can be found in karimra/sros-dialout \u21a9","title":"Listen"},{"location":"cmd/listen/#description","text":"gnmic can be used in a \"dial-out telemetry\" mode by means of the listen command. In the dial-out mode: a network element is configured with the telemetry paths a network element initiates a connection towards the server/collector ( gnmic acts as a server in that case) Info Currently gnmic only implements the dial-out support for Nokia 1 SR OS 20.5.r1+ routers.","title":"Description"},{"location":"cmd/listen/#usage","text":"gnmic listen [ global flags ] [ local flags ]","title":"Usage"},{"location":"cmd/listen/#flags","text":"","title":"Flags"},{"location":"cmd/listen/#address","text":"The address flag [-a | --address] tells gnmic which address to bind an internal server to in an address:port format, e.g.: 0.0.0.0:57400 .","title":"address"},{"location":"cmd/listen/#tls-cert","text":"Path to the TLS certificate can be supplied with --tls-cert flag.","title":"tls-cert"},{"location":"cmd/listen/#tls-key","text":"Path to the private key can be supplied with --tls-key flag.","title":"tls-key"},{"location":"cmd/listen/#max-concurrent-streams","text":"To limit the maximum number of concurrent HTTP2 streams use the --max-concurrent-streams flag, the default value is 256.","title":"max-concurrent-streams"},{"location":"cmd/listen/#prometheus-address","text":"The prometheus-address flag [--prometheus-address] allows starting a prometheus server that can be scraped by a prometheus client. It exposes metrics like memory, CPU and file descriptor usage.","title":"prometheus-address"},{"location":"cmd/listen/#examples","text":"","title":"Examples"},{"location":"cmd/listen/#tls-disabled-server","text":"To start gnmic as a server listening on all interfaces without TLS support is as simple as: gnmic listen -a 0 .0.0.0:57400 SR OS configuration for non TLS dialout connections /configure system telemetry destination-group \"dialout\" allow-unsecure-connection /configure system telemetry destination-group \"dialout\" destination 10.2.0.99 port 57400 router-instance \"management\" /configure system telemetry persistent-subscriptions { } /configure system telemetry persistent-subscriptions subscription \"dialout\" admin-state enable /configure system telemetry persistent-subscriptions subscription \"dialout\" sensor-group \"port_stats\" /configure system telemetry persistent-subscriptions subscription \"dialout\" mode sample /configure system telemetry persistent-subscriptions subscription \"dialout\" sample-interval 1000 /configure system telemetry persistent-subscriptions subscription \"dialout\" destination-group \"dialout\" /configure system telemetry persistent-subscriptions subscription \"dialout\" encoding bytes /configure system telemetry sensor-groups { } /configure system telemetry sensor-groups { sensor-group \"port_stats\" } /configure system telemetry sensor-groups { sensor-group \"port_stats\" path \"/state/port[port-id=1/1/c1/1]/statistics/in-octets\" }","title":"TLS disabled server"},{"location":"cmd/listen/#tls-enabled-server","text":"By using tls-cert and tls-key flags it is possible to run gnmic with TLS. gnmic listen -a 0 .0.0.0:57400 --tls-cert gnmic.pem --tls-key gnmic-key.pem SR OS configuration for a TLS enabled dialout connections The configuration below does not utilise router-side certificates and uses the certificate provided by the server (gnmic). The router will also not verify the certificate. /configure system telemetry destination-group \"dialout\" tls-client-profile \"client-tls\" /configure system telemetry destination-group \"dialout\" destination 10.2.0.99 port 57400 router-instance \"management\" /configure system telemetry persistent-subscriptions { } /configure system telemetry persistent-subscriptions subscription \"dialout\" admin-state enable /configure system telemetry persistent-subscriptions subscription \"dialout\" sensor-group \"port_stats\" /configure system telemetry persistent-subscriptions subscription \"dialout\" mode sample /configure system telemetry persistent-subscriptions subscription \"dialout\" sample-interval 1000 /configure system telemetry persistent-subscriptions subscription \"dialout\" destination-group \"dialout\" /configure system telemetry persistent-subscriptions subscription \"dialout\" encoding bytes /configure system telemetry sensor-groups { } /configure system telemetry sensor-groups { sensor-group \"port_stats\" } /configure system telemetry sensor-groups { sensor-group \"port_stats\" path \"/state/port[port-id=1/1/c1/1]/statistics/in-octets\" } /configure system security tls client-cipher-list \"client-ciphers\" { } /configure system security tls client-cipher-list \"client-ciphers\" cipher 1 name tls-rsa-with-aes128-cbc-sha /configure system security tls client-cipher-list \"client-ciphers\" cipher 2 name tls-rsa-with-aes128-cbc-sha256 /configure system security tls client-cipher-list \"client-ciphers\" cipher 3 name tls-rsa-with-aes256-cbc-sha /configure system security tls client-cipher-list \"client-ciphers\" cipher 4 name tls-rsa-with-aes256-cbc-sha256 /configure system security tls client-tls-profile \"client-tls\" admin-state enable /configure system security tls client-tls-profile \"client-tls\" cipher-list \"client-ciphers\" Nokia dial-out proto definition can be found in karimra/sros-dialout \u21a9","title":"TLS enabled server"},{"location":"cmd/path/","text":"Description # With path command it is possible to generate and search through the XPATH style paths extracted from a YANG file. By extracting the XPATH styled paths from a YANG model it is made possible to utilize CLI search tools like awk , sed and alike to find the paths satisfying specific matching rules. The embedded search capability allows to perform a quick and simple search through the model's paths using simple inclusion/exclusion operators. Flags # types # When --types flag is present the extracted paths will also have a corresponding type printed out. path-type # The --path-type flag governs which style is used to display the path information. The default value is xpath which will produce the XPATH compatible paths. The other option is gnmi which will result in the paths to be formatted using the gNMI Path Conventions. XPATH /state/sfm [ sfm-slot = * ] /hardware-data/firmware-revision-status gNMI elem: { name: \"state\" } elem: { name: \"sfm\" key: { key: \"sfm-slot\" value: \"*\" }} elem: { name: \"hardware-data\" } elem: { name: \"firmware-revision-status\" } search # With the --search flag present an interactive CLI search dialog is displayed that allows to navigate through the paths list and perform a search. \u276f gnmic path --file _test/nokia-state-combined.yang --search Use the arrow keys to navigate: \u2193 \u2191 \u2192 \u2190 and : toggles search ? select path: /state/aaa/radius/statistics/coa/dropped/bad-authentication /state/aaa/radius/statistics/coa/dropped/missing-auth-policy \u25b8 /state/aaa/radius/statistics/coa/dropped/invalid /state/aaa/radius/statistics/coa/dropped/missing-resource /state/aaa/radius/statistics/coa/received /state/aaa/radius/statistics/coa/accepted /state/aaa/radius/statistics/coa/rejected /state/aaa/radius/statistics/disconnect-messages/dropped/bad-authentication /state/aaa/radius/statistics/disconnect-messages/dropped/missing-auth-policy \u2193 /state/aaa/radius/statistics/disconnect-messages/dropped/invalid descr # When the --descr flag is present, the leaf description is printed after the path, indented with a \\t . config-only # When the --config-only flag is present, paths are generated only for YANG leaves representing config data. state-only # When the --state-only flag is present, paths are generated only for YANG leaves representing state data. with-non-leaves # When the --with-non-leaves flag is present, paths are generated not only for YANG leaves. Examples # # output to stdout the XPATH styled paths # from the nokia-state module of nokia-state-combined.yang file gnmic path --file nokia-state-combined.yang # from the nokia-conf module gnmic path -m nokia-conf --file nokia-conf-combined.yang # with the gNMI styled paths gnmic path --file nokia-state-combined.yang --path-type gnmi # with path types gnmic path --file nokia-state-combined.yang --types # entering the interactive navigation prompt gnmic path --file nokia-state-combined.yang --search Nokia combined models can be found in nokia/7x50_YangModels repo. \u21a9","title":"Path"},{"location":"cmd/path/#description","text":"With path command it is possible to generate and search through the XPATH style paths extracted from a YANG file. By extracting the XPATH styled paths from a YANG model it is made possible to utilize CLI search tools like awk , sed and alike to find the paths satisfying specific matching rules. The embedded search capability allows to perform a quick and simple search through the model's paths using simple inclusion/exclusion operators.","title":"Description"},{"location":"cmd/path/#flags","text":"","title":"Flags"},{"location":"cmd/path/#types","text":"When --types flag is present the extracted paths will also have a corresponding type printed out.","title":"types"},{"location":"cmd/path/#path-type","text":"The --path-type flag governs which style is used to display the path information. The default value is xpath which will produce the XPATH compatible paths. The other option is gnmi which will result in the paths to be formatted using the gNMI Path Conventions. XPATH /state/sfm [ sfm-slot = * ] /hardware-data/firmware-revision-status gNMI elem: { name: \"state\" } elem: { name: \"sfm\" key: { key: \"sfm-slot\" value: \"*\" }} elem: { name: \"hardware-data\" } elem: { name: \"firmware-revision-status\" }","title":"path-type"},{"location":"cmd/path/#search","text":"With the --search flag present an interactive CLI search dialog is displayed that allows to navigate through the paths list and perform a search. \u276f gnmic path --file _test/nokia-state-combined.yang --search Use the arrow keys to navigate: \u2193 \u2191 \u2192 \u2190 and : toggles search ? select path: /state/aaa/radius/statistics/coa/dropped/bad-authentication /state/aaa/radius/statistics/coa/dropped/missing-auth-policy \u25b8 /state/aaa/radius/statistics/coa/dropped/invalid /state/aaa/radius/statistics/coa/dropped/missing-resource /state/aaa/radius/statistics/coa/received /state/aaa/radius/statistics/coa/accepted /state/aaa/radius/statistics/coa/rejected /state/aaa/radius/statistics/disconnect-messages/dropped/bad-authentication /state/aaa/radius/statistics/disconnect-messages/dropped/missing-auth-policy \u2193 /state/aaa/radius/statistics/disconnect-messages/dropped/invalid","title":"search"},{"location":"cmd/path/#descr","text":"When the --descr flag is present, the leaf description is printed after the path, indented with a \\t .","title":"descr"},{"location":"cmd/path/#config-only","text":"When the --config-only flag is present, paths are generated only for YANG leaves representing config data.","title":"config-only"},{"location":"cmd/path/#state-only","text":"When the --state-only flag is present, paths are generated only for YANG leaves representing state data.","title":"state-only"},{"location":"cmd/path/#with-non-leaves","text":"When the --with-non-leaves flag is present, paths are generated not only for YANG leaves.","title":"with-non-leaves"},{"location":"cmd/path/#examples","text":"# output to stdout the XPATH styled paths # from the nokia-state module of nokia-state-combined.yang file gnmic path --file nokia-state-combined.yang # from the nokia-conf module gnmic path -m nokia-conf --file nokia-conf-combined.yang # with the gNMI styled paths gnmic path --file nokia-state-combined.yang --path-type gnmi # with path types gnmic path --file nokia-state-combined.yang --types # entering the interactive navigation prompt gnmic path --file nokia-state-combined.yang --search Nokia combined models can be found in nokia/7x50_YangModels repo. \u21a9","title":"Examples"},{"location":"cmd/prompt/","text":"Description # The prompt command starts gnmic in an interactive prompt mode with the following auto-completion features: All gnmic commands names and their flags are suggested . Values for the flags that rely on YANG-defined data (like --path , --prefix , --model ,...) will be dynamically suggested, we call this feature YANG-completions . The auto-completions are generated from the YANG modules d with the --file and --dir flags. Flags with the fixed set of values ( --format , --encoding , ...) will get their values suggested . Flags that require a file path value will auto-suggest the available files as the user types. Usage # gnmic [global-flags] prompt [local-flags] Flags # description-with-prefix # When set, the description of the path elements in the suggestion box will contain module's prefix. description-with-types # When set, the description of the path elements in the suggestion box will contain element's type information. max-suggestions # The --max-suggestions flag sets the number of lines that the suggestion box will display without scrolling. Defaults to 10. Note, the terminal height might limit the number of lines in the suggestions box. suggest-all-flags # The --suggest-all-flags makes gnmic prompt suggest both global and local flags for a sub-command. The default behavior (when this flag is not set) is to suggest only local flags for any typed sub-command. suggest-with-origin # The --suggest-with-origin flag prepends the suggested path with the module name to which this path belongs. The path becomes rendered as <module_name>:/<suggested-container> . The module name will be used as the origin of the gNMI path. suggestions-bg-color # The --suggestions-bg-color flag sets the background color of the left part of the suggestion box. Defaults to dark blue. description-bg-color # The --description-bg-color flag sets the background color of the right part of the suggestion box. Defaults to dark gray. prefix-color # The --prefix-color flag sets the gnmic prompt prefix color gnmic> . Defaults to dark blue. Examples # The detailed explanation of the prompt command the the YANG-completions is provided on the Prompt mode and auto-suggestions page.","title":"Prompt"},{"location":"cmd/prompt/#description","text":"The prompt command starts gnmic in an interactive prompt mode with the following auto-completion features: All gnmic commands names and their flags are suggested . Values for the flags that rely on YANG-defined data (like --path , --prefix , --model ,...) will be dynamically suggested, we call this feature YANG-completions . The auto-completions are generated from the YANG modules d with the --file and --dir flags. Flags with the fixed set of values ( --format , --encoding , ...) will get their values suggested . Flags that require a file path value will auto-suggest the available files as the user types.","title":"Description"},{"location":"cmd/prompt/#usage","text":"gnmic [global-flags] prompt [local-flags]","title":"Usage"},{"location":"cmd/prompt/#flags","text":"","title":"Flags"},{"location":"cmd/prompt/#description-with-prefix","text":"When set, the description of the path elements in the suggestion box will contain module's prefix.","title":"description-with-prefix"},{"location":"cmd/prompt/#description-with-types","text":"When set, the description of the path elements in the suggestion box will contain element's type information.","title":"description-with-types"},{"location":"cmd/prompt/#max-suggestions","text":"The --max-suggestions flag sets the number of lines that the suggestion box will display without scrolling. Defaults to 10. Note, the terminal height might limit the number of lines in the suggestions box.","title":"max-suggestions"},{"location":"cmd/prompt/#suggest-all-flags","text":"The --suggest-all-flags makes gnmic prompt suggest both global and local flags for a sub-command. The default behavior (when this flag is not set) is to suggest only local flags for any typed sub-command.","title":"suggest-all-flags"},{"location":"cmd/prompt/#suggest-with-origin","text":"The --suggest-with-origin flag prepends the suggested path with the module name to which this path belongs. The path becomes rendered as <module_name>:/<suggested-container> . The module name will be used as the origin of the gNMI path.","title":"suggest-with-origin"},{"location":"cmd/prompt/#suggestions-bg-color","text":"The --suggestions-bg-color flag sets the background color of the left part of the suggestion box. Defaults to dark blue.","title":"suggestions-bg-color"},{"location":"cmd/prompt/#description-bg-color","text":"The --description-bg-color flag sets the background color of the right part of the suggestion box. Defaults to dark gray.","title":"description-bg-color"},{"location":"cmd/prompt/#prefix-color","text":"The --prefix-color flag sets the gnmic prompt prefix color gnmic> . Defaults to dark blue.","title":"prefix-color"},{"location":"cmd/prompt/#examples","text":"The detailed explanation of the prompt command the the YANG-completions is provided on the Prompt mode and auto-suggestions page.","title":"Examples"},{"location":"cmd/set/","text":"Description # The set command represents the gNMI Set RPC . It is used to send a Set Request to the specified target(s) and expects one Set Response per target. Set RPC allows the client to modify the state of data on the target. The data specified referenced by a path can be updated, replaced or deleted . Note It is possible to combine update , replace and delete in a single gnmic set command. Usage # gnmic [global-flags] set [local-flags] The Set Request can be any of (or a combination of) update, replace or/and delete operations. Flags # prefix # The --prefix flag sets a common prefix to all paths specified using the local --path flag. Defaults to \"\" . If a user needs to provide origin information to the Path message, the following pattern should be used for the path string: \"origin:path\" : Note The path after the origin value has to start with a / gnmic set --update \"openconfig-interfaces:/interfaces/interface:::<type>:::<value>\" target # With the optional [--target] flag it is possible to supply the path target information in the prefix field of the SetRequest message. dry-run # The --dry-run flag allow to run a Set request without sending it to the targets. This is useful while developing templated Set requests. Update Request # There are several ways to perform an update operation with gNMI Set RPC: 1. in-line update, implicit type # Using both --update-path and --update-value flags, a user can update a value for a given path. gnmic set --update-path /configure/system/name --update-value router1 gnmic set --update-path /configure/router [ router-name = Base ] /interface [ interface-name = system ] /admin-state \\ --update-value enable The above 2 updates can be combined in the same cli command: gnmic set --update-path /configure/system/name \\ --update-value router1 \\ --update-path /configure/router [ router-name = Base ] /interface [ interface-name = system ] /admin-state \\ --update-value enable 2. in-line update, explicit type # Using the update flag --update , one can specify the path, value type and value in a single parameter using a delimiter --delimiter . Delimiter string defaults to \":::\" . Supported types: json, json_ietf, string, int, uint, bool, decimal, float, bytes, ascii. # path:::value-type:::value gnmic set --update /configure/system/name:::json:::router1 gnmic set --update /configure/router [ router-name = Base ] /interface [ interface-name = system ] /admin-state:::json:::enable gnmic set --update /configure/router [ router-name = Base ] /interface [ interface-name = system ] :::json::: '{\"admin-state\":\"enable\"}' 3. update with a value from JSON or YAML file # It is also possible to specify the values from a local JSON or YAML file using --update-file flag for the value and --update-path for the path. In which case the value encoding will be determined by the global flag [ -e | --encoding ] , both JSON and JSON_IETF are supported The file's format is identified by its extension, json: .json and yaml .yaml or .yml . interface.json { \"admin-state\" : \"enable\" , \"ipv4\" : { \"primary\" : { \"address\" : \"1.1.1.1\" , \"prefix-length\" : 32 } } } gnmic set --update-path /configure/router [ router-name = Base ] /interface [ interface-name = system ] \\ --update-file interface.json interface.yml \"admin-state\" : enable \"ipv4\" : \"primary\" : \"address\" : 1 .1.1.1 \"prefix-length\" : 32 gnmic set --update-path /configure/router [ router-name = Base ] /interface [ interface-name = system ] \\ --update-file interface.yml Replace Request # There are 3 main ways to specify a replace operation: 1. in-line replace, implicit type # Using both --replace-path and --replace-value flags, a user can replace a value for a given path. The type of the value is implicitly set to JSON : gnmic set --replace-path /configure/system/name --replace-value router1 gnmic set --replace-path /configure/router [ router-name = Base ] /interface [ interface-name = system ] /admin-state \\ --replace-value enable The above 2 commands can be packed in the same cli command: gnmic set --replace-path /configure/system/name \\ --replace-value router1 \\ --replace-path /configure/router [ router-name = Base ] /interface [ interface-name = system ] /admin-state \\ --replace-value enable 2. in-line replace, explicit type # Using the replace flag --replace , you can specify the path, value type and value in a single parameter using a delimiter --delimiter . Delimiter string defaults to \":::\" . Supported types: json, json_ietf, string, int, uint, bool, decimal, float, bytes, ascii. gnmic set --replace /configure/system/name:::json:::router1 gnmic set --replace /configure/router [ router-name = Base ] /interface [ interface-name = system ] /admin-state:::json:::enable 3. replace with a value from JSON or YAML file # It is also possible to specify the values from a local JSON or YAML file using flag --replace-file for the value and --replace-path for the path. In which case the value encoding will be determined by the global flag [ -e | --encoding ] , both JSON and JSON_IETF are supported The file is identified by its extension, json: .json and yaml .yaml or .yml . interface.json { \"admin-state\" : \"enable\" , \"ipv4\" : { \"primary\" : { \"address\" : \"1.1.1.1\" , \"prefix-length\" : 32 } } } interface.yml \"admin-state\" : enable \"ipv4\" : \"primary\" : \"address\" : 1 .1.1.1 \"prefix-length\" : 32 Then refer to the file with --replace-file flag gnmic set --replace-path /configure/router [ router-name = Base ] /interface [ interface-name = system ] \\ --replace-file interface.json Delete Request # A deletion operation within the Set RPC is specified using the delete flag --delete . It takes an XPATH pointing to the config node to be deleted: gnmic set --delete \"/configure/router[router-name=Base]/interface[interface-name=dummy_interface]\" Templated Set Request file # A Set Request can also be built based on one or multiple templates and (optionally) a set of variables. The variables allow to generate a Set Request file on per target basis. If no variable file is found, the execution continues and the template is assumed to be a static string. Each template specified with the flag --request-file is rendered against the variables defined in the file set with --request-vars . Each template results in a single gNMI Set Request. gnmic set --request-file <template1> --request-file <template2> --request-vars <vars_file> Template Format # The rendered template data can be a JSON or YAML valid string. It has 3 sections, updates , replaces and deletes . In each of the updates and replaces , a path , a value and an encoding can be configured. If not specified, path defaults to / , while encoding defaults to the value set with --encoding flag. updates and replaces result in a set of gNMI Set Updates in the Set RPC, deletes result in a set of gNMI paths to be deleted. The value can be any arbitrary data format that the target accepts, it will be encoded based on the value of \"encoding\". JSON { \"updates\" : [ { \"path\" : \"/interface[name=ethernet-1/1]\" , \"value\" : { \"admin-state\" : \"enable\" , \"description\" : \"to_spine1\" }, \"encoding\" : \"json_ietf\" }, { \"path\" : \"/interface[name=ethernet-1/2]\" , \"value\" : { \"admin-state\" : \"enable\" , \"description\" : \"to_spine2\" }, \"encoding\" : \"json_ietf\" } ], \"replaces\" : [ { \"path\" : \"/interface[name=ethernet-1/3]\" , \"value\" : { \"admin-state\" : \"enable\" , \"description\" : \"to_spine3\" } }, { \"path\" : \"/interface[name=ethernet-1/4]\" , \"value\" : { \"admin-state\" : \"enable\" , \"description\" : \"to_spine4\" } } ], \"deletes\" : [ \"/interface[name=ethernet-1/5]\" , \"/interface[name=ethernet-1/6]\" ] } YAML updates : - path : \"/interface[name=ethernet-1/1]\" value : admin-state : enable description : \"to_spine1\" encoding : \"json_ietf\" - path : \"/interface[name=ethernet-1/2]\" value : admin-state : enable description : \"to_spine2\" encoding : \"json_ietf\" replaces : - path : \"/interface[name=ethernet-1/3]\" value : admin-state : enable description : \"to_spine3\" - path : \"/interface[name=ethernet-1/4]\" value : admin-state : enable description : \"to_spine4\" deletes : - \"/interface[name=ethernet-1/5]\" - \"/interface[name=ethernet-1/6]\" Per Target Template Variables # The file --request-file can be written as a Go Text template . The parsed template is loaded with additional functions from gomplate . gnmic generates one gNMI Set request per target. The template will be rendered using variables read from the file --request-vars . Just like the template file, the variables file can either be a JSON or YAML formatted file. If the flag --request-vars is not set, gnmic looks for a file with the same path, name and extension as the request-file , appended with _vars . Within the template, the variables defined in the --request-vars file are accessible using the .Vars notation, while the target name is accessible using the .TargetName notation. Example request template: replaces : {{ $target : = index .Vars .TargetName }} {{ - range $interface : = index $target \"interfaces\" }} - path : \"/interface[name={{ index $interface \" name\" }}]\" encoding : \"json_ietf\" value : admin-state : {{ index $interface \"admin-state\" | default \"disable\" }} description : {{ index $interface \"description\" | default \"\" }} {{ - range $index , $subinterface : = index $interface \"subinterfaces\" }} subinterface : - index : {{ $index }} admin-state : {{ index $subinterface \"admin-state\" | default \"disable\" }} {{ - if has $subinterface \"ipv4-address\" }} ipv4 : address : - ip-prefix : {{ index $subinterface \"ipv4-address\" | toString }} {{ - end }} {{ - if has $subinterface \"ipv6-address\" }} ipv6 : address : - ip-prefix : {{ index $subinterface \"ipv6-address\" | toString }} {{ - end }} {{ - end }} {{ - end }} The below variables file defines the input for 3 leafs: leaf1:57400 : interfaces : - name : ethernet-1/1 admin-state : \"enable\" description : \"leaf1_to_spine1\" subinterfaces : - admin-state : enable ipv4-address : 192.168.78.1/30 - name : ethernet-1/2 admin-state : \"enable\" description : \"leaf1_to_spine2\" subinterfaces : - admin-state : enable ipv4-address : 192.168.79.1/30 leaf2:57400 : interfaces : - name : ethernet-1/1 admin-state : \"enable\" description : \"leaf2_to_spine1\" subinterfaces : - admin-state : enable ipv4-address : 192.168.88.1/30 - name : ethernet-1/2 admin-state : \"enable\" description : \"leaf2_to_spine2\" subinterfaces : - admin-state : enable ipv4-address : 192.168.89.1/30 leaf3:57400 : interfaces : - name : ethernet-1/1 admin-state : \"enable\" description : \"leaf3_to_spine1\" subinterfaces : - admin-state : enable ipv4-address : 192.168.98.1/30 - name : ethernet-1/2 admin-state : \"enable\" description : \"leaf3_to_spine2\" subinterfaces : - admin-state : enable ipv4-address : 192.168.99.1/30 Result Request file per target: leaf1 updates : - path : /interface[name=ethernet-1/1] encoding : \"json_ietf\" value : admin-state : enable description : leaf1_to_spine1 subinterface : - index : 0 admin-state : enable ipv4 : address : - ip-prefix : 192.168.78.1/30 - path : /interface[name=ethernet-1/2] encoding : \"json_ietf\" value : admin-state : enable description : leaf1_to_spine2 subinterface : - index : 0 admin-state : enable ipv4 : address : - ip-prefix : 192.168.79.1/30 leaf2 updates : - path : /interface[name=ethernet-1/1] encoding : \"json_ietf\" value : admin-state : enable description : leaf2_to_spine1 subinterface : - index : 0 admin-state : enable ipv4 : address : - ip-prefix : 192.168.88.1/30 - path : /interface[name=ethernet-1/2] encoding : \"json_ietf\" value : admin-state : enable description : leaf2_to_spine2 subinterface : - index : 0 admin-state : enable ipv4 : address : - ip-prefix : 192.168.89.1/30 leaf3 updates : - path : /interface[name=ethernet-1/1] encoding : \"json_ietf\" value : admin-state : enable description : leaf3_to_spine1 subinterface : - index : 0 admin-state : enable ipv4 : address : - ip-prefix : 192.168.98.1/30 - path : /interface[name=ethernet-1/2] encoding : \"json_ietf\" value : admin-state : enable description : leaf3_to_spine2 subinterface : - index : 0 admin-state : enable ipv4 : address : - ip-prefix : 192.168.99.1/30 Examples # 1. update # in-line value # gnmic -a <ip:port> set --update-path /configure/system/name \\ --update-value <system_name> value from JSON file # cat jsonFile.json { \"name\" : \"router1\" } gnmic -a <ip:port> set --update-path /configure/system \\ --update-file <jsonFile.json> echo '{\"name\": \"router1\"}' | gnmic -a <ip:port> set \\ --update-path /configure/system \\ --update-file - specify value type # gnmic -a <ip:port> set --update /configure/system/name:::json:::router1 gnmic -a <ip:port> set --update /configure/system/name@json@router1 \\ --delimiter @ 2. replace # cat interface.json { \"address\" : \"1.1.1.1\" , \"prefix-length\" : 32 } gnmic -a <ip:port> --insecure \\ set --replace-path /configure/router [ router-name = Base ] /interface [ interface-name = interface1 ] /ipv4/primary \\ --replace-file interface.json echo '{\"address\": \"1.1.1.1\", \"prefix-length\": 32}' | gnmic -a <ip:port> --insecure \\ set --replace-path /configure/router [ router-name = Base ] /interface [ interface-name = interface1 ] /ipv4/primary \\ --replace-file - 3. delete # gnmic -a <ip:port> --insecure set --delete /configure/router [ router-name = Base ] /interface [ interface-name = interface1 ]","title":"Set"},{"location":"cmd/set/#description","text":"The set command represents the gNMI Set RPC . It is used to send a Set Request to the specified target(s) and expects one Set Response per target. Set RPC allows the client to modify the state of data on the target. The data specified referenced by a path can be updated, replaced or deleted . Note It is possible to combine update , replace and delete in a single gnmic set command.","title":"Description"},{"location":"cmd/set/#usage","text":"gnmic [global-flags] set [local-flags] The Set Request can be any of (or a combination of) update, replace or/and delete operations.","title":"Usage"},{"location":"cmd/set/#flags","text":"","title":"Flags"},{"location":"cmd/set/#prefix","text":"The --prefix flag sets a common prefix to all paths specified using the local --path flag. Defaults to \"\" . If a user needs to provide origin information to the Path message, the following pattern should be used for the path string: \"origin:path\" : Note The path after the origin value has to start with a / gnmic set --update \"openconfig-interfaces:/interfaces/interface:::<type>:::<value>\"","title":"prefix"},{"location":"cmd/set/#target","text":"With the optional [--target] flag it is possible to supply the path target information in the prefix field of the SetRequest message.","title":"target"},{"location":"cmd/set/#dry-run","text":"The --dry-run flag allow to run a Set request without sending it to the targets. This is useful while developing templated Set requests.","title":"dry-run"},{"location":"cmd/set/#update-request","text":"There are several ways to perform an update operation with gNMI Set RPC:","title":"Update Request"},{"location":"cmd/set/#1-in-line-update-implicit-type","text":"Using both --update-path and --update-value flags, a user can update a value for a given path. gnmic set --update-path /configure/system/name --update-value router1 gnmic set --update-path /configure/router [ router-name = Base ] /interface [ interface-name = system ] /admin-state \\ --update-value enable The above 2 updates can be combined in the same cli command: gnmic set --update-path /configure/system/name \\ --update-value router1 \\ --update-path /configure/router [ router-name = Base ] /interface [ interface-name = system ] /admin-state \\ --update-value enable","title":"1. in-line update, implicit type"},{"location":"cmd/set/#2-in-line-update-explicit-type","text":"Using the update flag --update , one can specify the path, value type and value in a single parameter using a delimiter --delimiter . Delimiter string defaults to \":::\" . Supported types: json, json_ietf, string, int, uint, bool, decimal, float, bytes, ascii. # path:::value-type:::value gnmic set --update /configure/system/name:::json:::router1 gnmic set --update /configure/router [ router-name = Base ] /interface [ interface-name = system ] /admin-state:::json:::enable gnmic set --update /configure/router [ router-name = Base ] /interface [ interface-name = system ] :::json::: '{\"admin-state\":\"enable\"}'","title":"2. in-line update, explicit type"},{"location":"cmd/set/#3-update-with-a-value-from-json-or-yaml-file","text":"It is also possible to specify the values from a local JSON or YAML file using --update-file flag for the value and --update-path for the path. In which case the value encoding will be determined by the global flag [ -e | --encoding ] , both JSON and JSON_IETF are supported The file's format is identified by its extension, json: .json and yaml .yaml or .yml . interface.json { \"admin-state\" : \"enable\" , \"ipv4\" : { \"primary\" : { \"address\" : \"1.1.1.1\" , \"prefix-length\" : 32 } } } gnmic set --update-path /configure/router [ router-name = Base ] /interface [ interface-name = system ] \\ --update-file interface.json interface.yml \"admin-state\" : enable \"ipv4\" : \"primary\" : \"address\" : 1 .1.1.1 \"prefix-length\" : 32 gnmic set --update-path /configure/router [ router-name = Base ] /interface [ interface-name = system ] \\ --update-file interface.yml","title":"3. update with a value from JSON or YAML file"},{"location":"cmd/set/#replace-request","text":"There are 3 main ways to specify a replace operation:","title":"Replace Request"},{"location":"cmd/set/#1-in-line-replace-implicit-type","text":"Using both --replace-path and --replace-value flags, a user can replace a value for a given path. The type of the value is implicitly set to JSON : gnmic set --replace-path /configure/system/name --replace-value router1 gnmic set --replace-path /configure/router [ router-name = Base ] /interface [ interface-name = system ] /admin-state \\ --replace-value enable The above 2 commands can be packed in the same cli command: gnmic set --replace-path /configure/system/name \\ --replace-value router1 \\ --replace-path /configure/router [ router-name = Base ] /interface [ interface-name = system ] /admin-state \\ --replace-value enable","title":"1. in-line replace, implicit type"},{"location":"cmd/set/#2-in-line-replace-explicit-type","text":"Using the replace flag --replace , you can specify the path, value type and value in a single parameter using a delimiter --delimiter . Delimiter string defaults to \":::\" . Supported types: json, json_ietf, string, int, uint, bool, decimal, float, bytes, ascii. gnmic set --replace /configure/system/name:::json:::router1 gnmic set --replace /configure/router [ router-name = Base ] /interface [ interface-name = system ] /admin-state:::json:::enable","title":"2. in-line replace, explicit type"},{"location":"cmd/set/#3-replace-with-a-value-from-json-or-yaml-file","text":"It is also possible to specify the values from a local JSON or YAML file using flag --replace-file for the value and --replace-path for the path. In which case the value encoding will be determined by the global flag [ -e | --encoding ] , both JSON and JSON_IETF are supported The file is identified by its extension, json: .json and yaml .yaml or .yml . interface.json { \"admin-state\" : \"enable\" , \"ipv4\" : { \"primary\" : { \"address\" : \"1.1.1.1\" , \"prefix-length\" : 32 } } } interface.yml \"admin-state\" : enable \"ipv4\" : \"primary\" : \"address\" : 1 .1.1.1 \"prefix-length\" : 32 Then refer to the file with --replace-file flag gnmic set --replace-path /configure/router [ router-name = Base ] /interface [ interface-name = system ] \\ --replace-file interface.json","title":"3. replace with a value from JSON or YAML file"},{"location":"cmd/set/#delete-request","text":"A deletion operation within the Set RPC is specified using the delete flag --delete . It takes an XPATH pointing to the config node to be deleted: gnmic set --delete \"/configure/router[router-name=Base]/interface[interface-name=dummy_interface]\"","title":"Delete Request"},{"location":"cmd/set/#templated-set-request-file","text":"A Set Request can also be built based on one or multiple templates and (optionally) a set of variables. The variables allow to generate a Set Request file on per target basis. If no variable file is found, the execution continues and the template is assumed to be a static string. Each template specified with the flag --request-file is rendered against the variables defined in the file set with --request-vars . Each template results in a single gNMI Set Request. gnmic set --request-file <template1> --request-file <template2> --request-vars <vars_file>","title":"Templated Set Request file"},{"location":"cmd/set/#template-format","text":"The rendered template data can be a JSON or YAML valid string. It has 3 sections, updates , replaces and deletes . In each of the updates and replaces , a path , a value and an encoding can be configured. If not specified, path defaults to / , while encoding defaults to the value set with --encoding flag. updates and replaces result in a set of gNMI Set Updates in the Set RPC, deletes result in a set of gNMI paths to be deleted. The value can be any arbitrary data format that the target accepts, it will be encoded based on the value of \"encoding\". JSON { \"updates\" : [ { \"path\" : \"/interface[name=ethernet-1/1]\" , \"value\" : { \"admin-state\" : \"enable\" , \"description\" : \"to_spine1\" }, \"encoding\" : \"json_ietf\" }, { \"path\" : \"/interface[name=ethernet-1/2]\" , \"value\" : { \"admin-state\" : \"enable\" , \"description\" : \"to_spine2\" }, \"encoding\" : \"json_ietf\" } ], \"replaces\" : [ { \"path\" : \"/interface[name=ethernet-1/3]\" , \"value\" : { \"admin-state\" : \"enable\" , \"description\" : \"to_spine3\" } }, { \"path\" : \"/interface[name=ethernet-1/4]\" , \"value\" : { \"admin-state\" : \"enable\" , \"description\" : \"to_spine4\" } } ], \"deletes\" : [ \"/interface[name=ethernet-1/5]\" , \"/interface[name=ethernet-1/6]\" ] } YAML updates : - path : \"/interface[name=ethernet-1/1]\" value : admin-state : enable description : \"to_spine1\" encoding : \"json_ietf\" - path : \"/interface[name=ethernet-1/2]\" value : admin-state : enable description : \"to_spine2\" encoding : \"json_ietf\" replaces : - path : \"/interface[name=ethernet-1/3]\" value : admin-state : enable description : \"to_spine3\" - path : \"/interface[name=ethernet-1/4]\" value : admin-state : enable description : \"to_spine4\" deletes : - \"/interface[name=ethernet-1/5]\" - \"/interface[name=ethernet-1/6]\"","title":"Template Format"},{"location":"cmd/set/#per-target-template-variables","text":"The file --request-file can be written as a Go Text template . The parsed template is loaded with additional functions from gomplate . gnmic generates one gNMI Set request per target. The template will be rendered using variables read from the file --request-vars . Just like the template file, the variables file can either be a JSON or YAML formatted file. If the flag --request-vars is not set, gnmic looks for a file with the same path, name and extension as the request-file , appended with _vars . Within the template, the variables defined in the --request-vars file are accessible using the .Vars notation, while the target name is accessible using the .TargetName notation. Example request template: replaces : {{ $target : = index .Vars .TargetName }} {{ - range $interface : = index $target \"interfaces\" }} - path : \"/interface[name={{ index $interface \" name\" }}]\" encoding : \"json_ietf\" value : admin-state : {{ index $interface \"admin-state\" | default \"disable\" }} description : {{ index $interface \"description\" | default \"\" }} {{ - range $index , $subinterface : = index $interface \"subinterfaces\" }} subinterface : - index : {{ $index }} admin-state : {{ index $subinterface \"admin-state\" | default \"disable\" }} {{ - if has $subinterface \"ipv4-address\" }} ipv4 : address : - ip-prefix : {{ index $subinterface \"ipv4-address\" | toString }} {{ - end }} {{ - if has $subinterface \"ipv6-address\" }} ipv6 : address : - ip-prefix : {{ index $subinterface \"ipv6-address\" | toString }} {{ - end }} {{ - end }} {{ - end }} The below variables file defines the input for 3 leafs: leaf1:57400 : interfaces : - name : ethernet-1/1 admin-state : \"enable\" description : \"leaf1_to_spine1\" subinterfaces : - admin-state : enable ipv4-address : 192.168.78.1/30 - name : ethernet-1/2 admin-state : \"enable\" description : \"leaf1_to_spine2\" subinterfaces : - admin-state : enable ipv4-address : 192.168.79.1/30 leaf2:57400 : interfaces : - name : ethernet-1/1 admin-state : \"enable\" description : \"leaf2_to_spine1\" subinterfaces : - admin-state : enable ipv4-address : 192.168.88.1/30 - name : ethernet-1/2 admin-state : \"enable\" description : \"leaf2_to_spine2\" subinterfaces : - admin-state : enable ipv4-address : 192.168.89.1/30 leaf3:57400 : interfaces : - name : ethernet-1/1 admin-state : \"enable\" description : \"leaf3_to_spine1\" subinterfaces : - admin-state : enable ipv4-address : 192.168.98.1/30 - name : ethernet-1/2 admin-state : \"enable\" description : \"leaf3_to_spine2\" subinterfaces : - admin-state : enable ipv4-address : 192.168.99.1/30 Result Request file per target: leaf1 updates : - path : /interface[name=ethernet-1/1] encoding : \"json_ietf\" value : admin-state : enable description : leaf1_to_spine1 subinterface : - index : 0 admin-state : enable ipv4 : address : - ip-prefix : 192.168.78.1/30 - path : /interface[name=ethernet-1/2] encoding : \"json_ietf\" value : admin-state : enable description : leaf1_to_spine2 subinterface : - index : 0 admin-state : enable ipv4 : address : - ip-prefix : 192.168.79.1/30 leaf2 updates : - path : /interface[name=ethernet-1/1] encoding : \"json_ietf\" value : admin-state : enable description : leaf2_to_spine1 subinterface : - index : 0 admin-state : enable ipv4 : address : - ip-prefix : 192.168.88.1/30 - path : /interface[name=ethernet-1/2] encoding : \"json_ietf\" value : admin-state : enable description : leaf2_to_spine2 subinterface : - index : 0 admin-state : enable ipv4 : address : - ip-prefix : 192.168.89.1/30 leaf3 updates : - path : /interface[name=ethernet-1/1] encoding : \"json_ietf\" value : admin-state : enable description : leaf3_to_spine1 subinterface : - index : 0 admin-state : enable ipv4 : address : - ip-prefix : 192.168.98.1/30 - path : /interface[name=ethernet-1/2] encoding : \"json_ietf\" value : admin-state : enable description : leaf3_to_spine2 subinterface : - index : 0 admin-state : enable ipv4 : address : - ip-prefix : 192.168.99.1/30","title":"Per Target Template Variables"},{"location":"cmd/set/#examples","text":"","title":"Examples"},{"location":"cmd/set/#1-update","text":"","title":"1. update"},{"location":"cmd/set/#in-line-value","text":"gnmic -a <ip:port> set --update-path /configure/system/name \\ --update-value <system_name>","title":"in-line value"},{"location":"cmd/set/#value-from-json-file","text":"cat jsonFile.json { \"name\" : \"router1\" } gnmic -a <ip:port> set --update-path /configure/system \\ --update-file <jsonFile.json> echo '{\"name\": \"router1\"}' | gnmic -a <ip:port> set \\ --update-path /configure/system \\ --update-file -","title":"value from JSON file"},{"location":"cmd/set/#specify-value-type","text":"gnmic -a <ip:port> set --update /configure/system/name:::json:::router1 gnmic -a <ip:port> set --update /configure/system/name@json@router1 \\ --delimiter @","title":"specify value type"},{"location":"cmd/set/#2-replace","text":"cat interface.json { \"address\" : \"1.1.1.1\" , \"prefix-length\" : 32 } gnmic -a <ip:port> --insecure \\ set --replace-path /configure/router [ router-name = Base ] /interface [ interface-name = interface1 ] /ipv4/primary \\ --replace-file interface.json echo '{\"address\": \"1.1.1.1\", \"prefix-length\": 32}' | gnmic -a <ip:port> --insecure \\ set --replace-path /configure/router [ router-name = Base ] /interface [ interface-name = interface1 ] /ipv4/primary \\ --replace-file -","title":"2. replace"},{"location":"cmd/set/#3-delete","text":"gnmic -a <ip:port> --insecure set --delete /configure/router [ router-name = Base ] /interface [ interface-name = interface1 ]","title":"3. delete"},{"location":"cmd/subscribe/","text":"Description # The [subscribe | sub] command represents the gNMI Subscribe RPC . It is used to send a Subscribe Request to the specified target(s) and expects one or multiple Subscribe Response Usage # gnmic [global-flags] subscribe [local-flags] Local Flags # The subscribe command supports the following local flags: prefix # The [--prefix] flag sets a common prefix to all paths specified using the local --path flag. Defaults to \"\" . path # The path flag [--path] is used to specify the path(s) to which the client wants to subscribe. Multiple paths can be specified by using repeated --path flags: gnmic sub --path \"/state/ports[port-id=*]\" \\ --path \"/state/router[router-name=*]/interface[interface-name=*]\" If a user needs to provide origin information to the Path message, the following pattern should be used for the path string: \"origin:path\" : Note The path after the origin value has to start with a / gnmic sub --path \"openconfig-interfaces:/interfaces/interface\" target # With the optional [--target] flag it is possible to supply the path target information in the prefix field of the SubscriptionList message. set-target # The [--set-target] flag is used to set the SubscribeRequest Prefix target value to the configured target name stripped of the port number. model # The [--model] flag is used to specify the schema definition modules that the target should use when extracting the data to stream back. qos # The [--qos] flag specifies the packet marking that is to be used for the responses to the subscription request. Default marking is set to 20 . If qos marking is not supported by a target the marking can be disabled by setting the value to 0 . mode # The [--mode] mode flag specifies the mode of subscription to be created. This may be one of: ONCE , STREAM or POLL . It is case insensitive and defaults to STREAM . stream subscription mode # The [--stream-mode] flag is used to specify the stream subscription mode. This may be one of: ON_CHANGE, SAMPLE or TARGET_DEFINED This flag applies only if --mode is set to STREAM . It is case insensitive and defaults to SAMPLE . sample interval # The [--sample-interval] flag is used to specify the sample interval to be used by the target to send samples to the client. This flag applies only in case --mode is set to STREAM and --stream-mode is set to SAMPLE . Valid formats: 1s, 1m30s, 1h . Defaults to 0s which is the lowest interval supported by a target. heartbeat interval # The [--heartbeat-interval] flag is used to specify the server heartbeat interval. The heartbeat interval value can be specified along with ON_CHANGE or SAMPLE stream subscriptions modes. ON_CHANGE : The value of the data item(s) MUST be re-sent once per heartbeat interval regardless of whether the value has changed or not. SAMPLE : The target MUST generate one telemetry update per heartbeat interval, regardless of whether the --suppress-redundant flag is set to true. quiet # With [--quiet] flag set gnmic will not output subscription responses to stdout . The --quiet flag is useful when gnmic exports the received data to one of the export providers. suppress redundant # When the [--suppress-redundant] flag is set to true, the target SHOULD NOT generate a telemetry update message unless the value of the path being reported on has changed since the last update was generated. This flag applies only in case --mode is set to STREAM and --stream-mode is set to SAMPLE . updates only # When the [--updates-only] flag is set to true, the target MUST not transmit the current state of the paths that the client has subscribed to, but rather should send only updates to them. name # The [--name] flag is used to trigger one or multiple subscriptions already defined in the configuration file see defining subscriptions output # The [--output] flag is used to select one or multiple output already defined in the configuration file. Outputs defined under target take precedence over this flag, see defining outputs and defining targets watch-config # The [--watch-config] flag is used to enable automatic target loading from the configuration source at runtime. On each configuration change, gnmic reloads the list of targets, subscribes to new targets and/or deletes subscriptions to the deleted ones. Only addition and deletion of targets are currently supported, changes in an existing target config are not possible. backoff # The [--backoff] flag is used to specify a duration between consecutive subscription towards targets. It defaults to 0s meaning all subscription are started in parallel. If a locker is configured, the backoff timer is set to 100ms by default. lock-retry # The [--lock-retry] flag is a duration used to set the wait time between consecutive lock attempts. Defaults to 5s . history-snapshot # The [--history-snapshot] flag sets the snapshot value in the subscribe request gNMI History extension . The value can be either nanoseconds since Unix epoch or a date in RFC3339 format. history-start # The [--history-start] flag sets the start value in the subscribe request Time Range gNMI History extension . The value can be either nanoseconds since Unix epoch or a date in RFC3339 format. history-end # The [--history-end] flag sets the end value in the subscribe request Time Range gNMI History extension . Examples # 1. streaming, target-defined, 10s interval # gnmic -a <ip:port> sub --path /state/port [ port-id = * ] /statistics 2. streaming, sample, 30s interval # gnmic -a <ip:port> sub --path \"/state/port[port-id=*]/statistics\" \\ --sample-interval 30s 3. streaming, on-change, heartbeat interval 1min # gnmic -a <ip:port> sub --path \"/state/port[port-id=*]/statistics\" \\ --stream-mode on-change \\ --heartbeat-interval 1m 4. once subscription # gnmic -a <ip:port> sub --path \"/state/port[port-id=*]/statistics\" \\ --mode once","title":"Subscribe"},{"location":"cmd/subscribe/#description","text":"The [subscribe | sub] command represents the gNMI Subscribe RPC . It is used to send a Subscribe Request to the specified target(s) and expects one or multiple Subscribe Response","title":"Description"},{"location":"cmd/subscribe/#usage","text":"gnmic [global-flags] subscribe [local-flags]","title":"Usage"},{"location":"cmd/subscribe/#local-flags","text":"The subscribe command supports the following local flags:","title":"Local Flags"},{"location":"cmd/subscribe/#prefix","text":"The [--prefix] flag sets a common prefix to all paths specified using the local --path flag. Defaults to \"\" .","title":"prefix"},{"location":"cmd/subscribe/#path","text":"The path flag [--path] is used to specify the path(s) to which the client wants to subscribe. Multiple paths can be specified by using repeated --path flags: gnmic sub --path \"/state/ports[port-id=*]\" \\ --path \"/state/router[router-name=*]/interface[interface-name=*]\" If a user needs to provide origin information to the Path message, the following pattern should be used for the path string: \"origin:path\" : Note The path after the origin value has to start with a / gnmic sub --path \"openconfig-interfaces:/interfaces/interface\"","title":"path"},{"location":"cmd/subscribe/#target","text":"With the optional [--target] flag it is possible to supply the path target information in the prefix field of the SubscriptionList message.","title":"target"},{"location":"cmd/subscribe/#set-target","text":"The [--set-target] flag is used to set the SubscribeRequest Prefix target value to the configured target name stripped of the port number.","title":"set-target"},{"location":"cmd/subscribe/#model","text":"The [--model] flag is used to specify the schema definition modules that the target should use when extracting the data to stream back.","title":"model"},{"location":"cmd/subscribe/#qos","text":"The [--qos] flag specifies the packet marking that is to be used for the responses to the subscription request. Default marking is set to 20 . If qos marking is not supported by a target the marking can be disabled by setting the value to 0 .","title":"qos"},{"location":"cmd/subscribe/#mode","text":"The [--mode] mode flag specifies the mode of subscription to be created. This may be one of: ONCE , STREAM or POLL . It is case insensitive and defaults to STREAM .","title":"mode"},{"location":"cmd/subscribe/#stream-subscription-mode","text":"The [--stream-mode] flag is used to specify the stream subscription mode. This may be one of: ON_CHANGE, SAMPLE or TARGET_DEFINED This flag applies only if --mode is set to STREAM . It is case insensitive and defaults to SAMPLE .","title":"stream subscription mode"},{"location":"cmd/subscribe/#sample-interval","text":"The [--sample-interval] flag is used to specify the sample interval to be used by the target to send samples to the client. This flag applies only in case --mode is set to STREAM and --stream-mode is set to SAMPLE . Valid formats: 1s, 1m30s, 1h . Defaults to 0s which is the lowest interval supported by a target.","title":"sample interval"},{"location":"cmd/subscribe/#heartbeat-interval","text":"The [--heartbeat-interval] flag is used to specify the server heartbeat interval. The heartbeat interval value can be specified along with ON_CHANGE or SAMPLE stream subscriptions modes. ON_CHANGE : The value of the data item(s) MUST be re-sent once per heartbeat interval regardless of whether the value has changed or not. SAMPLE : The target MUST generate one telemetry update per heartbeat interval, regardless of whether the --suppress-redundant flag is set to true.","title":"heartbeat interval"},{"location":"cmd/subscribe/#quiet","text":"With [--quiet] flag set gnmic will not output subscription responses to stdout . The --quiet flag is useful when gnmic exports the received data to one of the export providers.","title":"quiet"},{"location":"cmd/subscribe/#suppress-redundant","text":"When the [--suppress-redundant] flag is set to true, the target SHOULD NOT generate a telemetry update message unless the value of the path being reported on has changed since the last update was generated. This flag applies only in case --mode is set to STREAM and --stream-mode is set to SAMPLE .","title":"suppress redundant"},{"location":"cmd/subscribe/#updates-only","text":"When the [--updates-only] flag is set to true, the target MUST not transmit the current state of the paths that the client has subscribed to, but rather should send only updates to them.","title":"updates only"},{"location":"cmd/subscribe/#name","text":"The [--name] flag is used to trigger one or multiple subscriptions already defined in the configuration file see defining subscriptions","title":"name"},{"location":"cmd/subscribe/#output","text":"The [--output] flag is used to select one or multiple output already defined in the configuration file. Outputs defined under target take precedence over this flag, see defining outputs and defining targets","title":"output"},{"location":"cmd/subscribe/#watch-config","text":"The [--watch-config] flag is used to enable automatic target loading from the configuration source at runtime. On each configuration change, gnmic reloads the list of targets, subscribes to new targets and/or deletes subscriptions to the deleted ones. Only addition and deletion of targets are currently supported, changes in an existing target config are not possible.","title":"watch-config"},{"location":"cmd/subscribe/#backoff","text":"The [--backoff] flag is used to specify a duration between consecutive subscription towards targets. It defaults to 0s meaning all subscription are started in parallel. If a locker is configured, the backoff timer is set to 100ms by default.","title":"backoff"},{"location":"cmd/subscribe/#lock-retry","text":"The [--lock-retry] flag is a duration used to set the wait time between consecutive lock attempts. Defaults to 5s .","title":"lock-retry"},{"location":"cmd/subscribe/#history-snapshot","text":"The [--history-snapshot] flag sets the snapshot value in the subscribe request gNMI History extension . The value can be either nanoseconds since Unix epoch or a date in RFC3339 format.","title":"history-snapshot"},{"location":"cmd/subscribe/#history-start","text":"The [--history-start] flag sets the start value in the subscribe request Time Range gNMI History extension . The value can be either nanoseconds since Unix epoch or a date in RFC3339 format.","title":"history-start"},{"location":"cmd/subscribe/#history-end","text":"The [--history-end] flag sets the end value in the subscribe request Time Range gNMI History extension .","title":"history-end"},{"location":"cmd/subscribe/#examples","text":"","title":"Examples"},{"location":"cmd/subscribe/#1-streaming-target-defined-10s-interval","text":"gnmic -a <ip:port> sub --path /state/port [ port-id = * ] /statistics","title":"1. streaming, target-defined, 10s interval"},{"location":"cmd/subscribe/#2-streaming-sample-30s-interval","text":"gnmic -a <ip:port> sub --path \"/state/port[port-id=*]/statistics\" \\ --sample-interval 30s","title":"2. streaming, sample, 30s interval"},{"location":"cmd/subscribe/#3-streaming-on-change-heartbeat-interval-1min","text":"gnmic -a <ip:port> sub --path \"/state/port[port-id=*]/statistics\" \\ --stream-mode on-change \\ --heartbeat-interval 1m","title":"3. streaming, on-change, heartbeat interval 1min"},{"location":"cmd/subscribe/#4-once-subscription","text":"gnmic -a <ip:port> sub --path \"/state/port[port-id=*]/statistics\" \\ --mode once","title":"4. once subscription"},{"location":"cmd/generate/generate_path/","text":"Description # The path sub command is an alias for the gnmic path command.","title":"Generate Path"},{"location":"cmd/generate/generate_path/#description","text":"The path sub command is an alias for the gnmic path command.","title":"Description"},{"location":"cmd/generate/generate_set_request/","text":"Description # The set-request sub command generates a Set request file given a list of update and/or replace paths. If no paths are supplied, a root ( / ) replace path is used as a default. The generated file can be manually edited and used with gnmic set command: gnmic set --request-file <path_to_generated_file> Aliases: sreq , srq , sr Usage # gnmic [global-flags] generate [generate-flags] set-request [sub-command-flags] Flags # update # The --update flag specifies a valid xpath, used to generate an updates section of the set request file . Multiple --update flags can be supplied. replace # The --replace flag specifies a valid xpath, used to generate a replaces section of the set request file . Multiple --replace flags can be supplied. Examples # Openconfig # YANG repo: openconfig/public Clone the OpenConfig repository: git clone https://github.com/openconfig/public cd public gnmic --encoding json_ietf \\ generate \\ --file release/models \\ --dir third_party \\ --exclude ietf-interfaces \\ set-request \\ --replace /interfaces/interface/subinterfaces/subinterface/ipv4/addresses/address The above command generates the below YAML output (JSON if --json flag is supplied) replaces : - path : /interfaces/interface/subinterfaces/subinterface/ipv4/addresses/address value : - config : ip : \"\" prefix-length : \"\" ip : \"\" vrrp : vrrp-group : - config : accept-mode : \"false\" advertisement-interval : \"100\" preempt : \"true\" preempt-delay : \"0\" priority : \"100\" virtual-address : \"\" virtual-router-id : \"\" interface-tracking : config : priority-decrement : \"0\" track-interface : \"\" virtual-router-id : \"\" encoding : JSON_IETF The value section can be filled with the desired configuration variables. Nokia SR OS # git clone https://github.com/nokia/7x50_YangModels cd 7x50_YangModels git checkout sros_21.2.r2 gnmic generate \\ --file YANG/nokia-combined \\ --dir YANG \\ set-request \\ --replace /configure/service/vprn/bgp/family The above command generates the below YAML output (JSON if --json flag is supplied) replaces : - path : /configure/service/vprn/bgp/family value : flow-ipv4 : \"false\" flow-ipv6 : \"false\" ipv4 : \"true\" ipv6 : \"false\" label-ipv4 : \"false\" mcast-ipv4 : \"false\" mcast-ipv6 : \"false\" Cisco # YANG repo: YangModels/yang Clone the YangModels/yang repo and change into the main directory of the repo: git clone https://github.com/YangModels/yang cd yang/vendor gnmic --encoding json_ietf \\ generate \\ --file vendor/cisco/xr/721/Cisco-IOS-XR-um-router-bgp-cfg.yang \\ --file vendor/cisco/xr/721/Cisco-IOS-XR-ipv4-bgp-oper.yang \\ --dir standard/ietf \\ set-request \\ --path /active-nodes The above command generates the below YAML output (JSON if --json flag is supplied) replaces : - path : /active-nodes value : active-node : - node-name : \"\" selective-vrf-download : role : address-family : ipv4 : unicast : \"\" ipv6 : unicast : \"\" vrf-groups : vrf-group : - vrf-group-name : \"\" encoding : JSON_IETF Juniper # YANG repo: Juniper/yang Clone the Juniper YANG repository and change into the release directory: git clone https://github.com/Juniper/yang cd yang/20.3/20.3R1 gnmic --encoding json_ietf \\ generate --file junos/conf \\ --dir common set-request \\ --replace /configuration/interfaces/interface/unit/family/inet/address The above command generates the below YAML output (JSON if --json flag is supplied) replaces : - path : /configuration/interfaces/interface/unit/family/inet/address value : - apply-groups : \"\" apply-groups-except : \"\" apply-macro : - data : - name : \"\" value : \"\" name : \"\" arp : - case_1 : \"\" case_2 : \"\" l2-interface : \"\" name : \"\" publish : \"\" broadcast : \"\" destination : \"\" destination-profile : \"\" master-only : \"\" multipoint-destination : - apply-groups : \"\" apply-groups-except : \"\" apply-macro : - data : - name : \"\" value : \"\" name : \"\" case_1 : \"\" case_2 : \"\" epd-threshold : apply-groups : \"\" apply-groups-except : \"\" apply-macro : - data : - name : \"\" value : \"\" name : \"\" epd-threshold-plp0 : \"\" plp1 : \"\" inverse-arp : \"\" name : \"\" oam-liveness : apply-groups : \"\" apply-groups-except : \"\" apply-macro : - data : - name : \"\" value : \"\" name : \"\" down-count : \"\" up-count : \"\" oam-period : disable : {} oam_period : \"\" shaping : apply-groups : \"\" apply-groups-except : \"\" apply-macro : - data : - name : \"\" value : \"\" name : \"\" cbr : cbr-value : \"\" cdvt : \"\" queue-length : \"\" rtvbr : burst : \"\" cdvt : \"\" peak : \"\" sustained : \"\" vbr : burst : \"\" cdvt : \"\" peak : \"\" sustained : \"\" transmit-weight : \"\" name : \"\" preferred : \"\" primary : \"\" virtual-gateway-address : \"\" vrrp-group : - advertisements-threshold : \"\" apply-groups : \"\" apply-groups-except : \"\" apply-macro : - data : - name : \"\" value : \"\" name : \"\" authentication-key : \"\" authentication-type : \"\" case_1 : \"\" case_2 : \"\" case_3 : \"\" name : \"\" preferred : \"\" priority : \"\" track : apply-groups : \"\" apply-groups-except : \"\" apply-macro : - data : - name : \"\" value : \"\" name : \"\" interface : - apply-groups : \"\" apply-groups-except : \"\" apply-macro : - data : - name : \"\" value : \"\" name : \"\" bandwidth-threshold : - name : \"\" priority-cost : \"\" name : \"\" priority-cost : \"\" priority-hold-time : \"\" route : - priority-cost : \"\" route_address : \"\" routing-instance : \"\" virtual-link-local-address : \"\" vrrp-inherit-from : active-group : \"\" active-interface : \"\" apply-groups : \"\" apply-groups-except : \"\" apply-macro : - data : - name : \"\" value : \"\" name : \"\" web-authentication : apply-groups : \"\" apply-groups-except : \"\" apply-macro : - data : - name : \"\" value : \"\" name : \"\" http : \"\" https : \"\" redirect-to-https : \"\" encoding : JSON_IETF Arista # YANG repo: aristanetworks/yang Arista uses a subset of OpenConfig modules and does not provide IETF modules inside their repo. So make sure you have IETF models available so you can reference it, a openconfig/public is a good candidate. Clone the Arista YANG repo: git clone https://github.com/aristanetworks/yang cd yang The above command generates the below YAML output (JSON if --json flag is supplied) gnmic --encoding json_ietf \\ generate --file EOS-4.23.2F/openconfig/public/release/models \\ --dir ../openconfig/public/third_party/ietf \\ --exclude ietf-interfaces \\ set-request \\ --replace bgp/neighbors/neighbor/config replaces : - path : bgp/neighbors/neighbor/config value : auth-password : \"\" description : \"\" enabled : \"true\" local-as : \"\" neighbor-address : \"\" peer-as : \"\" peer-group : \"\" peer-type : \"\" remove-private-as : \"\" route-flap-damping : \"false\" send-community : NONE","title":"Generate Set-Request"},{"location":"cmd/generate/generate_set_request/#description","text":"The set-request sub command generates a Set request file given a list of update and/or replace paths. If no paths are supplied, a root ( / ) replace path is used as a default. The generated file can be manually edited and used with gnmic set command: gnmic set --request-file <path_to_generated_file> Aliases: sreq , srq , sr","title":"Description"},{"location":"cmd/generate/generate_set_request/#usage","text":"gnmic [global-flags] generate [generate-flags] set-request [sub-command-flags]","title":"Usage"},{"location":"cmd/generate/generate_set_request/#flags","text":"","title":"Flags"},{"location":"cmd/generate/generate_set_request/#update","text":"The --update flag specifies a valid xpath, used to generate an updates section of the set request file . Multiple --update flags can be supplied.","title":"update"},{"location":"cmd/generate/generate_set_request/#replace","text":"The --replace flag specifies a valid xpath, used to generate a replaces section of the set request file . Multiple --replace flags can be supplied.","title":"replace"},{"location":"cmd/generate/generate_set_request/#examples","text":"","title":"Examples"},{"location":"cmd/generate/generate_set_request/#openconfig","text":"YANG repo: openconfig/public Clone the OpenConfig repository: git clone https://github.com/openconfig/public cd public gnmic --encoding json_ietf \\ generate \\ --file release/models \\ --dir third_party \\ --exclude ietf-interfaces \\ set-request \\ --replace /interfaces/interface/subinterfaces/subinterface/ipv4/addresses/address The above command generates the below YAML output (JSON if --json flag is supplied) replaces : - path : /interfaces/interface/subinterfaces/subinterface/ipv4/addresses/address value : - config : ip : \"\" prefix-length : \"\" ip : \"\" vrrp : vrrp-group : - config : accept-mode : \"false\" advertisement-interval : \"100\" preempt : \"true\" preempt-delay : \"0\" priority : \"100\" virtual-address : \"\" virtual-router-id : \"\" interface-tracking : config : priority-decrement : \"0\" track-interface : \"\" virtual-router-id : \"\" encoding : JSON_IETF The value section can be filled with the desired configuration variables.","title":"Openconfig"},{"location":"cmd/generate/generate_set_request/#nokia-sr-os","text":"git clone https://github.com/nokia/7x50_YangModels cd 7x50_YangModels git checkout sros_21.2.r2 gnmic generate \\ --file YANG/nokia-combined \\ --dir YANG \\ set-request \\ --replace /configure/service/vprn/bgp/family The above command generates the below YAML output (JSON if --json flag is supplied) replaces : - path : /configure/service/vprn/bgp/family value : flow-ipv4 : \"false\" flow-ipv6 : \"false\" ipv4 : \"true\" ipv6 : \"false\" label-ipv4 : \"false\" mcast-ipv4 : \"false\" mcast-ipv6 : \"false\"","title":"Nokia SR OS"},{"location":"cmd/generate/generate_set_request/#cisco","text":"YANG repo: YangModels/yang Clone the YangModels/yang repo and change into the main directory of the repo: git clone https://github.com/YangModels/yang cd yang/vendor gnmic --encoding json_ietf \\ generate \\ --file vendor/cisco/xr/721/Cisco-IOS-XR-um-router-bgp-cfg.yang \\ --file vendor/cisco/xr/721/Cisco-IOS-XR-ipv4-bgp-oper.yang \\ --dir standard/ietf \\ set-request \\ --path /active-nodes The above command generates the below YAML output (JSON if --json flag is supplied) replaces : - path : /active-nodes value : active-node : - node-name : \"\" selective-vrf-download : role : address-family : ipv4 : unicast : \"\" ipv6 : unicast : \"\" vrf-groups : vrf-group : - vrf-group-name : \"\" encoding : JSON_IETF","title":"Cisco"},{"location":"cmd/generate/generate_set_request/#juniper","text":"YANG repo: Juniper/yang Clone the Juniper YANG repository and change into the release directory: git clone https://github.com/Juniper/yang cd yang/20.3/20.3R1 gnmic --encoding json_ietf \\ generate --file junos/conf \\ --dir common set-request \\ --replace /configuration/interfaces/interface/unit/family/inet/address The above command generates the below YAML output (JSON if --json flag is supplied) replaces : - path : /configuration/interfaces/interface/unit/family/inet/address value : - apply-groups : \"\" apply-groups-except : \"\" apply-macro : - data : - name : \"\" value : \"\" name : \"\" arp : - case_1 : \"\" case_2 : \"\" l2-interface : \"\" name : \"\" publish : \"\" broadcast : \"\" destination : \"\" destination-profile : \"\" master-only : \"\" multipoint-destination : - apply-groups : \"\" apply-groups-except : \"\" apply-macro : - data : - name : \"\" value : \"\" name : \"\" case_1 : \"\" case_2 : \"\" epd-threshold : apply-groups : \"\" apply-groups-except : \"\" apply-macro : - data : - name : \"\" value : \"\" name : \"\" epd-threshold-plp0 : \"\" plp1 : \"\" inverse-arp : \"\" name : \"\" oam-liveness : apply-groups : \"\" apply-groups-except : \"\" apply-macro : - data : - name : \"\" value : \"\" name : \"\" down-count : \"\" up-count : \"\" oam-period : disable : {} oam_period : \"\" shaping : apply-groups : \"\" apply-groups-except : \"\" apply-macro : - data : - name : \"\" value : \"\" name : \"\" cbr : cbr-value : \"\" cdvt : \"\" queue-length : \"\" rtvbr : burst : \"\" cdvt : \"\" peak : \"\" sustained : \"\" vbr : burst : \"\" cdvt : \"\" peak : \"\" sustained : \"\" transmit-weight : \"\" name : \"\" preferred : \"\" primary : \"\" virtual-gateway-address : \"\" vrrp-group : - advertisements-threshold : \"\" apply-groups : \"\" apply-groups-except : \"\" apply-macro : - data : - name : \"\" value : \"\" name : \"\" authentication-key : \"\" authentication-type : \"\" case_1 : \"\" case_2 : \"\" case_3 : \"\" name : \"\" preferred : \"\" priority : \"\" track : apply-groups : \"\" apply-groups-except : \"\" apply-macro : - data : - name : \"\" value : \"\" name : \"\" interface : - apply-groups : \"\" apply-groups-except : \"\" apply-macro : - data : - name : \"\" value : \"\" name : \"\" bandwidth-threshold : - name : \"\" priority-cost : \"\" name : \"\" priority-cost : \"\" priority-hold-time : \"\" route : - priority-cost : \"\" route_address : \"\" routing-instance : \"\" virtual-link-local-address : \"\" vrrp-inherit-from : active-group : \"\" active-interface : \"\" apply-groups : \"\" apply-groups-except : \"\" apply-macro : - data : - name : \"\" value : \"\" name : \"\" web-authentication : apply-groups : \"\" apply-groups-except : \"\" apply-macro : - data : - name : \"\" value : \"\" name : \"\" http : \"\" https : \"\" redirect-to-https : \"\" encoding : JSON_IETF","title":"Juniper"},{"location":"cmd/generate/generate_set_request/#arista","text":"YANG repo: aristanetworks/yang Arista uses a subset of OpenConfig modules and does not provide IETF modules inside their repo. So make sure you have IETF models available so you can reference it, a openconfig/public is a good candidate. Clone the Arista YANG repo: git clone https://github.com/aristanetworks/yang cd yang The above command generates the below YAML output (JSON if --json flag is supplied) gnmic --encoding json_ietf \\ generate --file EOS-4.23.2F/openconfig/public/release/models \\ --dir ../openconfig/public/third_party/ietf \\ --exclude ietf-interfaces \\ set-request \\ --replace bgp/neighbors/neighbor/config replaces : - path : bgp/neighbors/neighbor/config value : auth-password : \"\" description : \"\" enabled : \"true\" local-as : \"\" neighbor-address : \"\" peer-as : \"\" peer-group : \"\" peer-type : \"\" remove-private-as : \"\" route-flap-damping : \"false\" send-community : NONE","title":"Arista"},{"location":"deployments/deployments_intro/","text":"There are numerous ways gnmic can be deployed, each fulfilling a specific use case. Whether it is gNMI telemetry collection and export to a single output, or clustered data pipelines with high availability and redundancy, the below examples should cover the most common use cases. In this section you will find multiple deployment examples, using docker-compose or containerlab . Each deployment comes with: a docker-compose or clab file one or multiple gnmic configuration file(s) extra configuration files if required by the use case (e.g: prometheus, grafana,...) The containerlab examples come with a fabric deployed using Nokia's SR Linux If you don't find an example that fits your needs, feel free to start a discussion on github Single Instance # These examples showcase single gnmic instance deployments with the most commonly used outputs NATS output: clab , docker-compose Kafka output: clab , docker-compose InfluxDB output: clab , docker-compose Prometheus output: clab , docker-compose Multiple outputs: clab , docker-compose Clusters # gnmic can also be deployed in clustered mode to either load share the targets connections between multiple instances and offer connection resiliency, and/or replicate the collected data among all the cluster members InfluxDB output: clab , docker-compose Prometheus output: clab , docker-compose Prometheus output with data replication: clab , docker-compose Pipelines # Building data pipelines using gnmic is achieved using the outputs and inputs plugins. You will be able to process the data in a serial fashion, split it for parallel processing or mirror it to create a forked pipeline. NATS to Prometheus: docker-compose NATS to InfluxDB: docker-compose Clustered pipeline: docker-compose Forked pipeline: docker-compose","title":"Deployments"},{"location":"deployments/deployments_intro/#single-instance","text":"These examples showcase single gnmic instance deployments with the most commonly used outputs NATS output: clab , docker-compose Kafka output: clab , docker-compose InfluxDB output: clab , docker-compose Prometheus output: clab , docker-compose Multiple outputs: clab , docker-compose","title":"Single Instance"},{"location":"deployments/deployments_intro/#clusters","text":"gnmic can also be deployed in clustered mode to either load share the targets connections between multiple instances and offer connection resiliency, and/or replicate the collected data among all the cluster members InfluxDB output: clab , docker-compose Prometheus output: clab , docker-compose Prometheus output with data replication: clab , docker-compose","title":"Clusters"},{"location":"deployments/deployments_intro/#pipelines","text":"Building data pipelines using gnmic is achieved using the outputs and inputs plugins. You will be able to process the data in a serial fashion, split it for parallel processing or mirror it to create a forked pipeline. NATS to Prometheus: docker-compose NATS to InfluxDB: docker-compose Clustered pipeline: docker-compose Forked pipeline: docker-compose","title":"Pipelines"},{"location":"deployments/clusters/containerlab/cluster_with_gnmi_server_and_prometheus_output/","text":"The purpose of this deployment is to achieve redundancy , high-availability and data aggregation via clustering. This deployment example includes: A 3 instances gNMIc cluster , A standalone gNMIc instance. A Prometheus Server A Grafana Server A Consul Server The leader election and target distribution is done with the help of a Consul server All members of the cluster expose a gNMI Server that the single gNMIc instance will use to aggregate the collected data. The aggregation gNMIc instance exposes a Prometheus output that is registered in Consul and is discoverable by the Prometheus server. The whole lab is pretty much self organising: The gNMIc cluster instances discover the targets dynamically using a Docker Loader The gNMIc standalone instance, discovers the cluster instance using a Consul Loader The Prometheus server discovers gNMIc's Prometheus output using Consul Service Discovery Deployment files: containerlab gNMIc cluster config gNMIc aggregator config Prometheus config Grafana datasource Deploy it with: git clone https://github.com/karimra/gnmic.git cd gnmic/examples/deployments/2.clusters/4.gnmi-server/containerlab sudo clab deploy -t gnmi-server.clab.yaml +----+-------------------------+--------------+------------------------------+-------+-------+---------+-----------------+-----------------------+ | # | Name | Container ID | Image | Kind | Group | State | IPv4 Address | IPv6 Address | +----+-------------------------+--------------+------------------------------+-------+-------+---------+-----------------+-----------------------+ | 1 | clab-lab24-agg-gnmic | 2e9cc2821b07 | ghcr.io/karimra/gnmic:latest | linux | | running | 172.20.20.7/24 | 2001:172:20:20::7/64 | | 2 | clab-lab24-consul-agent | c17d31d5f41b | consul:latest | linux | | running | 172.20.20.2/24 | 2001:172:20:20::2/64 | | 3 | clab-lab24-gnmic1 | 3d56e09955f2 | ghcr.io/karimra/gnmic:latest | linux | | running | 172.20.20.4/24 | 2001:172:20:20::4/64 | | 4 | clab-lab24-gnmic2 | eba24dacea36 | ghcr.io/karimra/gnmic:latest | linux | | running | 172.20.20.3/24 | 2001:172:20:20::3/64 | | 5 | clab-lab24-gnmic3 | caf473f500f6 | ghcr.io/karimra/gnmic:latest | linux | | running | 172.20.20.6/24 | 2001:172:20:20::6/64 | | 6 | clab-lab24-grafana | eaa224e62243 | grafana/grafana:latest | linux | | running | 172.20.20.8/24 | 2001:172:20:20::8/64 | | 7 | clab-lab24-leaf1 | 6771dc8d3786 | ghcr.io/nokia/srlinux | srl | | running | 172.20.20.10/24 | 2001:172:20:20::a/64 | | 8 | clab-lab24-leaf2 | 5cfb1cf68958 | ghcr.io/nokia/srlinux | srl | | running | 172.20.20.14/24 | 2001:172:20:20::e/64 | | 9 | clab-lab24-leaf3 | c438f734e44d | ghcr.io/nokia/srlinux | srl | | running | 172.20.20.19/24 | 2001:172:20:20::13/64 | | 10 | clab-lab24-leaf4 | ae4321825a03 | ghcr.io/nokia/srlinux | srl | | running | 172.20.20.17/24 | 2001:172:20:20::11/64 | | 11 | clab-lab24-leaf5 | ee7a520fd844 | ghcr.io/nokia/srlinux | srl | | running | 172.20.20.18/24 | 2001:172:20:20::12/64 | | 12 | clab-lab24-leaf6 | 59c3c515ef35 | ghcr.io/nokia/srlinux | srl | | running | 172.20.20.9/24 | 2001:172:20:20::9/64 | | 13 | clab-lab24-leaf7 | 111f858b19fd | ghcr.io/nokia/srlinux | srl | | running | 172.20.20.22/24 | 2001:172:20:20::16/64 | | 14 | clab-lab24-leaf8 | 0ecc69891eb4 | ghcr.io/nokia/srlinux | srl | | running | 172.20.20.20/24 | 2001:172:20:20::14/64 | | 15 | clab-lab24-prometheus | 357821ec726e | prom/prometheus:latest | linux | | running | 172.20.20.5/24 | 2001:172:20:20::5/64 | | 16 | clab-lab24-spine1 | 0f5f6f6dc5fa | ghcr.io/nokia/srlinux | srl | | running | 172.20.20.13/24 | 2001:172:20:20::d/64 | | 17 | clab-lab24-spine2 | b718503d3b3f | ghcr.io/nokia/srlinux | srl | | running | 172.20.20.15/24 | 2001:172:20:20::f/64 | | 18 | clab-lab24-spine3 | e02f18d0e3ff | ghcr.io/nokia/srlinux | srl | | running | 172.20.20.11/24 | 2001:172:20:20::b/64 | | 19 | clab-lab24-spine4 | 3347cba3f277 | ghcr.io/nokia/srlinux | srl | | running | 172.20.20.12/24 | 2001:172:20:20::c/64 | | 20 | clab-lab24-super-spine1 | 4abc7bcaf43c | ghcr.io/nokia/srlinux | srl | | running | 172.20.20.16/24 | 2001:172:20:20::10/64 | | 21 | clab-lab24-super-spine2 | 5b2f5f153d43 | ghcr.io/nokia/srlinux | srl | | running | 172.20.20.21/24 | 2001:172:20:20::15/64 | +----+-------------------------+--------------+------------------------------+-------+-------+---------+-----------------+-----------------------+ Check the Prometheus Output and gNMI Server documentation pages for more configuration options","title":"Containerlab"},{"location":"deployments/clusters/containerlab/cluster_with_influxdb_output/","text":"The purpose of this deployment is to achieve redundancy , high-availability via clustering. This deployment example includes: A 3 instances gNMIc cluster , A InfluxDB Server A Grafana Server A Consul Server The leader election and target distribution is done with the help of a Consul server Deployment files: containerlab gNMIc config Grafana datasource Deploy it with: git clone https://github.com/karimra/gnmic.git cd gnmic/examples/deployments/2.clusters/1.influxdb-output/containerlab sudo clab deploy -t lab21.clab.yaml +----+-------------------------+--------------+------------------------------+-------+-------+---------+-----------------+-----------------------+ | # | Name | Container ID | Image | Kind | Group | State | IPv4 Address | IPv6 Address | +----+-------------------------+--------------+------------------------------+-------+-------+---------+-----------------+-----------------------+ | 1 | clab-lab21-consul-agent | a6f6eb70965f | consul:latest | linux | | running | 172.20.20.7/24 | 2001:172:20:20::7/64 | | 2 | clab-lab21-gnmic1 | 9758b0761431 | ghcr.io/karimra/gnmic:latest | linux | | running | 172.20.20.5/24 | 2001:172:20:20::5/64 | | 3 | clab-lab21-gnmic2 | 6d6ae91c64bf | ghcr.io/karimra/gnmic:latest | linux | | running | 172.20.20.2/24 | 2001:172:20:20::2/64 | | 4 | clab-lab21-gnmic3 | 5df100a9fa73 | ghcr.io/karimra/gnmic:latest | linux | | running | 172.20.20.4/24 | 2001:172:20:20::4/64 | | 5 | clab-lab21-grafana | fe51bda1830c | grafana/grafana:latest | linux | | running | 172.20.20.3/24 | 2001:172:20:20::3/64 | | 6 | clab-lab21-influxdb | 20712484d835 | influxdb:latest | linux | | running | 172.20.20.6/24 | 2001:172:20:20::6/64 | | 7 | clab-lab21-leaf1 | ce084f636942 | ghcr.io/nokia/srlinux | srl | | running | 172.20.20.14/24 | 2001:172:20:20::e/64 | | 8 | clab-lab21-leaf2 | 5cbaba4bc9ff | ghcr.io/nokia/srlinux | srl | | running | 172.20.20.11/24 | 2001:172:20:20::b/64 | | 9 | clab-lab21-leaf3 | a5e92ca08c7e | ghcr.io/nokia/srlinux | srl | | running | 172.20.20.8/24 | 2001:172:20:20::8/64 | | 10 | clab-lab21-leaf4 | 1ccfe0082b15 | ghcr.io/nokia/srlinux | srl | | running | 172.20.20.12/24 | 2001:172:20:20::c/64 | | 11 | clab-lab21-leaf5 | 7fd4144277a0 | ghcr.io/nokia/srlinux | srl | | running | 172.20.20.9/24 | 2001:172:20:20::9/64 | | 12 | clab-lab21-leaf6 | cb4df0d609db | ghcr.io/nokia/srlinux | srl | | running | 172.20.20.13/24 | 2001:172:20:20::d/64 | | 13 | clab-lab21-leaf7 | 8f09b622365f | ghcr.io/nokia/srlinux | srl | | running | 172.20.20.19/24 | 2001:172:20:20::13/64 | | 14 | clab-lab21-leaf8 | 0ab91010b4a7 | ghcr.io/nokia/srlinux | srl | | running | 172.20.20.18/24 | 2001:172:20:20::12/64 | | 15 | clab-lab21-spine1 | 86d00f11b944 | ghcr.io/nokia/srlinux | srl | | running | 172.20.20.15/24 | 2001:172:20:20::f/64 | | 16 | clab-lab21-spine2 | 90cf49595ad2 | ghcr.io/nokia/srlinux | srl | | running | 172.20.20.20/24 | 2001:172:20:20::14/64 | | 17 | clab-lab21-spine3 | 1c694820eb88 | ghcr.io/nokia/srlinux | srl | | running | 172.20.20.16/24 | 2001:172:20:20::10/64 | | 18 | clab-lab21-spine4 | 1e3eac3de55f | ghcr.io/nokia/srlinux | srl | | running | 172.20.20.10/24 | 2001:172:20:20::a/64 | | 19 | clab-lab21-super-spine1 | aafc478de31d | ghcr.io/nokia/srlinux | srl | | running | 172.20.20.21/24 | 2001:172:20:20::15/64 | | 20 | clab-lab21-super-spine2 | bb27b743c97f | ghcr.io/nokia/srlinux | srl | | running | 172.20.20.17/24 | 2001:172:20:20::11/64 | +----+-------------------------+--------------+------------------------------+-------+-------+---------+-----------------+-----------------------+ Check the InfluxDB Output documentation page for more configuration options.","title":"Containerlab"},{"location":"deployments/clusters/containerlab/cluster_with_nats_input_and_prometheus_output/","text":"The purpose of this deployment is to achieve redundancy , high-availability as well as data replication . The redundancy and high-availability are guaranteed by deploying a gnmic cluster. The data replication is achieved using a NATS server acting as both a gnmic input and output. This deployment example includes a: 3 instances gNMIc cluster , A NATS Server acting as both input and output A Prometheus Server A Grafana Server A Consul Server The leader election and target distribution is done with the help of a Consul server Each gnmic instance outputs the streamed gNMI data to NATS, and reads back all the data from the same NATS server (including its own), This effectively guarantees that each instance holds the data streamed by the whole cluster. Like in the previous examples, each gnmic instance will also register its Prometheus output service in Consul . But before doing so, it will attempt to acquire a key lock gnmic/$CLUSTER_NAME/prometheus-output , ( use-lock: true ) prom-output : type : prometheus listen : \":9804\" service-registration : address : consul-agent:8500 use-lock : true # <=== Since only one instance can hold a lock, only one prometheus output is registered, so only one output is scraped by Prometheus. Deployment files: containerlab gNMIc config prometheus config Grafana datasource Deploy it with: git clone https://github.com/karimra/gnmic.git cd gnmic/examples/deployments/2.clusters/3.nats-input-prometheus-output/containerlab sudo clab deploy -t lab23.clab.yaml +----+-------------------------+--------------+------------------------------+-------+-------+---------+-----------------+-----------------------+ | # | Name | Container ID | Image | Kind | Group | State | IPv4 Address | IPv6 Address | +----+-------------------------+--------------+------------------------------+-------+-------+---------+-----------------+-----------------------+ | 1 | clab-lab23-consul-agent | cfdaf19e9435 | consul:latest | linux | | running | 172.20.20.8/24 | 2001:172:20:20::8/64 | | 2 | clab-lab23-gnmic1 | 7e2a4060a1ae | ghcr.io/karimra/gnmic:latest | linux | | running | 172.20.20.3/24 | 2001:172:20:20::3/64 | | 3 | clab-lab23-gnmic2 | 9e27e4620104 | ghcr.io/karimra/gnmic:latest | linux | | running | 172.20.20.4/24 | 2001:172:20:20::4/64 | | 4 | clab-lab23-gnmic3 | bb7471eb5f49 | ghcr.io/karimra/gnmic:latest | linux | | running | 172.20.20.5/24 | 2001:172:20:20::5/64 | | 5 | clab-lab23-grafana | 3fbf7755c49e | grafana/grafana:latest | linux | | running | 172.20.20.2/24 | 2001:172:20:20::2/64 | | 6 | clab-lab23-leaf1 | a61624d5312b | ghcr.io/nokia/srlinux | srl | | running | 172.20.20.21/24 | 2001:172:20:20::15/64 | | 7 | clab-lab23-leaf2 | ef86f701b379 | ghcr.io/nokia/srlinux | srl | | running | 172.20.20.14/24 | 2001:172:20:20::e/64 | | 8 | clab-lab23-leaf3 | 352433a2ab3b | ghcr.io/nokia/srlinux | srl | | running | 172.20.20.22/24 | 2001:172:20:20::16/64 | | 9 | clab-lab23-leaf4 | 5ddba813d36f | ghcr.io/nokia/srlinux | srl | | running | 172.20.20.19/24 | 2001:172:20:20::13/64 | | 10 | clab-lab23-leaf5 | aad20f4b9969 | ghcr.io/nokia/srlinux | srl | | running | 172.20.20.11/24 | 2001:172:20:20::b/64 | | 11 | clab-lab23-leaf6 | 757c76527a75 | ghcr.io/nokia/srlinux | srl | | running | 172.20.20.15/24 | 2001:172:20:20::f/64 | | 12 | clab-lab23-leaf7 | d85e94aaa0dd | ghcr.io/nokia/srlinux | srl | | running | 172.20.20.10/24 | 2001:172:20:20::a/64 | | 13 | clab-lab23-leaf8 | ef6210c0e5aa | ghcr.io/nokia/srlinux | srl | | running | 172.20.20.20/24 | 2001:172:20:20::14/64 | | 14 | clab-lab23-nats | f1a1f351bbf8 | nats:latest | linux | | running | 172.20.20.6/24 | 2001:172:20:20::6/64 | | 15 | clab-lab23-prometheus | f7f194a934c5 | prom/prometheus:latest | linux | | running | 172.20.20.7/24 | 2001:172:20:20::7/64 | | 16 | clab-lab23-spine1 | ddbf4e804097 | ghcr.io/nokia/srlinux | srl | | running | 172.20.20.16/24 | 2001:172:20:20::10/64 | | 17 | clab-lab23-spine2 | f48323a4de88 | ghcr.io/nokia/srlinux | srl | | running | 172.20.20.17/24 | 2001:172:20:20::11/64 | | 18 | clab-lab23-spine3 | 2a65eed26a7e | ghcr.io/nokia/srlinux | srl | | running | 172.20.20.18/24 | 2001:172:20:20::12/64 | | 19 | clab-lab23-spine4 | ea59d0e5d9ed | ghcr.io/nokia/srlinux | srl | | running | 172.20.20.12/24 | 2001:172:20:20::c/64 | | 20 | clab-lab23-super-spine1 | 37af6cd04dd8 | ghcr.io/nokia/srlinux | srl | | running | 172.20.20.9/24 | 2001:172:20:20::9/64 | | 21 | clab-lab23-super-spine2 | 3408891a0718 | ghcr.io/nokia/srlinux | srl | | running | 172.20.20.13/24 | 2001:172:20:20::d/64 | +----+-------------------------+--------------+------------------------------+-------+-------+---------+-----------------+-----------------------+ Check the NATS Output , NATS Input and Prometheus Output documentation pages for more configuration options.","title":"Containerlab"},{"location":"deployments/clusters/containerlab/cluster_with_prometheus_output/","text":"The purpose of this deployment is to achieve redundancy , high-availability via clustering. This deployment example includes: A 3 instances gNMIc cluster , A Prometheus Server A Grafana Server A Consul Server The leader election and target distribution is done with the help of a Consul server gnmic will also register its Prometheus output service in Consul so that Prometheus can discover which Prometheus servers are available to be scraped. Deployment files: containerlab gNMIc config Prometheus config Grafana datasource Deploy it with: git clone https://github.com/karimra/gnmic.git cd gnmic/examples/deployments/2.clusters/2.prometheus-output/containerlab sudo clab deploy -t lab22.clab.yaml +----+-------------------------+--------------+------------------------------+-------+-------+---------+-----------------+-----------------------+ | # | Name | Container ID | Image | Kind | Group | State | IPv4 Address | IPv6 Address | +----+-------------------------+--------------+------------------------------+-------+-------+---------+-----------------+-----------------------+ | 1 | clab-lab22-consul-agent | 542169159f8b | consul:latest | linux | | running | 172.20.20.2/24 | 2001:172:20:20::2/64 | | 2 | clab-lab22-gnmic1 | c04b2b597e7a | ghcr.io/karimra/gnmic:latest | linux | | running | 172.20.20.4/24 | 2001:172:20:20::4/64 | | 3 | clab-lab22-gnmic2 | 49604280d82d | ghcr.io/karimra/gnmic:latest | linux | | running | 172.20.20.3/24 | 2001:172:20:20::3/64 | | 4 | clab-lab22-gnmic3 | 49e910460cad | ghcr.io/karimra/gnmic:latest | linux | | running | 172.20.20.5/24 | 2001:172:20:20::5/64 | | 5 | clab-lab22-grafana | c0a37b012d29 | grafana/grafana:latest | linux | | running | 172.20.20.7/24 | 2001:172:20:20::7/64 | | 6 | clab-lab22-leaf1 | c6429b499c11 | ghcr.io/nokia/srlinux | srl | | running | 172.20.20.19/24 | 2001:172:20:20::13/64 | | 7 | clab-lab22-leaf2 | 62f235b39a62 | ghcr.io/nokia/srlinux | srl | | running | 172.20.20.17/24 | 2001:172:20:20::11/64 | | 8 | clab-lab22-leaf3 | 78d3b4e62a6b | ghcr.io/nokia/srlinux | srl | | running | 172.20.20.11/24 | 2001:172:20:20::b/64 | | 9 | clab-lab22-leaf4 | 8c5d80b4d916 | ghcr.io/nokia/srlinux | srl | | running | 172.20.20.13/24 | 2001:172:20:20::d/64 | | 10 | clab-lab22-leaf5 | 508d4d2389b4 | ghcr.io/nokia/srlinux | srl | | running | 172.20.20.16/24 | 2001:172:20:20::10/64 | | 11 | clab-lab22-leaf6 | 14ce19a8c5da | ghcr.io/nokia/srlinux | srl | | running | 172.20.20.9/24 | 2001:172:20:20::9/64 | | 12 | clab-lab22-leaf7 | c4f6e586baa3 | ghcr.io/nokia/srlinux | srl | | running | 172.20.20.20/24 | 2001:172:20:20::14/64 | | 13 | clab-lab22-leaf8 | 1e00e6346bf1 | ghcr.io/nokia/srlinux | srl | | running | 172.20.20.12/24 | 2001:172:20:20::c/64 | | 14 | clab-lab22-prometheus | 5ed38ce63113 | prom/prometheus:latest | linux | | running | 172.20.20.6/24 | 2001:172:20:20::6/64 | | 15 | clab-lab22-spine1 | 38247b0f81e7 | ghcr.io/nokia/srlinux | srl | | running | 172.20.20.10/24 | 2001:172:20:20::a/64 | | 16 | clab-lab22-spine2 | 76bf66748acd | ghcr.io/nokia/srlinux | srl | | running | 172.20.20.21/24 | 2001:172:20:20::15/64 | | 17 | clab-lab22-spine3 | 5c8776e2fc77 | ghcr.io/nokia/srlinux | srl | | running | 172.20.20.15/24 | 2001:172:20:20::f/64 | | 18 | clab-lab22-spine4 | de67e5b92f36 | ghcr.io/nokia/srlinux | srl | | running | 172.20.20.14/24 | 2001:172:20:20::e/64 | | 19 | clab-lab22-super-spine1 | 00f0aee0265a | ghcr.io/nokia/srlinux | srl | | running | 172.20.20.18/24 | 2001:172:20:20::12/64 | | 20 | clab-lab22-super-spine2 | 418888eb7325 | ghcr.io/nokia/srlinux | srl | | running | 172.20.20.8/24 | 2001:172:20:20::8/64 | +----+-------------------------+--------------+------------------------------+-------+-------+---------+-----------------+-----------------------+ Check the Prometheus Output documentation page for more configuration options.","title":"Containerlab"},{"location":"deployments/clusters/docker-compose/cluster_with_influxdb_output/","text":"The purpose of this deployment is to achieve redundancy , high-availability via clustering. This deployment example includes: A 3 instances gnmic cluster , A single InfluxDB output The leader election and target distribution is done with the help of a Consul server Deployment files: Docker Compose gNMIc config Download the files, update the gnmic config files with the desired subscriptions and targets. Deploy it with: sudo docker-compose up -d Check the InfluxDB Output documentation page for more configuration options.","title":"Docker Compose"},{"location":"deployments/clusters/docker-compose/cluster_with_nats_input_and_prometheus_output/","text":"The purpose of this deployment is to achieve redundancy , high-availability as well as data replication . The redundancy and high-availability are guaranteed by deploying a gnmic cluster. The data replication is achieved using a NATS server acting as both a gnmic input and output. This deployment example includes a: 3 instances gnmic cluster , A NATS input and output A Prometheus output The leader election and target distribution is done with the help of a Consul server Each gnmic instance outputs the streamed gNMI data to NATS, and reads back all the data from the same NATS server (including its own), This effectively guarantees that each instance holds the data streamed by the whole cluster. Like in the previous examples, each gnmic instance will also register its Prometheus output service in Consul . But before doing so, it will attempt to acquire a key lock gnmic/$CLUSTER_NAME/prometheus-output , ( use-lock: true ) prom-output : type : prometheus listen : \":9804\" service-registration : address : consul-agent:8500 use-lock : true # <=== Since only one instance can hold a lock, only one prometheus output is registered, so only one output is scraped by Prometheus. Deployment files: Docker Compose gNMIc config Prometheus config Download the files, update the gnmic config files with the desired subscriptions and targets. Note The targets outputs list should include the nats output name Deploy it with: sudo docker-compose up -d Check the NATS Output , NATS Input and Prometheus Output documentation pages for more configuration options.","title":"Docker Compose"},{"location":"deployments/clusters/docker-compose/cluster_with_prometheus_output/","text":"The purpose of this deployment is to achieve redundancy , high-availability via clustering. This deployment example includes: A 3 instances gnmic cluster , A single Prometheus output The leader election and target distribution is done with the help of a Consul server gnmic will also register its Prometheus output service in Consul so that Prometheus can discover which Prometheus servers are available to be scraped Deployment files: Docker Compose gNMIc config Prometheus config Download the files, update the gnmic config files with the desired subscriptions and targets. Deploy it with: sudo docker-compose up -d Check the Prometheus Output documentation page for more configuration options.","title":"Docker Compose"},{"location":"deployments/clusters/kubernetes/cluster_with_prometheus_output/","text":"The purpose of this deployment is to achieve redundancy , high-availability using Kubernetes and gnmic 's internal clustering mechanism. This deployment example includes: A 3 instances gnmic cluster , A single Prometheus output The leader election and target distribution is done with the help of a Consul server gnmic can be discovered by Prometheus using Kubernetes service discovery. Kubernetes uses a headless service with a StatefulSet to disable the internal load balancing across multiple pods of the same StatefulSet and allow Prometheus to discover all instances of gnmic . Prometheus Operator must be installed prior to gnmic deployment. (Can also be installed via kube-prometheus-stack helm chart or kube-prometheus ) Deployment files: gnmic consul prometheus servicemonitor Download the files, update the gnmic ConfigMap with the desired subscriptions and targets and make sure that prometheus servicemonitor is in a namespace or has a label that Prometheus operator is watching. Deploy it with: kubectl create ns gnmic kubectl apply -n gnmic -f kubernetes/consul kubectl apply -n gnmic -f kubernetes/gnmic-app # Before deploying the Prometheus ServiceMonitor # Install Prometheus operator or kube-prometheus or kube-prometheus-stack helm chart # Otherwise the command will fail kubectl apply -f kubernetes/prometheus Check the Prometheus Output documentation page for more configuration options.","title":"Kubernetes"},{"location":"deployments/pipelines/docker-compose/forked_pipeline/","text":"The purpose of this deployment is to create a forked data pipeline using NATS , Influxdb and Prometheus The example includes 3 gnmic instances. The first, called collector , is responsible for streaming the gNMI data from the targets and output it to a NATS server. The second and third, called relay1 and relay2 , reads the data from NATS and writes it to either InfluxDB or Prometheus This deployment enables a few use cases: Apply different processors by the collector and relay. Scale the collector and relay separately, see this example for a scaled-out version. Fork the data into a separate pipeline for a different use case. Deployment files: docker compose gnmic collector config gnmic relay1 config gnmic relay2 config prometheus config Download the files, update the gnmic collector config files with the desired subscriptions and targets. Deploy it with: sudo docker-compose up -d Check the Prometheus Output and NATS Input documentation page for more configuration options","title":"Docker Compose"},{"location":"deployments/pipelines/docker-compose/gnmic_cluster_nats_prometheus/","text":"The purpose of this deployment is to create a clustered data pipeline using NATS and Prometheus . Achieving redundancy , high-availability and data replication , all in clustered data pipeline. The example is divided in 2 parts: Clustered collectors and single relay Clustered collectors and clustered relays These 2 examples are essentially scaled-out versions of this example Clustered collectors and single relay # Deployment files: docker compose gnmic collector config gnmic relay config prometheus config Download the files, update the gnmic collectors config files with the desired subscriptions and targets. Deploy it with: sudo docker-compose up -d Check the Prometheus Output and NATS Input documentation page for more configuration options Clustered collectors and clustered relays # Deployment files: docker compose gnmic collector config gnmic relay config prometheus config Download the files, update the gnmic collectors config files with the desired subscriptions and targets. Deploy it with: sudo docker-compose up -d Check the Prometheus Output and NATS Input documentation page for more configuration options","title":"Docker Compose"},{"location":"deployments/pipelines/docker-compose/gnmic_cluster_nats_prometheus/#clustered-collectors-and-single-relay","text":"Deployment files: docker compose gnmic collector config gnmic relay config prometheus config Download the files, update the gnmic collectors config files with the desired subscriptions and targets. Deploy it with: sudo docker-compose up -d Check the Prometheus Output and NATS Input documentation page for more configuration options","title":"Clustered collectors and single relay"},{"location":"deployments/pipelines/docker-compose/gnmic_cluster_nats_prometheus/#clustered-collectors-and-clustered-relays","text":"Deployment files: docker compose gnmic collector config gnmic relay config prometheus config Download the files, update the gnmic collectors config files with the desired subscriptions and targets. Deploy it with: sudo docker-compose up -d Check the Prometheus Output and NATS Input documentation page for more configuration options","title":"Clustered collectors and clustered relays"},{"location":"deployments/pipelines/docker-compose/nats_influxdb/","text":"The purpose of this deployment is to create data pipeline using NATS and InfluxDB The example includes 2 gnmic instances. The first, called collector , is responsible for streaming the gNMI data from the targets and output it to a NATS server. The second, called relay , reads the data from NATS and writes it to InfluxDB This deployment enables a few use cases: Apply different processors by the collector and relay. Scale the collector and relay separately, see this example for a scaled-out version. Fork the data into a separate pipeline for a different use case. Deployment files: docker compose gnmic collector config gnmic relay config Download the files, update the gnmic collector config files with the desired subscriptions and targets. Deploy it with: sudo docker-compose up -d Check the InfluxDB Output and NATS Input documentation page for more configuration options","title":"Docker Compose"},{"location":"deployments/pipelines/docker-compose/nats_prometheus/","text":"The purpose of this deployment is to create data pipeline using NATS and Prometheus The example includes 2 gnmic instances. The first, called collector , is responsible for streaming the gNMI data from the targets and output it to a NATS server. The second, called relay , reads the data from NATS and writes it to Prometheus This deployment enables a few use cases: Apply different processors by the collector and relay. Scale the collector and relay separately, see this example for a scaled-out version. Fork the data into a separate pipeline for a different use case. Deployment files: docker compose gnmic collector config gnmic relay config Download the files, update the gnmic collector config files with the desired subscriptions and targets. Deploy it with: sudo docker-compose up -d Check the Prometheus Output and NATS Input documentation page for more configuration options","title":"Docker Compose"},{"location":"deployments/single-instance/containerlab/influxdb-output/","text":"The purpose of this deployment is to collect gNMI data and write it to an InfluxDB instance. This deployment example includes a single gnmic instance, a single InfluxDB server acting as an InfluxDB output and a Grafana server Deployment files: containerlab gNMIc config Grafana datasource The deployed SR Linux nodes are discovered using Docker API and are loaded as gNMI targets. Edit the subscriptions section if needed. Deploy it with: git clone https://github.com/karimra/gnmic.git cd gnmic/examples/deployments/1.single-instance/3.influxdb-output/containerlab sudo clab deploy -t influxdb.clab.yaml +---+---------------------+--------------+------------------------------+-------+-------+---------+-----------------+----------------------+ | # | Name | Container ID | Image | Kind | Group | State | IPv4 Address | IPv6 Address | +---+---------------------+--------------+------------------------------+-------+-------+---------+-----------------+----------------------+ | 1 | clab-lab13-gnmic | 1ee4c75ff443 | ghcr.io/karimra/gnmic:latest | linux | | running | 172.20.20.3/24 | 2001:172:20:20::3/64 | | 2 | clab-lab13-grafana | a932207780bb | grafana/grafana:latest | linux | | running | 172.20.20.2/24 | 2001:172:20:20::2/64 | | 3 | clab-lab13-influxdb | 0768ba6ca10b | influxdb:latest | linux | | running | 172.20.20.4/24 | 2001:172:20:20::4/64 | | 4 | clab-lab13-leaf1 | e0e2045fca7f | ghcr.io/nokia/srlinux | srl | | running | 172.20.20.7/24 | 2001:172:20:20::7/64 | | 5 | clab-lab13-leaf2 | 75b8978e734c | ghcr.io/nokia/srlinux | srl | | running | 172.20.20.6/24 | 2001:172:20:20::6/64 | | 6 | clab-lab13-leaf3 | 7b03eed78f5d | ghcr.io/nokia/srlinux | srl | | running | 172.20.20.5/24 | 2001:172:20:20::5/64 | | 7 | clab-lab13-leaf4 | 19007ce81e04 | ghcr.io/nokia/srlinux | srl | | running | 172.20.20.8/24 | 2001:172:20:20::8/64 | | 8 | clab-lab13-spine1 | c044fc51196d | ghcr.io/nokia/srlinux | srl | | running | 172.20.20.10/24 | 2001:172:20:20::a/64 | | 9 | clab-lab13-spine2 | bcfa52ad2772 | ghcr.io/nokia/srlinux | srl | | running | 172.20.20.9/24 | 2001:172:20:20::9/64 | +---+---------------------+--------------+------------------------------+-------+-------+---------+-----------------+----------------------+ Check the InfluxDB Output documentation page for more configuration options.","title":"Containerlab"},{"location":"deployments/single-instance/containerlab/kafka-output/","text":"The purpose of this deployment is to collect gNMI data and write it to a Kafka broker. Multiple 3 rd Party systems (acting as a Kafka consumers) can then read the data from the Kafka broker for further processing. This deployment example includes a single gnmic instance and a single Kafka output Deployment files: containerlab gNMIc config The deployed SR Linux nodes are discovered using Docker API and are loaded as gNMI targets. Edit the subscriptions section if needed. Deploy it with: git clone https://github.com/karimra/gnmic.git cd gnmic/examples/deployments/1.single-instance/2.kafka-output/containerlab sudo clab deploy -t kafka.clab.yaml +---+-----------------------------+--------------+------------------------------+-------+-------+---------+-----------------+----------------------+ | # | Name | Container ID | Image | Kind | Group | State | IPv4 Address | IPv6 Address | +---+-----------------------------+--------------+------------------------------+-------+-------+---------+-----------------+----------------------+ | 1 | clab-lab12-gnmic | e79d31f92a7a | ghcr.io/karimra/gnmic:latest | linux | | running | 172.20.20.2/24 | 2001:172:20:20::2/64 | | 2 | clab-lab12-kafka-server | 004a338cdb3d | bitnami/kafka:latest | linux | | running | 172.20.20.4/24 | 2001:172:20:20::4/64 | | 3 | clab-lab12-leaf1 | b9269bac3adf | ghcr.io/nokia/srlinux | srl | | running | 172.20.20.7/24 | 2001:172:20:20::7/64 | | 4 | clab-lab12-leaf2 | baaeea0ad1a6 | ghcr.io/nokia/srlinux | srl | | running | 172.20.20.8/24 | 2001:172:20:20::8/64 | | 5 | clab-lab12-leaf3 | 08127014b3cd | ghcr.io/nokia/srlinux | srl | | running | 172.20.20.5/24 | 2001:172:20:20::5/64 | | 6 | clab-lab12-leaf4 | da037997c5ff | ghcr.io/nokia/srlinux | srl | | running | 172.20.20.10/24 | 2001:172:20:20::a/64 | | 7 | clab-lab12-spine1 | c3bcfe40fcc7 | ghcr.io/nokia/srlinux | srl | | running | 172.20.20.9/24 | 2001:172:20:20::9/64 | | 8 | clab-lab12-spine2 | 842b259d01b0 | ghcr.io/nokia/srlinux | srl | | running | 172.20.20.6/24 | 2001:172:20:20::6/64 | | 9 | clab-lab12-zookeeper-server | 5c89e48fdff1 | bitnami/zookeeper:latest | linux | | running | 172.20.20.3/24 | 2001:172:20:20::3/64 | +---+-----------------------------+--------------+------------------------------+-------+-------+---------+-----------------+----------------------+ Check the Kafka Output documentation page for more configuration options.","title":"Containerlab"},{"location":"deployments/single-instance/containerlab/multiple-outputs/","text":"The purpose of this deployment is to collect gNMI data and write it to multiple outputs. This deployment example includes: A single gnmic instance A Prometheus Server An InfluxDB Server A NATS Server A Kafka Server A File output A Consul Agent A Grafana Server Deployment files: containerlab gNMIc config Prometheus config Grafana datasource Deploy it with: git clone https://github.com/karimra/gnmic.git cd gnmic/examples/deployments/1.single-instance/5.multiple-outputs/containerlab sudo clab deploy -t multiple-outputs.clab.yaml +----+-----------------------------+--------------+------------------------------+-------+-------+---------+-----------------+----------------------+ | # | Name | Container ID | Image | Kind | Group | State | IPv4 Address | IPv6 Address | +----+-----------------------------+--------------+------------------------------+-------+-------+---------+-----------------+----------------------+ | 1 | clab-lab15-consul-agent | 14f864fb1da9 | consul:latest | linux | | running | 172.20.20.4/24 | 2001:172:20:20::4/64 | | 2 | clab-lab15-gnmic | cfb8bfca7547 | ghcr.io/karimra/gnmic:latest | linux | | running | 172.20.20.6/24 | 2001:172:20:20::6/64 | | 3 | clab-lab15-grafana | 56c19565e27c | grafana/grafana:latest | linux | | running | 172.20.20.2/24 | 2001:172:20:20::2/64 | | 4 | clab-lab15-influxdb | f2d0b2186e10 | influxdb:latest | linux | | running | 172.20.20.9/24 | 2001:172:20:20::9/64 | | 5 | clab-lab15-kafka-server | efe445dbf0f0 | bitnami/kafka:latest | linux | | running | 172.20.20.7/24 | 2001:172:20:20::7/64 | | 6 | clab-lab15-leaf1 | 42d57c79385e | ghcr.io/nokia/srlinux | srl | | running | 172.20.20.10/24 | 2001:172:20:20::a/64 | | 7 | clab-lab15-leaf2 | e4b041046779 | ghcr.io/nokia/srlinux | srl | | running | 172.20.20.11/24 | 2001:172:20:20::b/64 | | 8 | clab-lab15-leaf3 | ba87204f2678 | ghcr.io/nokia/srlinux | srl | | running | 172.20.20.13/24 | 2001:172:20:20::d/64 | | 9 | clab-lab15-leaf4 | 327461ee913e | ghcr.io/nokia/srlinux | srl | | running | 172.20.20.15/24 | 2001:172:20:20::f/64 | | 10 | clab-lab15-nats | 0363dae05edf | nats:latest | linux | | running | 172.20.20.3/24 | 2001:172:20:20::3/64 | | 11 | clab-lab15-prometheus | 44611ebe4a03 | prom/prometheus:latest | linux | | running | 172.20.20.8/24 | 2001:172:20:20::8/64 | | 12 | clab-lab15-spine1 | 8b2b430eea87 | ghcr.io/nokia/srlinux | srl | | running | 172.20.20.12/24 | 2001:172:20:20::c/64 | | 13 | clab-lab15-spine2 | 425bea3a243e | ghcr.io/nokia/srlinux | srl | | running | 172.20.20.14/24 | 2001:172:20:20::e/64 | | 14 | clab-lab15-zookeeper-server | 91b546eb7bf9 | bitnami/zookeeper:latest | linux | | running | 172.20.20.5/24 | 2001:172:20:20::5/64 | +----+-----------------------------+--------------+------------------------------+-------+-------+---------+-----------------+----------------------+ Check the gnmic outputs documentation page for more configuration options.","title":"Containerlab"},{"location":"deployments/single-instance/containerlab/nats-output/","text":"The purpose of this deployment is to collect gNMI data and write it to a NATS server. Multiple 3 rd Party systems (acting as a NATS clients) can then read the data from the NATS server for further processing. This deployment example includes a single gnmic instance and a single NATS output Deployment files: containerlab gNMIc config The deployed SR Linux nodes are discovered using Docker API and are loaded as gNMI targets. Edit the subscriptions section if needed. Deploy it with: git clone https://github.com/karimra/gnmic.git cd gnmic/examples/deployments/1.single-instance/1.nats-output/containerlab sudo clab deploy -t nats.clab.yaml +---+-------------------+--------------+------------------------------+-------+-------+---------+----------------+----------------------+ | # | Name | Container ID | Image | Kind | Group | State | IPv4 Address | IPv6 Address | +---+-------------------+--------------+------------------------------+-------+-------+---------+----------------+----------------------+ | 1 | clab-lab11-gnmic | 955eaa35b730 | ghcr.io/karimra/gnmic:latest | linux | | running | 172.20.20.3/24 | 2001:172:20:20::3/64 | | 2 | clab-lab11-leaf1 | f0f61a79124e | ghcr.io/nokia/srlinux | srl | | running | 172.20.20.4/24 | 2001:172:20:20::4/64 | | 3 | clab-lab11-leaf2 | de714ee79856 | ghcr.io/nokia/srlinux | srl | | running | 172.20.20.9/24 | 2001:172:20:20::9/64 | | 4 | clab-lab11-leaf3 | c674b7bbb898 | ghcr.io/nokia/srlinux | srl | | running | 172.20.20.8/24 | 2001:172:20:20::8/64 | | 5 | clab-lab11-leaf4 | c37033f30e99 | ghcr.io/nokia/srlinux | srl | | running | 172.20.20.7/24 | 2001:172:20:20::7/64 | | 6 | clab-lab11-nats | ebbd346d2aee | nats:latest | linux | | running | 172.20.20.2/24 | 2001:172:20:20::2/64 | | 7 | clab-lab11-spine1 | 0fe91271bdfe | ghcr.io/nokia/srlinux | srl | | running | 172.20.20.6/24 | 2001:172:20:20::6/64 | | 8 | clab-lab11-spine2 | 6b05f4e42cc4 | ghcr.io/nokia/srlinux | srl | | running | 172.20.20.5/24 | 2001:172:20:20::5/64 | +---+-------------------+--------------+------------------------------+-------+-------+---------+----------------+----------------------+ Check the NATS Output documentation page for more configuration options.","title":"Containerlab"},{"location":"deployments/single-instance/containerlab/prometheus-output/","text":"The purpose of this deployment is to collect gNMI data and make it available for scraping by a Prometheus client. This deployment example includes a single gnmic instance, a Prometheus Server , a Consul agent used by Prometheus to discover gNMIc's Prometheus output and a Grafana server. Deployment files: containerlab gNMIc config Prometheus config Grafana datasource The deployed SR Linux nodes are discovered using Docker API and are loaded as gNMI targets. Edit the subscriptions section if needed. Deploy it with: git clone https://github.com/karimra/gnmic.git cd gnmic/examples/deployments/1.single-instance/4.prometheus-output/containerlab sudo clab deploy -t prometheus.clab.yaml +----+-------------------------+--------------+------------------------------+-------+-------+---------+-----------------+----------------------+ | # | Name | Container ID | Image | Kind | Group | State | IPv4 Address | IPv6 Address | +----+-------------------------+--------------+------------------------------+-------+-------+---------+-----------------+----------------------+ | 1 | clab-lab14-consul-agent | e402b0516753 | consul:latest | linux | | running | 172.20.20.4/24 | 2001:172:20:20::4/64 | | 2 | clab-lab14-gnmic | 53943cdb8cde | ghcr.io/karimra/gnmic:latest | linux | | running | 172.20.20.3/24 | 2001:172:20:20::3/64 | | 3 | clab-lab14-grafana | 1a57efb74f37 | grafana/grafana:latest | linux | | running | 172.20.20.2/24 | 2001:172:20:20::2/64 | | 4 | clab-lab14-leaf1 | 8343848fbd7a | ghcr.io/nokia/srlinux | srl | | running | 172.20.20.9/24 | 2001:172:20:20::9/64 | | 5 | clab-lab14-leaf2 | 9986ff987048 | ghcr.io/nokia/srlinux | srl | | running | 172.20.20.8/24 | 2001:172:20:20::8/64 | | 6 | clab-lab14-leaf3 | 25a212fcb7a1 | ghcr.io/nokia/srlinux | srl | | running | 172.20.20.11/24 | 2001:172:20:20::b/64 | | 7 | clab-lab14-leaf4 | 025373e9f192 | ghcr.io/nokia/srlinux | srl | | running | 172.20.20.10/24 | 2001:172:20:20::a/64 | | 8 | clab-lab14-prometheus | ae9b47c49c8d | prom/prometheus:latest | linux | | running | 172.20.20.5/24 | 2001:172:20:20::5/64 | | 9 | clab-lab14-spine1 | fb9abd5b4c5c | ghcr.io/nokia/srlinux | srl | | running | 172.20.20.7/24 | 2001:172:20:20::7/64 | | 10 | clab-lab14-spine2 | f32906f19d55 | ghcr.io/nokia/srlinux | srl | | running | 172.20.20.6/24 | 2001:172:20:20::6/64 | +----+-------------------------+--------------+------------------------------+-------+-------+---------+-----------------+----------------------+ Check the Prometheus output documentation page for more configuration options.","title":"Containerlab"},{"location":"deployments/single-instance/docker-compose/influxdb-output/","text":"The purpose of this deployment is to collect gNMI data and write it to an InfluxDB instance. This deployment example includes a single gnmic instance and a single InfluxDB output Deployment files: Docker Compose gNMIc config Download both files, update the gnmic config file with the desired subscriptions and targets. Deploy it with: sudo docker-compose up -d Check the InfluxDB Output documentation page for more configuration options","title":"Docker Compose"},{"location":"deployments/single-instance/docker-compose/kafka-output/","text":"The purpose of this deployment is to collect gNMI data and write it to a Kafka broker. Multiple 3 rd Party systems (acting as a Kafka consumers) can then read the data from the Kafka broker for further processing. This deployment example includes a single gnmic instance and a single Kafka output Deployment files: Docker Compose gNMIc config Download both files, update the gnmic config file with the desired subscriptions and targets. Deploy it with: sudo docker-compose up -d Check the Kafka Output documentation page for more configuration options","title":"Docker Compose"},{"location":"deployments/single-instance/docker-compose/multiple-outputs/","text":"The purpose of this deployment is to collect gNMI data and write it to multiple outputs. This deployment example includes: A single gnmic instance A Prometheus output An InfluxDB output A NATS output A Kafka output A File output Deployment files: Docker Compose gNMIc config Prometheus config Download both files, update the gnmic config file with the desired subscriptions and targets. Deploy it with: sudo docker-compose up -d Check the gnmic outputs documentation page for more configuration options","title":"Docker Compose"},{"location":"deployments/single-instance/docker-compose/nats-output/","text":"The purpose of this deployment is to collect gNMI data and write it to a NATS server. Multiple 3 rd Party systems (acting as a NATS clients) can then read the data from the NATS server for further processing. This deployment example includes a single gnmic instance and a single NATS output Deployment files: Docker Compose gNMIc config Download both files, update the gnmic config file with the desired subscriptions and targets. Deploy it with: sudo docker-compose up -d Check the NATS Output documentation page for more configuration options","title":"Docker Compose"},{"location":"deployments/single-instance/docker-compose/prometheus-output/","text":"The purpose of this deployment is to collect gNMI data and make it available for scraping by a Prometheus client. This deployment example includes a single gnmic instance and a single Prometheus output Deployment files: Docker Compose gNMIc config Prometheus config Download both files, update the gnmic config file with the desired subscriptions and targets. Deploy it with: sudo docker-compose up -d Check the Prometheus output documentation page for more configuration options","title":"Docker Compose"},{"location":"user_guide/HA/","text":"Multiple instances of gnmic can be run in clustered mode in order to load share the targets connections and protect against failures. The cluster mode allows gnmic to scale and be highly available at the same time To join the cluster, the instances rely on a service discovery system and distributed KV store such as Consul , Clustering process # At startup, all instances belonging to a cluster: Enter an election process in order to become the cluster leader. Register their API service gnmic-api in a configured service discovery system. Upon becoming the leader: The gnmic instance starts watching the registered gnmic-api services, and maintains a local cache of the active ones. These are essentially the instances restAPI addresses. The leader then waits for clustering/leader-wait-timer to allow the other instances to register their API services as well. This is useful in case an instance is slow to boot, which leaves it out of the initial load sharing process. The leader then enters a \"target watch loop\" ( clustering/targets-watch-timer ), at each iteration the leader tries to determine if all configured targets are handled by an instance of the cluster, this is done by checking if there is a lock maintained for each configured target. The instances which failed to become the leader, continue to try to acquire the leader lock. Target distribution process # If the leader detects that a target does not have a lock, it triggers the target distribution process: Query all the targets keys from the KV store and calculate each instance load (number of maintained gNMI targets). If the target configuration includes tags , the leader selects the instance with the most matching tags (in order). If multiple instances have the same matching tags, the one with the lowest load is selected. If the target doesn't have configured tags, the leader simply select the least loaded instance to handle the target's subscriptions. Retrieve the selected instance API address from the local services cache. Send both the target configuration as well as a target activation action to the selected instance. When a cluster instance gets assigned a target (target activation): Acquire a key lock for that specific target. Once the lock is acquired, create the configured gNMI subscriptions. Maintain the target lock for the duration of the gNMI subscription. The whole target distribution process is repeated for each target missing a lock. Configuration # The cluster configuration is as simple as: # rest api address, format \"address:port\" api : \"\" # clustering related configuration fields clustering : # the cluster name, tells with instances belong to the same cluster # it is used as part of the leader key lock, and the targets key locks # if no value is configured, the value from flag --cluster-name is used. # if the flag has the empty string as value, \"default-cluster\" is used. cluster-name : default-cluster # unique instance name within the cluster, # used as the value in the target locks, # used as the value in the leader lock. # if no value is configured, the value from flag --instance-name is used. # if the flag has the empty string as value, a value is generated in # the format `gnmic-$UUID` instance-name : \"\" # service address to be registered in the locker(Consul) # if not defined, it defaults to the address part of the API address:port service-address : \"\" # gnmic instances API service watch timer # this is a long timer used by the cluster leader # in a consul long-blocking query: # https://www.consul.io/api-docs/features/blocking#implementation-details services-watch-timer : 60s # targets-watch-timer, targets watch timer, duration the leader waits # between consecutive targets distributions targets-watch-timer : 20s # target-assignment-timeout, max time a leader waits for an instance to # lock an assigned target. # if the timeout is reached the leader unassigns the target and reselects # a different instance. target-assignment-timeout : 10s # leader wait timer, allows to configure a wait time after an instance # acquires the leader key. # this wait time goal is to give more chances to other instances to register # their API services before the target distribution starts leader-wait-timer : 5s # ordered list of strings to be added as tags during api service # registration in addition to `cluster-name=${cluster-name}` and # `instance-name=${instance-name}` tags : [] # locker is used to configure the KV store used for # service registration, service discovery, leader election and targets locks locker : # type of locker, only consul is supported currently type : consul # address of the locker server address : localhost:8500 # Consul Data center, defaults to dc1 datacenter : # Consul username, to be used as part of HTTP basicAuth username : # Consul password, to be used as part of HTTP basicAuth password : # Consul Token, is used to provide a per-request ACL token which overrides # the agent's default token token : # session-ttl, session time-to-live after which a session is considered # invalid if not renewed # upon session invalidation, all services and locks created using this session # are considered invalid. session-ttl : 10s # delay, a time duration (0s to 60s), in the event of a session invalidation # consul will prevent the lock from being acquired for this duration. # The purpose is to allow a gnmic instance to stop active subscriptions before # another one takes over. delay : 5s # retry-timer, wait period between retries to acquire a lock # in the event of client failure, key is already locked or lock lost. retry-timer : 2s # renew-period, session renew period, must be lower that session-ttl. # if the value is greater or equal than session-ttl, is will be set to half # of session-ttl. renew-period : 5s # debug, enable extra logging messages debug : false A gnmic instance creates gNMI subscriptions only towards targets for which it acquired locks. It is also responsible for maintaining that lock for the duration of the subscription. Instance affinity # The target distribution process can be influenced using tags added to the target configuration. By default, gnmic instances register their API service with 2 tags; cluster-name=${clustering/cluster-name} instance-name=${clustering/instance-name} By adding the same tags to a target router1 configuration (below YAML), the cluster leader will \"assign\" router1 to instance gnmic1 in cluster my-cluster regardless of the instance load. targets : router1 : tags : - cluster-name=my-cluster - instance-name=gnmic1 Custom tags can be added to an instance API service registration in order to customize the instance affinity logic. clustering : tags : - my-custom-tag=value1 Instance failure # In the event of an instance failure, its maintained targets locks expire, which on the next clustering/targets-watch-timer interval will be detected by the cluster leader. The leader then performs the same target distribution process for those targets without a lock. Leader reelection # If a cluster leader fails, one of the other instances in the cluster eventually acquires the leader lock and becomes the cluster leader. It then, proceeds with the targets distribution process to assign the unhandled targets to an instance in the cluster. Scalability # Using the same above-mentioned clustering mechanism, gnmic can horizontally scale the number of supported gNMI connections distributed across multiple gnmic instances. The collected gNMI data can then be aggregated and made available through any of the running gnmic instances, regardless of whether that instance collected the data from the target or not. The data aggregation is done by chaining gnmic outputs and inputs to build a gNMI data pipeline. In the diagram below, the gnmic instances on the left and right side of NATS server can be identical.","title":"Clustering"},{"location":"user_guide/HA/#clustering-process","text":"At startup, all instances belonging to a cluster: Enter an election process in order to become the cluster leader. Register their API service gnmic-api in a configured service discovery system. Upon becoming the leader: The gnmic instance starts watching the registered gnmic-api services, and maintains a local cache of the active ones. These are essentially the instances restAPI addresses. The leader then waits for clustering/leader-wait-timer to allow the other instances to register their API services as well. This is useful in case an instance is slow to boot, which leaves it out of the initial load sharing process. The leader then enters a \"target watch loop\" ( clustering/targets-watch-timer ), at each iteration the leader tries to determine if all configured targets are handled by an instance of the cluster, this is done by checking if there is a lock maintained for each configured target. The instances which failed to become the leader, continue to try to acquire the leader lock.","title":"Clustering process"},{"location":"user_guide/HA/#target-distribution-process","text":"If the leader detects that a target does not have a lock, it triggers the target distribution process: Query all the targets keys from the KV store and calculate each instance load (number of maintained gNMI targets). If the target configuration includes tags , the leader selects the instance with the most matching tags (in order). If multiple instances have the same matching tags, the one with the lowest load is selected. If the target doesn't have configured tags, the leader simply select the least loaded instance to handle the target's subscriptions. Retrieve the selected instance API address from the local services cache. Send both the target configuration as well as a target activation action to the selected instance. When a cluster instance gets assigned a target (target activation): Acquire a key lock for that specific target. Once the lock is acquired, create the configured gNMI subscriptions. Maintain the target lock for the duration of the gNMI subscription. The whole target distribution process is repeated for each target missing a lock.","title":"Target distribution process"},{"location":"user_guide/HA/#configuration","text":"The cluster configuration is as simple as: # rest api address, format \"address:port\" api : \"\" # clustering related configuration fields clustering : # the cluster name, tells with instances belong to the same cluster # it is used as part of the leader key lock, and the targets key locks # if no value is configured, the value from flag --cluster-name is used. # if the flag has the empty string as value, \"default-cluster\" is used. cluster-name : default-cluster # unique instance name within the cluster, # used as the value in the target locks, # used as the value in the leader lock. # if no value is configured, the value from flag --instance-name is used. # if the flag has the empty string as value, a value is generated in # the format `gnmic-$UUID` instance-name : \"\" # service address to be registered in the locker(Consul) # if not defined, it defaults to the address part of the API address:port service-address : \"\" # gnmic instances API service watch timer # this is a long timer used by the cluster leader # in a consul long-blocking query: # https://www.consul.io/api-docs/features/blocking#implementation-details services-watch-timer : 60s # targets-watch-timer, targets watch timer, duration the leader waits # between consecutive targets distributions targets-watch-timer : 20s # target-assignment-timeout, max time a leader waits for an instance to # lock an assigned target. # if the timeout is reached the leader unassigns the target and reselects # a different instance. target-assignment-timeout : 10s # leader wait timer, allows to configure a wait time after an instance # acquires the leader key. # this wait time goal is to give more chances to other instances to register # their API services before the target distribution starts leader-wait-timer : 5s # ordered list of strings to be added as tags during api service # registration in addition to `cluster-name=${cluster-name}` and # `instance-name=${instance-name}` tags : [] # locker is used to configure the KV store used for # service registration, service discovery, leader election and targets locks locker : # type of locker, only consul is supported currently type : consul # address of the locker server address : localhost:8500 # Consul Data center, defaults to dc1 datacenter : # Consul username, to be used as part of HTTP basicAuth username : # Consul password, to be used as part of HTTP basicAuth password : # Consul Token, is used to provide a per-request ACL token which overrides # the agent's default token token : # session-ttl, session time-to-live after which a session is considered # invalid if not renewed # upon session invalidation, all services and locks created using this session # are considered invalid. session-ttl : 10s # delay, a time duration (0s to 60s), in the event of a session invalidation # consul will prevent the lock from being acquired for this duration. # The purpose is to allow a gnmic instance to stop active subscriptions before # another one takes over. delay : 5s # retry-timer, wait period between retries to acquire a lock # in the event of client failure, key is already locked or lock lost. retry-timer : 2s # renew-period, session renew period, must be lower that session-ttl. # if the value is greater or equal than session-ttl, is will be set to half # of session-ttl. renew-period : 5s # debug, enable extra logging messages debug : false A gnmic instance creates gNMI subscriptions only towards targets for which it acquired locks. It is also responsible for maintaining that lock for the duration of the subscription.","title":"Configuration"},{"location":"user_guide/HA/#instance-affinity","text":"The target distribution process can be influenced using tags added to the target configuration. By default, gnmic instances register their API service with 2 tags; cluster-name=${clustering/cluster-name} instance-name=${clustering/instance-name} By adding the same tags to a target router1 configuration (below YAML), the cluster leader will \"assign\" router1 to instance gnmic1 in cluster my-cluster regardless of the instance load. targets : router1 : tags : - cluster-name=my-cluster - instance-name=gnmic1 Custom tags can be added to an instance API service registration in order to customize the instance affinity logic. clustering : tags : - my-custom-tag=value1","title":"Instance affinity"},{"location":"user_guide/HA/#instance-failure","text":"In the event of an instance failure, its maintained targets locks expire, which on the next clustering/targets-watch-timer interval will be detected by the cluster leader. The leader then performs the same target distribution process for those targets without a lock.","title":"Instance failure"},{"location":"user_guide/HA/#leader-reelection","text":"If a cluster leader fails, one of the other instances in the cluster eventually acquires the leader lock and becomes the cluster leader. It then, proceeds with the targets distribution process to assign the unhandled targets to an instance in the cluster.","title":"Leader reelection"},{"location":"user_guide/HA/#scalability","text":"Using the same above-mentioned clustering mechanism, gnmic can horizontally scale the number of supported gNMI connections distributed across multiple gnmic instances. The collected gNMI data can then be aggregated and made available through any of the running gnmic instances, regardless of whether that instance collected the data from the target or not. The data aggregation is done by chaining gnmic outputs and inputs to build a gNMI data pipeline. In the diagram below, the gnmic instances on the left and right side of NATS server can be identical.","title":"Scalability"},{"location":"user_guide/configuration_env/","text":"gnmic can be configured using environment variables, it will read the environment variables starting with GNMIC_ . The Env variable names are inline with the flag names as well as the configuration hierarchy. For e.g to set the gNMI username, the env variable GNMIC_USERNAME should be set. Constructing environment variables names # Flags to environment variables mapping # Global flags to env variable name mapping: Flag name ENV variable name --address GNMIC_ADDRESS --encoding GNMIC_ENCODING --format GNMIC_FORMAT --insecure GNMIC_INSECURE --log GNMIC_LOG --log-file GNMIC_LOG_FILE --no-prefix GNMIC_NO_PREFIX --password GNMIC_PASSWORD --prometheus-address GNMIC_PROMETHEUS_ADDRESS --proxy-from-env GNMIC_PROXY_FROM_ENV --retry GNMIC_RETRY --skip-verify GNMIC_SKIP_VERIFY --timeout GNMIC_TIMEOUT --tls-ca GNMIC_TLS_CA --tls-cert GNMIC_TLS_CERT --tls-key GNMIC_TLS_KEY --tls-max-version GNMIC_TLS_MAX_VERSION --tls-min-version GNMIC_TLS_MIN_VERSION --tls-version GNMIC_TLS_VERSION --log-tls-secret GNMIC_LOG_TLS_SECRET --username GNMIC_USERNAME --cluster-name GNMIC_CLUSTER_NAME --instance-name GNMIC_INSTANCE_NAME --proto-file GNMIC_PROTO_FILE --proto-dir GNMIC_PROTO_DIR --token GNMIC_TOKEN Configuration file to environment variables mapping # For configuration items that do not have a corresponding flag, the env variable will be constructed from the path elements to the variable name joined with a _ . For e.g to set the clustering locker address, as in the yaml blob below: clustering : locker : address : the env variable GNMIC_CLUSTERING_LOCKER_ADDRESS should be set Note Configuration items of type list cannot be set using env vars. Intermediate configuration keys should not contain _ or - . Example: outputs : output1 : # <-- should not contain `_` or `-` type : prometheus listen : :9804 Is equivalent to: GNMIC_OUTPUTS_OUTPUT1_TYPE=prometheus GNMIC_OUTPUTS_OUTPUT1_LISTEN=:9804","title":"Environment variables"},{"location":"user_guide/configuration_env/#constructing-environment-variables-names","text":"","title":"Constructing environment variables names"},{"location":"user_guide/configuration_env/#flags-to-environment-variables-mapping","text":"Global flags to env variable name mapping: Flag name ENV variable name --address GNMIC_ADDRESS --encoding GNMIC_ENCODING --format GNMIC_FORMAT --insecure GNMIC_INSECURE --log GNMIC_LOG --log-file GNMIC_LOG_FILE --no-prefix GNMIC_NO_PREFIX --password GNMIC_PASSWORD --prometheus-address GNMIC_PROMETHEUS_ADDRESS --proxy-from-env GNMIC_PROXY_FROM_ENV --retry GNMIC_RETRY --skip-verify GNMIC_SKIP_VERIFY --timeout GNMIC_TIMEOUT --tls-ca GNMIC_TLS_CA --tls-cert GNMIC_TLS_CERT --tls-key GNMIC_TLS_KEY --tls-max-version GNMIC_TLS_MAX_VERSION --tls-min-version GNMIC_TLS_MIN_VERSION --tls-version GNMIC_TLS_VERSION --log-tls-secret GNMIC_LOG_TLS_SECRET --username GNMIC_USERNAME --cluster-name GNMIC_CLUSTER_NAME --instance-name GNMIC_INSTANCE_NAME --proto-file GNMIC_PROTO_FILE --proto-dir GNMIC_PROTO_DIR --token GNMIC_TOKEN","title":"Flags to environment variables mapping"},{"location":"user_guide/configuration_env/#configuration-file-to-environment-variables-mapping","text":"For configuration items that do not have a corresponding flag, the env variable will be constructed from the path elements to the variable name joined with a _ . For e.g to set the clustering locker address, as in the yaml blob below: clustering : locker : address : the env variable GNMIC_CLUSTERING_LOCKER_ADDRESS should be set Note Configuration items of type list cannot be set using env vars. Intermediate configuration keys should not contain _ or - . Example: outputs : output1 : # <-- should not contain `_` or `-` type : prometheus listen : :9804 Is equivalent to: GNMIC_OUTPUTS_OUTPUT1_TYPE=prometheus GNMIC_OUTPUTS_OUTPUT1_LISTEN=:9804","title":"Configuration file to environment variables mapping"},{"location":"user_guide/configuration_file/","text":"gnmic configuration by means of the command line flags is both consistent and reliable. But sometimes its not the best way forward. With lots of configuration options that gnmic supports it might get tedious to pass them all via CLI flags. In cases like that the file-based configuration comes handy. With a configuration file a user can specify all the command line flags by means of a single file. gnmic will read this file and retrieve the configuration options from it. What options can be in a file? # Configuration file allows a user to specify everything that can be supplied over the CLI and more. Global flags # All of the global flags can be put in a conf file. Consider the following example of a typical configuration file in YAML format: # gNMI target address; CLI flag `--address` address : \"10.0.0.1:57400\" # gNMI target user name; CLI flag `--username` username : admin # gNMI target user password; CLI flag `--password` password : admin # connection mode; CLI flag `--insecure` insecure : true # log file location; CLI flag `--log-file` log-file : /tmp/gnmic.log With such a file located at a default path the gNMI requests can be made in a very short and concise form: # configuration file is read by its default path gnmi capabilities # cfg file has all the global options set, so only the local flags are needed gnmi get --path /configure/system/name Local flags # Local flags have the scope of the command where they have been defined. Local flags can be put in a configuration file as well. To avoid flags names overlap between the different commands a command name should prepend the flag name - <cmd name>-<flag name> . So, for example, we can provide the path flag of a get command in the file by adding the get- prefix to the local flag name: address : \"router.lab:57400\" username : admin password : admin insecure : true get-path : /configure/system/name # `get` command local flag Another example: the update-path flag of a set will be set-update-path in the configuration file. Targets # It is possible to specify multiple targets with different configurations (credentials, timeout,...). This is described in Multiple targets documentation article. Subscriptions # It is possible to specify multiple subscriptions and associate them with different targets in a flexible way. This configuration option is described in Multiple subscriptions documentation article. Outputs # The other mode gnmic supports (in contrast to CLI) is running as a daemon and exporting the data received from gNMI subscriptions to multiple outputs like stan/nats, kafka, file, prometheus, influxdb, etc... Inputs # gnmic supports reading gNMI data from a set of inputs and export the data to any of the configured outputs. This is used when building data pipelines with gnmic Repeated flags # If a flag can appear more than once on the CLI, it can be represented as a list in the file. For example one can set multiple paths for get/set/subscribe operations. In the following example we define multiple paths for the get command to operate on: address : \"router.lab:57400\" username : admin password : admin insecure : true get-path : - /configure/system/name - /state/system/version Options preference # Configuration passed via CLI flags and Env variables take precedence over the file config. Environment variables in file # Environment variables can be used in the configuration file and will be expanded at the time the configuration is read. outputs : output1 : type : nats address : ${NATS_IP}:4222","title":"File configuration"},{"location":"user_guide/configuration_file/#what-options-can-be-in-a-file","text":"Configuration file allows a user to specify everything that can be supplied over the CLI and more.","title":"What options can be in a file?"},{"location":"user_guide/configuration_file/#global-flags","text":"All of the global flags can be put in a conf file. Consider the following example of a typical configuration file in YAML format: # gNMI target address; CLI flag `--address` address : \"10.0.0.1:57400\" # gNMI target user name; CLI flag `--username` username : admin # gNMI target user password; CLI flag `--password` password : admin # connection mode; CLI flag `--insecure` insecure : true # log file location; CLI flag `--log-file` log-file : /tmp/gnmic.log With such a file located at a default path the gNMI requests can be made in a very short and concise form: # configuration file is read by its default path gnmi capabilities # cfg file has all the global options set, so only the local flags are needed gnmi get --path /configure/system/name","title":"Global flags"},{"location":"user_guide/configuration_file/#local-flags","text":"Local flags have the scope of the command where they have been defined. Local flags can be put in a configuration file as well. To avoid flags names overlap between the different commands a command name should prepend the flag name - <cmd name>-<flag name> . So, for example, we can provide the path flag of a get command in the file by adding the get- prefix to the local flag name: address : \"router.lab:57400\" username : admin password : admin insecure : true get-path : /configure/system/name # `get` command local flag Another example: the update-path flag of a set will be set-update-path in the configuration file.","title":"Local flags"},{"location":"user_guide/configuration_file/#targets","text":"It is possible to specify multiple targets with different configurations (credentials, timeout,...). This is described in Multiple targets documentation article.","title":"Targets"},{"location":"user_guide/configuration_file/#subscriptions","text":"It is possible to specify multiple subscriptions and associate them with different targets in a flexible way. This configuration option is described in Multiple subscriptions documentation article.","title":"Subscriptions"},{"location":"user_guide/configuration_file/#outputs","text":"The other mode gnmic supports (in contrast to CLI) is running as a daemon and exporting the data received from gNMI subscriptions to multiple outputs like stan/nats, kafka, file, prometheus, influxdb, etc...","title":"Outputs"},{"location":"user_guide/configuration_file/#inputs","text":"gnmic supports reading gNMI data from a set of inputs and export the data to any of the configured outputs. This is used when building data pipelines with gnmic","title":"Inputs"},{"location":"user_guide/configuration_file/#repeated-flags","text":"If a flag can appear more than once on the CLI, it can be represented as a list in the file. For example one can set multiple paths for get/set/subscribe operations. In the following example we define multiple paths for the get command to operate on: address : \"router.lab:57400\" username : admin password : admin insecure : true get-path : - /configure/system/name - /state/system/version","title":"Repeated flags"},{"location":"user_guide/configuration_file/#options-preference","text":"Configuration passed via CLI flags and Env variables take precedence over the file config.","title":"Options preference"},{"location":"user_guide/configuration_file/#environment-variables-in-file","text":"Environment variables can be used in the configuration file and will be expanded at the time the configuration is read. outputs : output1 : type : nats address : ${NATS_IP}:4222","title":"Environment variables in file"},{"location":"user_guide/configuration_flags/","text":"gnmic supports a set of global flags, applicable to all sub commands, as well as local flags which are specific to each sub command. Global flags Local flags: Capabilities Get Set Subscribe Prompt Path Listen","title":"Configuration flags"},{"location":"user_guide/configuration_intro/","text":"gnmic reads configuration from three different sources, Global and local flags , environment variables and local system file . The different sources follow a precedence order where a configuration variable from a source take precedence over the next one in the below list: global and local flags Environment variables configuration file Flags # See here for a complete list of the supported global and local flags. Environment variables # gnmic can also be configured using environment variables, it will read the environment variables starting with GNMIC_ . The Env variable names are inline with the flag names as well as the configuration hierarchy. See here for more details on environment variables. File configuration # Configuration file that gnmic reads must be in one of the following formats: JSON, YAML, TOML, HCL or Properties. By default, gnmic will search for a file named .gnmic.[yml/yaml, toml, json] in the following locations and will use the first file that exists: $PWD $HOME $XDG_CONFIG_HOME $XDG_CONFIG_HOME/gnmic The default path can be overridden with --config flag. # config file default path is : # $PWD/.gnmic.[yml, toml, json], or # $HOME/.gnmic.[yml, toml, json], or # $XDG_CONFIG_HOME/.gnmic.[yml, toml, json], or # $XDG_CONFIG_HOME/gnmic/.gnmic.[yml, toml, json] gnmic capabilities # read `cfg.yml` file located in the current directory gnmic --config ./cfg.yml capabilities If the file referenced by --config flag is not present, the default path won't be tried. Example of the gnmic config files are provided in the following formats: YAML , JSON , TOML .","title":"Introduction"},{"location":"user_guide/configuration_intro/#flags","text":"See here for a complete list of the supported global and local flags.","title":"Flags"},{"location":"user_guide/configuration_intro/#environment-variables","text":"gnmic can also be configured using environment variables, it will read the environment variables starting with GNMIC_ . The Env variable names are inline with the flag names as well as the configuration hierarchy. See here for more details on environment variables.","title":"Environment variables"},{"location":"user_guide/configuration_intro/#file-configuration","text":"Configuration file that gnmic reads must be in one of the following formats: JSON, YAML, TOML, HCL or Properties. By default, gnmic will search for a file named .gnmic.[yml/yaml, toml, json] in the following locations and will use the first file that exists: $PWD $HOME $XDG_CONFIG_HOME $XDG_CONFIG_HOME/gnmic The default path can be overridden with --config flag. # config file default path is : # $PWD/.gnmic.[yml, toml, json], or # $HOME/.gnmic.[yml, toml, json], or # $XDG_CONFIG_HOME/.gnmic.[yml, toml, json], or # $XDG_CONFIG_HOME/gnmic/.gnmic.[yml, toml, json] gnmic capabilities # read `cfg.yml` file located in the current directory gnmic --config ./cfg.yml capabilities If the file referenced by --config flag is not present, the default path won't be tried. Example of the gnmic config files are provided in the following formats: YAML , JSON , TOML .","title":"File configuration"},{"location":"user_guide/gnmi_server/","text":"gNMI Server # Introduction # On top of acting as gNMI client gNMIc can run a gNMI server that supports Get , Set and Subscribe RPCs. The goal is to act as a caching point for the collected gNMI notifications and make them available to other collectors via the Subscribe RPC. Using this gNMI server feature it is possible to build gNMI based clusters and pipelines with gNMIc . The server keeps a cache of the gNMI notifications received from the defined subscriptions and utilizes it to build the Subscribe RPC responses. The unary RPCs, Get and Set, are relayed to known targets based on the Prefix.Target field. Supported features # Supports gNMI RPCs, Get, Set, Subscribe Acts as a gNMI gateway for Get and Set RPCs. Supports Service registration with Consul server. Supports all types of gNMI subscriptions, once , poll , stream . Supports all types of stream subscriptions, on-change , target-defined and sample . Supports updates-only with stream and once subscriptions. Supports suppress-redundant . Supports heartbeat-interval with on-change and sample stream subscriptions. Get RPC # The server supports the gNMI Get RPC, it allows a client to retrieve gNMI notifications from multiple targets into a single GetResponse . It relies on the GetRequest Prefix.Target field to select the target(s) against which it will run the Get RPC. If Prefix.Target is left empty or is equal to * , the Get RPC is performed against all known targets. The received GetRequest is cloned, enriched with each target name and sent to the corresponding destination. Comma separated target names are also supported and allow to select a list of specific targets to send the Get RPC to. gnmic -a gnmic-server:57400 get --path /interfaces \\ --target router1,router2,router3 Once all GetResponses are received back successfully, the notifications contained in each GetResponse are combined into a single GetResponse with each notification's Prefix.Target populated, if empty. The resulting GetResponse is then returned to the gNMI client. If one of the RPCs fails, an error with status code Internal(13) is returned to the client. If the GetRequest Path has the Origin field set to gnmic , the request is performed against the internal gNMIc server configuration. Currently only the paths targets and subscriptions are supported. gnmic -a gnmic-server:57400 get --path gnmic:/targets gnmic -a gnmic-server:57400 get --path gnmic:/subscriptions Set RPC # This gNMI server supports the gNMI Set RPC, it allows a client to run a single Set RPC against multiple targets. Just like in the case of Get RPC, the server relies on the Prefix.Target field to select the target(s) against which it will run the Set RPC. If Prefix.Target is left empty or is equal to * , a Set RPC is performed against all known targets. The received SetRequest is cloned, enriched with each target name and sent to the corresponding destination. Comma separated target names are also supported and allow to select a list of specific targets to send the Set RPC to. gnmic -a gnmic-server:57400 set \\ --update /system/ssh-server/admin-state:::json:::disable \\ --target router1,router2,router3 Once all SetResponses are received back successfully, the UpdateResult s from each response are merged into a single SetResponse, with the addition of the target name set in Path.Target . Note Adding a target value to a non prefix path is not compliant with the gNMI specification which stipulates that the Target field should only be present in Prefix Paths The resulting SetResponse is then returned to the gNMI client. If one of the RPCs fails, an error with status code Internal(13) is returned to the client. Subscribe RPC # The gNMIc server keeps a cache of gNMI notifications synched with the configured targets based on the configured subscriptions. The Subscribe requests received from a client are run against the afore mentioned cache, this means that a client cannot get updates about a leaf that gNMIc did not subscribe to as a client. Clients can subscribe to specific target using the gNMI Prefix.Target field, while leaving the Prefix.Target field empty or setting it to * is equivalent to subscribing to all known targets. Subscription Mode # gNMIc gNMI Server supports the 3 gNMI specified subscription modes: Once , Poll and Stream . It also supports some subscription behavior modifiers: updates-only with stream and once subscriptions. suppress-redundant . heartbeat-interval with on-change and sample stream subscriptions. Once # A subscription operating in the ONCE mode acts as a single request/response channel. The target creates the relevant update messages, transmits them, and subsequently closes the RPC. In this subscription mode, gNMIc server supports the updates-only knob. Poll # Polling subscriptions are used for on-demand retrieval of data items via long-lived RPCs. A poll subscription relates to a certain set of subscribed paths, and is initiated by sending a SubscribeRequest message with encapsulated SubscriptionList. Subscription messages contained within the SubscriptionList indicate the set of paths that are of interest to the polling client. Stream # Stream subscriptions are long-lived subscriptions which continue to transmit updates relating to the set of paths that are covered within the subscription indefinitely. In this subscription mode, gNMIc server supports the updates-only knob. On Change # When a subscription is defined to be on-change , data updates are only sent to the client when the value of the data item changes. In the case of gNMIc gNMI server, on-change subscriptions depend on the subscription writing data in the local cache, if it is a sample subscription, each update from a target will trigger an on-change update to the server client. gNMIc gNMI server supports on-change subscriptions with heartbeat-interval . If the heartbeat-interval value is set to a non zero value, the value of the data item(s) MUST be re-sent once per heartbeat interval regardless of whether the value has changed or not. Note The minimum heartbeat-interval is configurable using the field min-heartbeat-interval . It defaults to 1s If the received heartbeat-interval value is greater than zero but lower than min-heartbeat-interval , the min-heartbeat-interval value is used instead. Target Defined # When a client creates a subscription specifying the target defined mode, the target MUST determine the best type of subscription to be created on a per-leaf basis. In the case of gNMIc gNMI server, a target-defined stream subscription, is treated as an on-change subscription. Note that this does not mean that gNMIc will filter out the unchanged values received from a sample subscription to the actual targets. Sample # A sample subscription is one where data items are sent to the client once per sample-interval . The minimum supported sample-interval is configurable using the field min-sample-interval , defaults to 1ms . If within a SubscribeRequest the received sample-interval is zero, the default-sample-interval is used, defaults to 1s . Configuration # gnmi-server : # the address the gNMI server will listen to address : :57400 # if true, the server will not verify the client's certificates skip-verify : false # path to the CA certificate file to be used, irrelevant if `skip-verify` is true ca-file : # path to the server certificate file cert-file : # path to the server key file key-file : # maximum number of allowed subscriptions max-subscriptions : 64 # maximum number of active Get/Set RPCs max-unary-rpc : 64 # defines the minimum allowed sample interval, this value is used when the received sample-interval # is greater than zero but lower than this minimum value. min-sample-interval : 1ms # defines the default sample interval, # this value is used when the received sample-interval is zero within a stream/sample subscription. default-sample-interval : 1s # defines the minimum heartbeat-interval # this value is used when the received heartbeat-interval is greater than zero but # lower than this minimum value min-heartbeat-interval : 1s # enables the collection of Prometheus gRPC server metrics enable-metrics : false # enable additional debug logs debug : false # Enables Consul service registration service-registration : # Consul server address, default to localhost:8500 address : # Consul Data center, defaults to dc1 datacenter : # Consul username, to be used as part of HTTP basicAuth username : # Consul password, to be used as part of HTTP basicAuth password : # Consul Token, is used to provide a per-request ACL token # which overrides the agent's default token token : # gnmi server service check interval, only TTL Consul check is enabled # defaults to 5s check-interval : # Maximum number of failed checks before the service is deleted by Consul # defaults to 3 max-fail : # Consul service name name : # List of tags to be added to the service registration, # if available, the instance-name and cluster-name will be added as tags, # in the format: gnmic-instance=$instance-name and gnmic-cluster=$cluster-name tags : Secure vs Insecure Server # Insecure Mode # By default, the server runs in insecure mode, as long as skip-verify is false and none of ca-file , cert-file and key-file are set. Secure Mode # To run this gNMI server in secure mode, there are a few options: Using self signed certificates, without client certificate verification: gnmi-server : skip-verify : true Using self signed certificates, with client certificate verification: gnmi-server : # a valid CA certificate to verify the client provided certificates ca-file : /path/to/caFile Using CA provided certificates, without client certificate verification: gnmi-server : skip-verify : true # a valid server certificate cert-file : /path/to/server-cert # a valid server key key-file : /path/to/server-key Using CA provided certificates, with client certificate verification: gnmi-server : # a valid CA certificate to verify the client provided certificates ca-file : /path/to/caFile # a valid server certificate cert-file : /path/to/server-cert # a valid server key key-file : /path/to/server-key Fields # address # Defines the address the gNMI server will listen to. This can be a tcp socket in the format <addr:port> or a unix socket starting with unix:/// skip-verify # If true, the server will not verify the client's certificates. ca-file # Defines the path to the CA certificate file to be used, irrelevant if skip-verify is true cert-file # Defines the path to the server certificate file to be used. key-file # Defines the path to the server key file to be used. max-subscriptions # Defines the maximum number of allowed subscriptions. Defaults to 64 . max-unary-rpc # Defines the maximum number of active Get/Set RPCs. Defaults to 64 . min-sample-interval # Defines the minimum allowed sample interval, this value is used when the received sample-interval is greater than zero but lower than this minimum value. Defaults to 1ms default-sample-interval # Defines the default sample interval, this value is used when the received sample-interval is zero within a stream/sample subscription. Defaults to 1s min-heartbeat-interval # Defines the minimum heartbeat-interval, this value is used when the received heartbeat-interval is greater than zero but lower than this minimum value. Defaults to 1s enable-metrics # Enables the collection of Prometheus gRPC server metrics. debug # Enables additional debug logging.","title":"gNMI Server"},{"location":"user_guide/gnmi_server/#gnmi-server","text":"","title":"gNMI Server"},{"location":"user_guide/gnmi_server/#introduction","text":"On top of acting as gNMI client gNMIc can run a gNMI server that supports Get , Set and Subscribe RPCs. The goal is to act as a caching point for the collected gNMI notifications and make them available to other collectors via the Subscribe RPC. Using this gNMI server feature it is possible to build gNMI based clusters and pipelines with gNMIc . The server keeps a cache of the gNMI notifications received from the defined subscriptions and utilizes it to build the Subscribe RPC responses. The unary RPCs, Get and Set, are relayed to known targets based on the Prefix.Target field.","title":"Introduction"},{"location":"user_guide/gnmi_server/#supported-features","text":"Supports gNMI RPCs, Get, Set, Subscribe Acts as a gNMI gateway for Get and Set RPCs. Supports Service registration with Consul server. Supports all types of gNMI subscriptions, once , poll , stream . Supports all types of stream subscriptions, on-change , target-defined and sample . Supports updates-only with stream and once subscriptions. Supports suppress-redundant . Supports heartbeat-interval with on-change and sample stream subscriptions.","title":"Supported features"},{"location":"user_guide/gnmi_server/#get-rpc","text":"The server supports the gNMI Get RPC, it allows a client to retrieve gNMI notifications from multiple targets into a single GetResponse . It relies on the GetRequest Prefix.Target field to select the target(s) against which it will run the Get RPC. If Prefix.Target is left empty or is equal to * , the Get RPC is performed against all known targets. The received GetRequest is cloned, enriched with each target name and sent to the corresponding destination. Comma separated target names are also supported and allow to select a list of specific targets to send the Get RPC to. gnmic -a gnmic-server:57400 get --path /interfaces \\ --target router1,router2,router3 Once all GetResponses are received back successfully, the notifications contained in each GetResponse are combined into a single GetResponse with each notification's Prefix.Target populated, if empty. The resulting GetResponse is then returned to the gNMI client. If one of the RPCs fails, an error with status code Internal(13) is returned to the client. If the GetRequest Path has the Origin field set to gnmic , the request is performed against the internal gNMIc server configuration. Currently only the paths targets and subscriptions are supported. gnmic -a gnmic-server:57400 get --path gnmic:/targets gnmic -a gnmic-server:57400 get --path gnmic:/subscriptions","title":"Get RPC"},{"location":"user_guide/gnmi_server/#set-rpc","text":"This gNMI server supports the gNMI Set RPC, it allows a client to run a single Set RPC against multiple targets. Just like in the case of Get RPC, the server relies on the Prefix.Target field to select the target(s) against which it will run the Set RPC. If Prefix.Target is left empty or is equal to * , a Set RPC is performed against all known targets. The received SetRequest is cloned, enriched with each target name and sent to the corresponding destination. Comma separated target names are also supported and allow to select a list of specific targets to send the Set RPC to. gnmic -a gnmic-server:57400 set \\ --update /system/ssh-server/admin-state:::json:::disable \\ --target router1,router2,router3 Once all SetResponses are received back successfully, the UpdateResult s from each response are merged into a single SetResponse, with the addition of the target name set in Path.Target . Note Adding a target value to a non prefix path is not compliant with the gNMI specification which stipulates that the Target field should only be present in Prefix Paths The resulting SetResponse is then returned to the gNMI client. If one of the RPCs fails, an error with status code Internal(13) is returned to the client.","title":"Set RPC"},{"location":"user_guide/gnmi_server/#subscribe-rpc","text":"The gNMIc server keeps a cache of gNMI notifications synched with the configured targets based on the configured subscriptions. The Subscribe requests received from a client are run against the afore mentioned cache, this means that a client cannot get updates about a leaf that gNMIc did not subscribe to as a client. Clients can subscribe to specific target using the gNMI Prefix.Target field, while leaving the Prefix.Target field empty or setting it to * is equivalent to subscribing to all known targets.","title":"Subscribe RPC"},{"location":"user_guide/gnmi_server/#subscription-mode","text":"gNMIc gNMI Server supports the 3 gNMI specified subscription modes: Once , Poll and Stream . It also supports some subscription behavior modifiers: updates-only with stream and once subscriptions. suppress-redundant . heartbeat-interval with on-change and sample stream subscriptions.","title":"Subscription Mode"},{"location":"user_guide/gnmi_server/#once","text":"A subscription operating in the ONCE mode acts as a single request/response channel. The target creates the relevant update messages, transmits them, and subsequently closes the RPC. In this subscription mode, gNMIc server supports the updates-only knob.","title":"Once"},{"location":"user_guide/gnmi_server/#poll","text":"Polling subscriptions are used for on-demand retrieval of data items via long-lived RPCs. A poll subscription relates to a certain set of subscribed paths, and is initiated by sending a SubscribeRequest message with encapsulated SubscriptionList. Subscription messages contained within the SubscriptionList indicate the set of paths that are of interest to the polling client.","title":"Poll"},{"location":"user_guide/gnmi_server/#stream","text":"Stream subscriptions are long-lived subscriptions which continue to transmit updates relating to the set of paths that are covered within the subscription indefinitely. In this subscription mode, gNMIc server supports the updates-only knob.","title":"Stream"},{"location":"user_guide/gnmi_server/#on-change","text":"When a subscription is defined to be on-change , data updates are only sent to the client when the value of the data item changes. In the case of gNMIc gNMI server, on-change subscriptions depend on the subscription writing data in the local cache, if it is a sample subscription, each update from a target will trigger an on-change update to the server client. gNMIc gNMI server supports on-change subscriptions with heartbeat-interval . If the heartbeat-interval value is set to a non zero value, the value of the data item(s) MUST be re-sent once per heartbeat interval regardless of whether the value has changed or not. Note The minimum heartbeat-interval is configurable using the field min-heartbeat-interval . It defaults to 1s If the received heartbeat-interval value is greater than zero but lower than min-heartbeat-interval , the min-heartbeat-interval value is used instead.","title":"On Change"},{"location":"user_guide/gnmi_server/#target-defined","text":"When a client creates a subscription specifying the target defined mode, the target MUST determine the best type of subscription to be created on a per-leaf basis. In the case of gNMIc gNMI server, a target-defined stream subscription, is treated as an on-change subscription. Note that this does not mean that gNMIc will filter out the unchanged values received from a sample subscription to the actual targets.","title":"Target Defined"},{"location":"user_guide/gnmi_server/#sample","text":"A sample subscription is one where data items are sent to the client once per sample-interval . The minimum supported sample-interval is configurable using the field min-sample-interval , defaults to 1ms . If within a SubscribeRequest the received sample-interval is zero, the default-sample-interval is used, defaults to 1s .","title":"Sample"},{"location":"user_guide/gnmi_server/#configuration","text":"gnmi-server : # the address the gNMI server will listen to address : :57400 # if true, the server will not verify the client's certificates skip-verify : false # path to the CA certificate file to be used, irrelevant if `skip-verify` is true ca-file : # path to the server certificate file cert-file : # path to the server key file key-file : # maximum number of allowed subscriptions max-subscriptions : 64 # maximum number of active Get/Set RPCs max-unary-rpc : 64 # defines the minimum allowed sample interval, this value is used when the received sample-interval # is greater than zero but lower than this minimum value. min-sample-interval : 1ms # defines the default sample interval, # this value is used when the received sample-interval is zero within a stream/sample subscription. default-sample-interval : 1s # defines the minimum heartbeat-interval # this value is used when the received heartbeat-interval is greater than zero but # lower than this minimum value min-heartbeat-interval : 1s # enables the collection of Prometheus gRPC server metrics enable-metrics : false # enable additional debug logs debug : false # Enables Consul service registration service-registration : # Consul server address, default to localhost:8500 address : # Consul Data center, defaults to dc1 datacenter : # Consul username, to be used as part of HTTP basicAuth username : # Consul password, to be used as part of HTTP basicAuth password : # Consul Token, is used to provide a per-request ACL token # which overrides the agent's default token token : # gnmi server service check interval, only TTL Consul check is enabled # defaults to 5s check-interval : # Maximum number of failed checks before the service is deleted by Consul # defaults to 3 max-fail : # Consul service name name : # List of tags to be added to the service registration, # if available, the instance-name and cluster-name will be added as tags, # in the format: gnmic-instance=$instance-name and gnmic-cluster=$cluster-name tags :","title":"Configuration"},{"location":"user_guide/gnmi_server/#secure-vs-insecure-server","text":"","title":"Secure vs Insecure Server"},{"location":"user_guide/gnmi_server/#insecure-mode","text":"By default, the server runs in insecure mode, as long as skip-verify is false and none of ca-file , cert-file and key-file are set.","title":"Insecure Mode"},{"location":"user_guide/gnmi_server/#secure-mode","text":"To run this gNMI server in secure mode, there are a few options: Using self signed certificates, without client certificate verification: gnmi-server : skip-verify : true Using self signed certificates, with client certificate verification: gnmi-server : # a valid CA certificate to verify the client provided certificates ca-file : /path/to/caFile Using CA provided certificates, without client certificate verification: gnmi-server : skip-verify : true # a valid server certificate cert-file : /path/to/server-cert # a valid server key key-file : /path/to/server-key Using CA provided certificates, with client certificate verification: gnmi-server : # a valid CA certificate to verify the client provided certificates ca-file : /path/to/caFile # a valid server certificate cert-file : /path/to/server-cert # a valid server key key-file : /path/to/server-key","title":"Secure Mode"},{"location":"user_guide/gnmi_server/#fields","text":"","title":"Fields"},{"location":"user_guide/gnmi_server/#address","text":"Defines the address the gNMI server will listen to. This can be a tcp socket in the format <addr:port> or a unix socket starting with unix:///","title":"address"},{"location":"user_guide/gnmi_server/#skip-verify","text":"If true, the server will not verify the client's certificates.","title":"skip-verify"},{"location":"user_guide/gnmi_server/#ca-file","text":"Defines the path to the CA certificate file to be used, irrelevant if skip-verify is true","title":"ca-file"},{"location":"user_guide/gnmi_server/#cert-file","text":"Defines the path to the server certificate file to be used.","title":"cert-file"},{"location":"user_guide/gnmi_server/#key-file","text":"Defines the path to the server key file to be used.","title":"key-file"},{"location":"user_guide/gnmi_server/#max-subscriptions","text":"Defines the maximum number of allowed subscriptions. Defaults to 64 .","title":"max-subscriptions"},{"location":"user_guide/gnmi_server/#max-unary-rpc","text":"Defines the maximum number of active Get/Set RPCs. Defaults to 64 .","title":"max-unary-rpc"},{"location":"user_guide/gnmi_server/#min-sample-interval","text":"Defines the minimum allowed sample interval, this value is used when the received sample-interval is greater than zero but lower than this minimum value. Defaults to 1ms","title":"min-sample-interval"},{"location":"user_guide/gnmi_server/#default-sample-interval","text":"Defines the default sample interval, this value is used when the received sample-interval is zero within a stream/sample subscription. Defaults to 1s","title":"default-sample-interval"},{"location":"user_guide/gnmi_server/#min-heartbeat-interval","text":"Defines the minimum heartbeat-interval, this value is used when the received heartbeat-interval is greater than zero but lower than this minimum value. Defaults to 1s","title":"min-heartbeat-interval"},{"location":"user_guide/gnmi_server/#enable-metrics","text":"Enables the collection of Prometheus gRPC server metrics.","title":"enable-metrics"},{"location":"user_guide/gnmi_server/#debug","text":"Enables additional debug logging.","title":"debug"},{"location":"user_guide/prompt_suggestions/","text":"Starting with gnmic v0.4.0 release the users can enjoy the interactive prompt mode which can be enabled with the prompt command. The prompt mode delivers two major features: simplifies gnmic commands and flags navigation, as every option is suggested and auto-completed provides interactive YANG path auto-suggestions for get , set , subscribe commands effectively making the terminal your YANG browser Using the prompt interface # Depending on the cursor position in the prompt line, a so-called suggestion box pops up with contextual auto-completions. The user can enter the suggestion box by pressing the TAB key. The \u2191 and \u2193 keys can be used to navigate the suggestion list. Select the suggested menu item with SPACE key or directly commit your command with ENTER , its that easy! The following most-common key bindings will work in the prompt mode: Key combination Description Option/Control + \u2192/\u2190 move cursor a word right/left Control + W delete a word to the left Control + Z delete a path element in the xpath string ( example ) Control + A move cursor to the beginning of a line Control + E move cursor to the end of a line Control + C discard the current line Control + D exit prompt Control + K delete the line after the cursor to the clipboard Control + U delete the line before the cursor to the clipboard Control + L clear screen Commands and flags suggestions # To make gnmic configurable and flexible we introduced a considerable amount of flags and sub-commands. To help the users navigate the sheer selection of gnmic configuration options, the prompt mode will auto-suggest the global flags, sub-commands and local flags of those sub-commands. When the prompt mode is launched, the suggestions will be shown for the top-level commands and all the global flags. Once the sub-command is typed into the terminal, the auto-suggestions will be provided for the commands nested under this command and its local flags. In the following demo we show how the command and flag suggestions work. As the prompt starts, the suggestion box immediately hints what commands and global flags are available for input as well as their description. The user starts with adding the global flags --address, --insecure, --username and then selects the capabilities command and commits it. This results in gNMI Capability RPC execution against a specified target. Mixed mode # Its perfectly fine to specify some global flags outside of the prompt command and add more within the prompt mode. For example, the following is a valid invocation: gnmic --insecure --username admin --password admin --address 10.1.0.11 prompt Here the prompt will start with with the insecure, username, password, address flags set. YANG-completions # One of the most challenging problems in the network automation field is to process the YANG models and traverse YANG trees to construct the requests used against the network elements. Be it gNMI, NETCONF or RESTCONF a users still needs to have a path pointing to specific YANG-defined node which is targeted by a request. In gNMI paths can be represented in a human readable XPATH-like form - /a/b/c[key=val]/d - and these paths are based on the underlying YANG models. The problem at hand was how to get these paths interactively, or even better - walk the YANG tree from within the CLI and dynamically build the path used in a gNMI RPC? With YANG-completions feature embedded in gnmic what used to be a dream is now a reality \ud83c\udf89 Let us explain what just happened there. In the demonstration above, we called the gnmic with the well-known flags defining the gNMI target ( address , username , password ). But this time we also added a few YANG specific flags ( --file and --dir ) that load the full set of Nokia SR OS YANG models and the 3 rd party models SR OS rely on. gnmic --address 10.1.0.11 --insecure --username admin --password admin \\ --file ~/7x50_YangModels/YANG/nokia-combined \\ --dir ~/7x50_YangModels/YANG \\ prompt In the background gnmic processed these YANG models to build the entire schema tree of the Nokia SR OS state and configuration datastores. With that in-mem stored information, gnmic was able to auto-suggest all the possible YANG paths when the user entered the --path flag which accepts gNMI paths. By using the auto-suggestion hints, a user navigated the /state tree of a router and drilled down to the version-number leaf that, in the end, was retrieved with the gNMI Get RPC. YANG-driven path suggestions gnmic is now capable of reading and processing YANG modules to enable live path auto-suggestions YANG processing # For the YANG-completion feature to work its absolutely imperative for gnmic to successfully parse and compile the YANG models. The prompt command leverages the --file and --dir flags to select the YANG models for processing. With the --file flag a user specifies a file path to a YANG file or a directory of them that gnmic will read and process. If it points to a directory it will be visited recursively reading in all *.yang files it finds. The --dir flag also points to a YANG file or a directory and indicates which additional YANG files might be required. For example, if the YANG modules that a user specified with the --file flag import or include modules that were not part of the path specified with --file , they need to be added with the --dir flag. The Examples section provide some good practical examples on how these two flags can be used together to process the YANG models from different vendors. Understanding path suggestions # When gnmic provides a user with the path suggestions it does it in a smart and intuitive way. First, it understands in what part of the tree a user currently is and suggests only the next possible elements. Additionally, the suggested next path elements will be augmented with the information extracted from the YANG model, such as: element description, as given in the YANG description statement for the element element configuration state ( rw / ro ), as defined in section 4.2.3 of RFC 7950 . node type: The containers and lists will be denoted with the [+] marker, which means that a user can type / char after them to receive suggestions for the nested elements. the [\u22ef] character belongs to a leaf-list element. an empty space will indicate the leaf element. Examples # The examples in this section will show how to use the --file and --dir flags of the prompt command with the YANG collections from different vendors and standard bodies. Nokia SR OS # YANG repo: nokia/7x50_YangModels Clone the repository with Nokia YANG models and checkout the release of interest: git clone https://github.com/nokia/7x50_YangModels cd 7x50_YangModels git checkout sros_20.7.r2 Start gnmic in prompt mode and read in the nokia-combined YANG modules: gnmic --file YANG/nokia-combined \\ --dir YANG \\ prompt This will enable path auto-suggestions for the entire tree of the Nokia SR OS YANG models. The full command with the gNMI target specified could look like this: gnmic --address 10.1.0.11 --insecure --username admin --password admin \\ prompt \\ --file ~/7x50_YangModels/YANG/nokia-combined \\ --dir ~/7x50_YangModels/YANG Openconfig # YANG repo: openconfig/public Clone the OpenConfig repository: git clone https://github.com/openconfig/public cd public Start gnmic in prompt mode and read in all the modules: gnmic --file release/models \\ --dir third_party \\ --exclude ietf-interfaces \\ prompt Note With OpenConfig models we have to use --exclude flag to exclude ietf-interfaces module from being clashed with OpenConfig interfaces module. Cisco # YANG repo: YangModels/yang Clone the YangModels/yang repo and change into the main directory of the repo: git clone https://github.com/YangModels/yang cd yang/vendor IOS-XR # The IOS-XR native YANG models are disaggregated and spread all over the place. Although its technically possible to load them all in one go, this approach will produce a lot of top-level modules making the navigation quite hard. An easier and cleaner approach would be to find the relevant module(s) and load them separately or in small batches. For example here we load BGP config and operational models together: gnmic --file vendor/cisco/xr/721/Cisco-IOS-XR-um-router-bgp-cfg.yang \\ --file vendor/cisco/xr/721/Cisco-IOS-XR-ipv4-bgp-oper.yang \\ --dir standard/ietf \\ prompt Note We needed to include the ietf/ directory by means of the --dir flag, since the Cisco's native modules rely on the IETF modules and these modules are not in the same directory as the BGP modules. The full command that you can against the real Cisco IOS-XR node must have a target defined, the encoding set and origin suggestions enabled. Here is what it can look like: gnmic -a 10.10.30.5:57500 --insecure -e json_ietf -u admin -p Cisco123 \\ prompt \\ --file yang/vendor/cisco/xr/662/Cisco-IOS-XR-ipv4-bgp-cfg.yang \\ --file yang/vendor/cisco/xr/662/Cisco-IOS-XR-ipv4-bgp-oper.yang \\ --dir yang/standard/ietf \\ --suggest-with-origin NX-OS # Cisco NX-OS native modules, on the other hand, are aggregated in a single file, here is how you can generate the suggestions from it: gnmic --file vendor/cisco/xr/721/Cisco-IOS-XR-um-router-bgp-cfg.yang \\ --dir standard/ietf \\ prompt Juniper # YANG repo: Juniper/yang Clone the Juniper YANG repository and change into the release directory: git clone https://github.com/Juniper/yang cd yang/20.3/20.3R1 Start gnmic and generate path suggestions for the whole configuration tree of Juniper MX: gnmic --file junos/conf --dir common prompt Note Juniper models are constructed in a way that a top-level container appears to be /configuration , that will not work with your gNMI Subscribe RPC. Instead, you should omit this top level container. So, for example, the suggested path /configuration/interfaces/interface/state should become /interfaces/interface/state . Juniper vMX doesn't support gNMI Get RPC, if you plan to test it, use gNMI Subscribe RPC With gNMI Subscribe, specify -e proto flag to enable protobuf encoding. Arista # YANG repo: aristanetworks/yang Arista uses a subset of OpenConfig modules and does not provide IETF modules inside their repo. So make sure you have IETF models available so you can reference it, a openconfig/public is a good candidate. Clone the Arista YANG repo: git clone https://github.com/aristanetworks/yang cd yang Generate path suggestions for all Arista OpenConfig modules: gnmic --file EOS-4.23.2F/openconfig/public/release/models \\ --dir ~/public/third_party/ietf \\ --exclude ietf-interfaces \\ prompt Enumeration suggestions # gnmic flags that can take pre-defined values (enumerations) will get suggestions as well. For example, no need to keep in mind which subscription modes are available, the prompt will hint you: File-path completions # Whenever a user needs to provide a file path in a prompt mode, the filepath suggestions will make the process interactive:","title":"Prompt mode"},{"location":"user_guide/prompt_suggestions/#using-the-prompt-interface","text":"Depending on the cursor position in the prompt line, a so-called suggestion box pops up with contextual auto-completions. The user can enter the suggestion box by pressing the TAB key. The \u2191 and \u2193 keys can be used to navigate the suggestion list. Select the suggested menu item with SPACE key or directly commit your command with ENTER , its that easy! The following most-common key bindings will work in the prompt mode: Key combination Description Option/Control + \u2192/\u2190 move cursor a word right/left Control + W delete a word to the left Control + Z delete a path element in the xpath string ( example ) Control + A move cursor to the beginning of a line Control + E move cursor to the end of a line Control + C discard the current line Control + D exit prompt Control + K delete the line after the cursor to the clipboard Control + U delete the line before the cursor to the clipboard Control + L clear screen","title":"Using the prompt interface"},{"location":"user_guide/prompt_suggestions/#commands-and-flags-suggestions","text":"To make gnmic configurable and flexible we introduced a considerable amount of flags and sub-commands. To help the users navigate the sheer selection of gnmic configuration options, the prompt mode will auto-suggest the global flags, sub-commands and local flags of those sub-commands. When the prompt mode is launched, the suggestions will be shown for the top-level commands and all the global flags. Once the sub-command is typed into the terminal, the auto-suggestions will be provided for the commands nested under this command and its local flags. In the following demo we show how the command and flag suggestions work. As the prompt starts, the suggestion box immediately hints what commands and global flags are available for input as well as their description. The user starts with adding the global flags --address, --insecure, --username and then selects the capabilities command and commits it. This results in gNMI Capability RPC execution against a specified target.","title":"Commands and flags suggestions"},{"location":"user_guide/prompt_suggestions/#mixed-mode","text":"Its perfectly fine to specify some global flags outside of the prompt command and add more within the prompt mode. For example, the following is a valid invocation: gnmic --insecure --username admin --password admin --address 10.1.0.11 prompt Here the prompt will start with with the insecure, username, password, address flags set.","title":"Mixed mode"},{"location":"user_guide/prompt_suggestions/#yang-completions","text":"One of the most challenging problems in the network automation field is to process the YANG models and traverse YANG trees to construct the requests used against the network elements. Be it gNMI, NETCONF or RESTCONF a users still needs to have a path pointing to specific YANG-defined node which is targeted by a request. In gNMI paths can be represented in a human readable XPATH-like form - /a/b/c[key=val]/d - and these paths are based on the underlying YANG models. The problem at hand was how to get these paths interactively, or even better - walk the YANG tree from within the CLI and dynamically build the path used in a gNMI RPC? With YANG-completions feature embedded in gnmic what used to be a dream is now a reality \ud83c\udf89 Let us explain what just happened there. In the demonstration above, we called the gnmic with the well-known flags defining the gNMI target ( address , username , password ). But this time we also added a few YANG specific flags ( --file and --dir ) that load the full set of Nokia SR OS YANG models and the 3 rd party models SR OS rely on. gnmic --address 10.1.0.11 --insecure --username admin --password admin \\ --file ~/7x50_YangModels/YANG/nokia-combined \\ --dir ~/7x50_YangModels/YANG \\ prompt In the background gnmic processed these YANG models to build the entire schema tree of the Nokia SR OS state and configuration datastores. With that in-mem stored information, gnmic was able to auto-suggest all the possible YANG paths when the user entered the --path flag which accepts gNMI paths. By using the auto-suggestion hints, a user navigated the /state tree of a router and drilled down to the version-number leaf that, in the end, was retrieved with the gNMI Get RPC. YANG-driven path suggestions gnmic is now capable of reading and processing YANG modules to enable live path auto-suggestions","title":"YANG-completions"},{"location":"user_guide/prompt_suggestions/#yang-processing","text":"For the YANG-completion feature to work its absolutely imperative for gnmic to successfully parse and compile the YANG models. The prompt command leverages the --file and --dir flags to select the YANG models for processing. With the --file flag a user specifies a file path to a YANG file or a directory of them that gnmic will read and process. If it points to a directory it will be visited recursively reading in all *.yang files it finds. The --dir flag also points to a YANG file or a directory and indicates which additional YANG files might be required. For example, if the YANG modules that a user specified with the --file flag import or include modules that were not part of the path specified with --file , they need to be added with the --dir flag. The Examples section provide some good practical examples on how these two flags can be used together to process the YANG models from different vendors.","title":"YANG processing"},{"location":"user_guide/prompt_suggestions/#understanding-path-suggestions","text":"When gnmic provides a user with the path suggestions it does it in a smart and intuitive way. First, it understands in what part of the tree a user currently is and suggests only the next possible elements. Additionally, the suggested next path elements will be augmented with the information extracted from the YANG model, such as: element description, as given in the YANG description statement for the element element configuration state ( rw / ro ), as defined in section 4.2.3 of RFC 7950 . node type: The containers and lists will be denoted with the [+] marker, which means that a user can type / char after them to receive suggestions for the nested elements. the [\u22ef] character belongs to a leaf-list element. an empty space will indicate the leaf element.","title":"Understanding path suggestions"},{"location":"user_guide/prompt_suggestions/#examples","text":"The examples in this section will show how to use the --file and --dir flags of the prompt command with the YANG collections from different vendors and standard bodies.","title":"Examples"},{"location":"user_guide/prompt_suggestions/#nokia-sr-os","text":"YANG repo: nokia/7x50_YangModels Clone the repository with Nokia YANG models and checkout the release of interest: git clone https://github.com/nokia/7x50_YangModels cd 7x50_YangModels git checkout sros_20.7.r2 Start gnmic in prompt mode and read in the nokia-combined YANG modules: gnmic --file YANG/nokia-combined \\ --dir YANG \\ prompt This will enable path auto-suggestions for the entire tree of the Nokia SR OS YANG models. The full command with the gNMI target specified could look like this: gnmic --address 10.1.0.11 --insecure --username admin --password admin \\ prompt \\ --file ~/7x50_YangModels/YANG/nokia-combined \\ --dir ~/7x50_YangModels/YANG","title":"Nokia SR OS"},{"location":"user_guide/prompt_suggestions/#openconfig","text":"YANG repo: openconfig/public Clone the OpenConfig repository: git clone https://github.com/openconfig/public cd public Start gnmic in prompt mode and read in all the modules: gnmic --file release/models \\ --dir third_party \\ --exclude ietf-interfaces \\ prompt Note With OpenConfig models we have to use --exclude flag to exclude ietf-interfaces module from being clashed with OpenConfig interfaces module.","title":"Openconfig"},{"location":"user_guide/prompt_suggestions/#cisco","text":"YANG repo: YangModels/yang Clone the YangModels/yang repo and change into the main directory of the repo: git clone https://github.com/YangModels/yang cd yang/vendor","title":"Cisco"},{"location":"user_guide/prompt_suggestions/#ios-xr","text":"The IOS-XR native YANG models are disaggregated and spread all over the place. Although its technically possible to load them all in one go, this approach will produce a lot of top-level modules making the navigation quite hard. An easier and cleaner approach would be to find the relevant module(s) and load them separately or in small batches. For example here we load BGP config and operational models together: gnmic --file vendor/cisco/xr/721/Cisco-IOS-XR-um-router-bgp-cfg.yang \\ --file vendor/cisco/xr/721/Cisco-IOS-XR-ipv4-bgp-oper.yang \\ --dir standard/ietf \\ prompt Note We needed to include the ietf/ directory by means of the --dir flag, since the Cisco's native modules rely on the IETF modules and these modules are not in the same directory as the BGP modules. The full command that you can against the real Cisco IOS-XR node must have a target defined, the encoding set and origin suggestions enabled. Here is what it can look like: gnmic -a 10.10.30.5:57500 --insecure -e json_ietf -u admin -p Cisco123 \\ prompt \\ --file yang/vendor/cisco/xr/662/Cisco-IOS-XR-ipv4-bgp-cfg.yang \\ --file yang/vendor/cisco/xr/662/Cisco-IOS-XR-ipv4-bgp-oper.yang \\ --dir yang/standard/ietf \\ --suggest-with-origin","title":"IOS-XR"},{"location":"user_guide/prompt_suggestions/#nx-os","text":"Cisco NX-OS native modules, on the other hand, are aggregated in a single file, here is how you can generate the suggestions from it: gnmic --file vendor/cisco/xr/721/Cisco-IOS-XR-um-router-bgp-cfg.yang \\ --dir standard/ietf \\ prompt","title":"NX-OS"},{"location":"user_guide/prompt_suggestions/#juniper","text":"YANG repo: Juniper/yang Clone the Juniper YANG repository and change into the release directory: git clone https://github.com/Juniper/yang cd yang/20.3/20.3R1 Start gnmic and generate path suggestions for the whole configuration tree of Juniper MX: gnmic --file junos/conf --dir common prompt Note Juniper models are constructed in a way that a top-level container appears to be /configuration , that will not work with your gNMI Subscribe RPC. Instead, you should omit this top level container. So, for example, the suggested path /configuration/interfaces/interface/state should become /interfaces/interface/state . Juniper vMX doesn't support gNMI Get RPC, if you plan to test it, use gNMI Subscribe RPC With gNMI Subscribe, specify -e proto flag to enable protobuf encoding.","title":"Juniper"},{"location":"user_guide/prompt_suggestions/#arista","text":"YANG repo: aristanetworks/yang Arista uses a subset of OpenConfig modules and does not provide IETF modules inside their repo. So make sure you have IETF models available so you can reference it, a openconfig/public is a good candidate. Clone the Arista YANG repo: git clone https://github.com/aristanetworks/yang cd yang Generate path suggestions for all Arista OpenConfig modules: gnmic --file EOS-4.23.2F/openconfig/public/release/models \\ --dir ~/public/third_party/ietf \\ --exclude ietf-interfaces \\ prompt","title":"Arista"},{"location":"user_guide/prompt_suggestions/#enumeration-suggestions","text":"gnmic flags that can take pre-defined values (enumerations) will get suggestions as well. For example, no need to keep in mind which subscription modes are available, the prompt will hint you:","title":"Enumeration suggestions"},{"location":"user_guide/prompt_suggestions/#file-path-completions","text":"Whenever a user needs to provide a file path in a prompt mode, the filepath suggestions will make the process interactive:","title":"File-path completions"},{"location":"user_guide/subscriptions/","text":"Defining subscriptions with subscribe command's CLI flags is a quick&easy way to work with gNMI subscriptions. A downside of that approach is that commands can get lengthy when defining multiple subscriptions. With the multiple subscriptions defined in the configuration file we make a complex task of managing multiple subscriptions for multiple targets easy. The idea behind the multiple subscriptions is to define the subscriptions separately and then bind them to the targets. Defining subscriptions # To define a subscription a user needs to create the subscriptions container in the configuration file: subscriptions : # a configurable subscription name subscription-name : # string, path to be set as the Subscribe Request Prefix prefix : # string, value to set as the SubscribeRequest Prefix Target target : # boolean, if true, the SubscribeRequest Prefix Target will be set to # the configured target name under section `targets`. # does not apply if the previous field `target` is set. set-target : # true | false # list of strings, list of subscription paths for the named subscription paths : [] # list of strings, schema definition modules models : [] # string, case insensitive, one of ONCE, STREAM, POLL mode : STREAM # string, case insensitive, if `mode` is set to STREAM, this defines the type # of streamed subscription, # one of SAMPLE, TARGET_DEFINED, ON_CHANGE stream-mode : TARGET_DEFINED # string, case insensitive, defines the gNMI encoding to be used for the subscription encoding : JSON # integer, specifies the packet marking that is to be used for the subscribe responses qos : # duration, Golang duration format, e.g: 1s, 1m30s, 1h. # specifies the sample interval for a STREAM/SAMPLE subscription sample-interval : # duration, Golang duration format, e.g: 1s, 1m30s, 1h. # The heartbeat interval value can be specified along with `ON_CHANGE` or `SAMPLE` # stream subscriptions modes and has the following meanings in each case: # - `ON_CHANGE`: The value of the data item(s) MUST be re-sent once per heartbeat # interval regardless of whether the value has changed or not. # - `SAMPLE`: The target MUST generate one telemetry update per heartbeat interval, # regardless of whether the `--suppress-redundant` flag is set to true. heartbeat-interval : # boolean, if set to true, the target SHOULD NOT generate a telemetry update message unless # the value of the path being reported on has changed since the last suppress-redundant : # boolean, if set to true, the target MUST not transmit the current state of the paths # that the client has subscribed to, but rather should send only updates to them. updates-only : # historical subscription config: https://github.com/openconfig/reference/blob/master/rpc/gnmi/gnmi-history.md#1-purpose history : # string, nanoseconds since Unix epoch or RFC3339 format. # if set, the history extension type will be a Snapshot request snapshot : # string, nanoseconds since Unix epoch or RFC3339 format. # if set, the history extension type will be a Range request start : # string, nanoseconds since Unix epoch or RFC3339 format. # if set, the history extension type will be a Range request end : Examples: # part of ~/gnmic.yml config file subscriptions : # container for subscriptions port_stats : # a named subscription, a key is a name paths : # list of subscription paths for that named subscription - \"/state/port[port-id=1/1/c1/1]/statistics/out-octets\" - \"/state/port[port-id=1/1/c1/1]/statistics/in-octets\" stream-mode : sample # one of [on-change target-defined sample] sample-interval : 5s encoding : bytes service_state : paths : - \"/state/service/vpls[service-name=*]/oper-state\" - \"/state/service/vprn[service-name=*]/oper-state\" stream-mode : on-change system_facts : paths : - \"/configure/system/name\" - \"/state/system/version\" mode : once Inside that subscriptions container a user defines individual named subscriptions; in the example above two named subscriptions port_stats and service_state were defined. These subscriptions can be used on the cli via the [ --name ] flag of subscribe command: gnmic subscribe --name service_state --name port_stats Or by binding them to different targets, (see next section) Binding subscriptions # Once the subscriptions are defined, they can be flexibly associated with the targets. # part of ~/gnmic.yml config file targets : router1.lab.com : username : admin password : secret subscriptions : - port_stats - service_state router2.lab.com : username : gnmi password : telemetry subscriptions : - service_state The named subscriptions are put under the subscriptions section of a target container. As shown in the example above, it is allowed to add multiple named subscriptions under a single target; in that case each named subscription will result in a separate Subscription Request towards a target. Note If a target is not explicitly associated with any subscription, the client will subscribe to all defined subscriptions in the file. The full configuration with the subscriptions defined and associated with targets will look like this: username : admin password : nokiasr0s insecure : true targets : router1.lab.com : subscriptions : - port_stats - service_state - system_facts router2.lab.com : subscriptions : - service_state - system_facts subscriptions : port_stats : paths : - \"/state/port[port-id=1/1/c1/1]/statistics/out-octets\" - \"/state/port[port-id=1/1/c1/1]/statistics/in-octets\" stream-mode : sample sample-interval : 5s encoding : bytes service_state : paths : - \"/state/service/vpls[service-name=*]/oper-state\" - \"/state/service/vprn[service-name=*]/oper-state\" stream-mode : on-change system_facts : paths : - \"/configure/system/name\" - \"/state/system/version\" mode : once As a result of such configuration the gnmic will set up three gNMI subscriptions to router1 and two other gNMI subscriptions to router2: $ gnmic subscribe gnmic 2020 /07/06 22 :03:35.579942 target 'router2.lab.com' initialized gnmic 2020 /07/06 22 :03:35.593082 target 'router1.lab.com' initialized { \"source\" : \"router2.lab.com\" , \"subscription-name\" : \"service_state\" , \"timestamp\" : 1594065869313065895 , \"time\" : \"2020-07-06T22:04:29.313065895+02:00\" , \"prefix\" : \"state/service/vpls[service-name=testvpls]\" , \"updates\" : [ { \"Path\" : \"oper-state\" , \"values\" : { \"oper-state\" : \"down\" } } ] } { \"source\" : \"router1.lab.com\" , \"subscription-name\" : \"service_state\" , \"timestamp\" : 1594065868850351364 , \"time\" : \"2020-07-06T22:04:28.850351364+02:00\" , \"prefix\" : \"state/service/vpls[service-name=test]\" , \"updates\" : [ { \"Path\" : \"oper-state\" , \"values\" : { \"oper-state\" : \"down\" } } ] } { \"source\" : \"router1.lab.com\" , \"subscription-name\" : \"port_stats\" , \"timestamp\" : 1594065873938155916 , \"time\" : \"2020-07-06T22:04:33.938155916+02:00\" , \"prefix\" : \"state/port[port-id=1/1/c1/1]/statistics\" , \"updates\" : [ { \"Path\" : \"in-octets\" , \"values\" : { \"in-octets\" : \"671552\" } } ] } { \"source\" : \"router1.lab.com\" , \"subscription-name\" : \"port_stats\" , \"timestamp\" : 1594065873938043848 , \"time\" : \"2020-07-06T22:04:33.938043848+02:00\" , \"prefix\" : \"state/port[port-id=1/1/c1/1]/statistics\" , \"updates\" : [ { \"Path\" : \"out-octets\" , \"values\" : { \"out-octets\" : \"370930\" } } ] } ^C received sig nal 'i nterru p t '. ter mi nat i n g...","title":"Subscriptions"},{"location":"user_guide/subscriptions/#defining-subscriptions","text":"To define a subscription a user needs to create the subscriptions container in the configuration file: subscriptions : # a configurable subscription name subscription-name : # string, path to be set as the Subscribe Request Prefix prefix : # string, value to set as the SubscribeRequest Prefix Target target : # boolean, if true, the SubscribeRequest Prefix Target will be set to # the configured target name under section `targets`. # does not apply if the previous field `target` is set. set-target : # true | false # list of strings, list of subscription paths for the named subscription paths : [] # list of strings, schema definition modules models : [] # string, case insensitive, one of ONCE, STREAM, POLL mode : STREAM # string, case insensitive, if `mode` is set to STREAM, this defines the type # of streamed subscription, # one of SAMPLE, TARGET_DEFINED, ON_CHANGE stream-mode : TARGET_DEFINED # string, case insensitive, defines the gNMI encoding to be used for the subscription encoding : JSON # integer, specifies the packet marking that is to be used for the subscribe responses qos : # duration, Golang duration format, e.g: 1s, 1m30s, 1h. # specifies the sample interval for a STREAM/SAMPLE subscription sample-interval : # duration, Golang duration format, e.g: 1s, 1m30s, 1h. # The heartbeat interval value can be specified along with `ON_CHANGE` or `SAMPLE` # stream subscriptions modes and has the following meanings in each case: # - `ON_CHANGE`: The value of the data item(s) MUST be re-sent once per heartbeat # interval regardless of whether the value has changed or not. # - `SAMPLE`: The target MUST generate one telemetry update per heartbeat interval, # regardless of whether the `--suppress-redundant` flag is set to true. heartbeat-interval : # boolean, if set to true, the target SHOULD NOT generate a telemetry update message unless # the value of the path being reported on has changed since the last suppress-redundant : # boolean, if set to true, the target MUST not transmit the current state of the paths # that the client has subscribed to, but rather should send only updates to them. updates-only : # historical subscription config: https://github.com/openconfig/reference/blob/master/rpc/gnmi/gnmi-history.md#1-purpose history : # string, nanoseconds since Unix epoch or RFC3339 format. # if set, the history extension type will be a Snapshot request snapshot : # string, nanoseconds since Unix epoch or RFC3339 format. # if set, the history extension type will be a Range request start : # string, nanoseconds since Unix epoch or RFC3339 format. # if set, the history extension type will be a Range request end : Examples: # part of ~/gnmic.yml config file subscriptions : # container for subscriptions port_stats : # a named subscription, a key is a name paths : # list of subscription paths for that named subscription - \"/state/port[port-id=1/1/c1/1]/statistics/out-octets\" - \"/state/port[port-id=1/1/c1/1]/statistics/in-octets\" stream-mode : sample # one of [on-change target-defined sample] sample-interval : 5s encoding : bytes service_state : paths : - \"/state/service/vpls[service-name=*]/oper-state\" - \"/state/service/vprn[service-name=*]/oper-state\" stream-mode : on-change system_facts : paths : - \"/configure/system/name\" - \"/state/system/version\" mode : once Inside that subscriptions container a user defines individual named subscriptions; in the example above two named subscriptions port_stats and service_state were defined. These subscriptions can be used on the cli via the [ --name ] flag of subscribe command: gnmic subscribe --name service_state --name port_stats Or by binding them to different targets, (see next section)","title":"Defining subscriptions"},{"location":"user_guide/subscriptions/#binding-subscriptions","text":"Once the subscriptions are defined, they can be flexibly associated with the targets. # part of ~/gnmic.yml config file targets : router1.lab.com : username : admin password : secret subscriptions : - port_stats - service_state router2.lab.com : username : gnmi password : telemetry subscriptions : - service_state The named subscriptions are put under the subscriptions section of a target container. As shown in the example above, it is allowed to add multiple named subscriptions under a single target; in that case each named subscription will result in a separate Subscription Request towards a target. Note If a target is not explicitly associated with any subscription, the client will subscribe to all defined subscriptions in the file. The full configuration with the subscriptions defined and associated with targets will look like this: username : admin password : nokiasr0s insecure : true targets : router1.lab.com : subscriptions : - port_stats - service_state - system_facts router2.lab.com : subscriptions : - service_state - system_facts subscriptions : port_stats : paths : - \"/state/port[port-id=1/1/c1/1]/statistics/out-octets\" - \"/state/port[port-id=1/1/c1/1]/statistics/in-octets\" stream-mode : sample sample-interval : 5s encoding : bytes service_state : paths : - \"/state/service/vpls[service-name=*]/oper-state\" - \"/state/service/vprn[service-name=*]/oper-state\" stream-mode : on-change system_facts : paths : - \"/configure/system/name\" - \"/state/system/version\" mode : once As a result of such configuration the gnmic will set up three gNMI subscriptions to router1 and two other gNMI subscriptions to router2: $ gnmic subscribe gnmic 2020 /07/06 22 :03:35.579942 target 'router2.lab.com' initialized gnmic 2020 /07/06 22 :03:35.593082 target 'router1.lab.com' initialized { \"source\" : \"router2.lab.com\" , \"subscription-name\" : \"service_state\" , \"timestamp\" : 1594065869313065895 , \"time\" : \"2020-07-06T22:04:29.313065895+02:00\" , \"prefix\" : \"state/service/vpls[service-name=testvpls]\" , \"updates\" : [ { \"Path\" : \"oper-state\" , \"values\" : { \"oper-state\" : \"down\" } } ] } { \"source\" : \"router1.lab.com\" , \"subscription-name\" : \"service_state\" , \"timestamp\" : 1594065868850351364 , \"time\" : \"2020-07-06T22:04:28.850351364+02:00\" , \"prefix\" : \"state/service/vpls[service-name=test]\" , \"updates\" : [ { \"Path\" : \"oper-state\" , \"values\" : { \"oper-state\" : \"down\" } } ] } { \"source\" : \"router1.lab.com\" , \"subscription-name\" : \"port_stats\" , \"timestamp\" : 1594065873938155916 , \"time\" : \"2020-07-06T22:04:33.938155916+02:00\" , \"prefix\" : \"state/port[port-id=1/1/c1/1]/statistics\" , \"updates\" : [ { \"Path\" : \"in-octets\" , \"values\" : { \"in-octets\" : \"671552\" } } ] } { \"source\" : \"router1.lab.com\" , \"subscription-name\" : \"port_stats\" , \"timestamp\" : 1594065873938043848 , \"time\" : \"2020-07-06T22:04:33.938043848+02:00\" , \"prefix\" : \"state/port[port-id=1/1/c1/1]/statistics\" , \"updates\" : [ { \"Path\" : \"out-octets\" , \"values\" : { \"out-octets\" : \"370930\" } } ] } ^C received sig nal 'i nterru p t '. ter mi nat i n g...","title":"Binding subscriptions"},{"location":"user_guide/targets/","text":"Targets # Sometimes it is needed to perform an operation on multiple devices; be it getting the same leaf value from a given set of the network elements or setting a certain configuration element to some value. For cases like that gnmic offers support for multiple targets operations which a user can configure both via CLI flags as well as with the file-based configuration . CLI configuration # Specifying multiple targets in the CLI is as easy as repeating the --address flag. \u276f gnmic -a router1.lab.net:57400 \\ -a router2.lab.net:57400 \\ get --path /configure/system/name File-based configuration # With the file-based configuration a user has two options to specify multiple targets: using address option using targets option address option # With address option the user must provide a list of addresses. In the YAML format that would look like that: address : - \"router1.lab.net:57400\" - \"router2.lab.net:57400\" The limitation this approach has is that it is impossible to set different credentials for the targets, they will essentially share the credentials specified in a file or via flags. target option # With the targets option it is possible to set target specific options (such as credentials, subscriptions, TLS config, outputs), and thus this option is recommended to use: targets : router1.lab.net : timeout : 2s username : r1 password : gnmi_pass router2.lab.net:57000 : username : r2 password : gnmi_pass tls-key : /path/file1 tls-cert : /path/file2 The target address is defined as the key under the targets section of the configuration file. The default port (57400) can be omitted as demonstrated with router1.lab.net target address. Have a look at the file-based targets configuration example to get a glimpse of what it is capable of. The target inherits the globally defined options if the matching options are not set on a target level. For example, if a target doesn't have a username defined, it will use the username value set on a global level. secure/insecure connections # gnmic supports both secure and insecure gRPC connections to the target. insecure connection # Using the --insecure flag it is possible to establish an insecure gRPC connection to the target. gnmic -a router1:57400 \\ --insecure \\ get --path /configure/system/name secure connection # A one way secure connection without target certificate verification can be established using the --skip-verify flag. gnmic -a router1:57400 \\ --skip-verify \\ get --path /configure/system/name Adding target certificate verification can be done using the --tls-ca flag. gnmic -a router1:57400 \\ --tls-ca /path/to/ca/file \\ get --path /configure/system/name A two way secure connection can be established using the --tls-cert --tls-key flags. gnmic -a router1:57400 \\ --tls-cert /path/to/certificate/file \\ --tls-key /path/to/certificate/file \\ get --path /configure/system/name It is also possible to control the negotiated TLS version using the --tls-min-version , --tls-max-version and --tls-version (preferred TLS version) flags. target configuration options # Target supported options: targets : # target name or an address (IP or DNS name). # if an address is set it can include a port number or not, # if a port is not included, the default gRPC port will be added. target_key : # target name, will default to the target_key if not specified name : target_key # target address, if missing the target_key is used as an address. # supports comma separated addresses. # if any of the addresses is missing a port, the default gRPC port will be added. # if multiple addresses are set, all of them will be tried simultaneously, # the first established gRPC connection will be used, the other attempts will be canceled. address : # target username username : # target password password : # authentication token, # applied only in the case of a secure gRPC connection. token : # target RPC timeout timeout : # establish an insecure connection insecure : # path to tls ca file tls-ca : # path to tls certificate tls-cert : # path to tls key tls-key : # max tls version to use during negotiation tls-max-version : # min tls version to use during negotiation tls-min-version : # preferred tls version to use during negotiation tls-version : # enable logging of a pre-master TLS secret log-tls-secret : # do not verify the target certificate when using tls skip-verify : # list of subscription names to establish for this target. # if empty it defaults to all subscriptions defined under # the main level `subscriptions` field subscriptions : # list of output names to which the gnmi data will be written. # if empty if defaults to all outputs defined under # the main level `outputs` field outputs : # number of subscribe responses to keep in buffer before writing # the target outputs buffer-size : # target retry period retry : # list of tags, relevant when clustering is enabled. tags : # a mapping of static tags to add to all events from this target. # each key/value pair in this mapping will be added to metadata # on all events event-tags : # list of proto file names to decode protoBytes values proto-files : # list of directories to look for the proto files proto-dirs : # enable grpc gzip compression gzip : # proxy type and address, only SOCKS5 is supported currently # example: socks5://<address>:<port> proxy : Example # Whatever configuration option you choose, the multi-targeted operations will uniformly work across the commands that support them. Consider the get command acting on two routers getting their names: \u276f gnmic -a router1.lab.net:57400 \\ -a router2.lab.net:57400 \\ get --path /configure/system/name [ router1.lab.net:57400 ] { [ router1.lab.net:57400 ] \"source\" : \"router1.lab.net:57400\" , [ router1.lab.net:57400 ] \"timestamp\" : 1593009759618786781 , [ router1.lab.net:57400 ] \"time\" : \"2020-06-24T16:42:39.618786781+02:00\" , [ router1.lab.net:57400 ] \"updates\" : [ [ router1.lab.net:57400 ] { [ router1.lab.net:57400 ] \"Path\" : \"configure/system/name\" , [ router1.lab.net:57400 ] \"values\" : { [ router1.lab.net:57400 ] \"configure/system/name\" : \"gnmic_r1\" [ router1.lab.net:57400 ] } [ router1.lab.net:57400 ] } [ router1.lab.net:57400 ] ] [ router1.lab.net:57400 ] } [ router2.lab.net:57400 ] { [ router2.lab.net:57400 ] \"source\" : \"router2.lab.net:57400\" , [ router2.lab.net:57400 ] \"timestamp\" : 1593009759748265232 , [ router2.lab.net:57400 ] \"time\" : \"2020-06-24T16:42:39.748265232+02:00\" , [ router2.lab.net:57400 ] \"updates\" : [ [ router2.lab.net:57400 ] { [ router2.lab.net:57400 ] \"Path\" : \"configure/system/name\" , [ router2.lab.net:57400 ] \"values\" : { [ router2.lab.net:57400 ] \"configure/system/name\" : \"gnmic_r2\" [ router2.lab.net:57400 ] } [ router2.lab.net:57400 ] } [ router2.lab.net:57400 ] ] [ router2.lab.net:57400 ] } Notice how in the output the different gNMI targets are prefixed with the target address to make the output easy to read. If those prefixes are not needed, you can make them disappear with --no-prefix global flag.","title":"Configuration"},{"location":"user_guide/targets/#targets","text":"Sometimes it is needed to perform an operation on multiple devices; be it getting the same leaf value from a given set of the network elements or setting a certain configuration element to some value. For cases like that gnmic offers support for multiple targets operations which a user can configure both via CLI flags as well as with the file-based configuration .","title":"Targets"},{"location":"user_guide/targets/#cli-configuration","text":"Specifying multiple targets in the CLI is as easy as repeating the --address flag. \u276f gnmic -a router1.lab.net:57400 \\ -a router2.lab.net:57400 \\ get --path /configure/system/name","title":"CLI configuration"},{"location":"user_guide/targets/#file-based-configuration","text":"With the file-based configuration a user has two options to specify multiple targets: using address option using targets option","title":"File-based configuration"},{"location":"user_guide/targets/#address-option","text":"With address option the user must provide a list of addresses. In the YAML format that would look like that: address : - \"router1.lab.net:57400\" - \"router2.lab.net:57400\" The limitation this approach has is that it is impossible to set different credentials for the targets, they will essentially share the credentials specified in a file or via flags.","title":"address option"},{"location":"user_guide/targets/#target-option","text":"With the targets option it is possible to set target specific options (such as credentials, subscriptions, TLS config, outputs), and thus this option is recommended to use: targets : router1.lab.net : timeout : 2s username : r1 password : gnmi_pass router2.lab.net:57000 : username : r2 password : gnmi_pass tls-key : /path/file1 tls-cert : /path/file2 The target address is defined as the key under the targets section of the configuration file. The default port (57400) can be omitted as demonstrated with router1.lab.net target address. Have a look at the file-based targets configuration example to get a glimpse of what it is capable of. The target inherits the globally defined options if the matching options are not set on a target level. For example, if a target doesn't have a username defined, it will use the username value set on a global level.","title":"target option"},{"location":"user_guide/targets/#secureinsecure-connections","text":"gnmic supports both secure and insecure gRPC connections to the target.","title":"secure/insecure connections"},{"location":"user_guide/targets/#insecure-connection","text":"Using the --insecure flag it is possible to establish an insecure gRPC connection to the target. gnmic -a router1:57400 \\ --insecure \\ get --path /configure/system/name","title":"insecure connection"},{"location":"user_guide/targets/#secure-connection","text":"A one way secure connection without target certificate verification can be established using the --skip-verify flag. gnmic -a router1:57400 \\ --skip-verify \\ get --path /configure/system/name Adding target certificate verification can be done using the --tls-ca flag. gnmic -a router1:57400 \\ --tls-ca /path/to/ca/file \\ get --path /configure/system/name A two way secure connection can be established using the --tls-cert --tls-key flags. gnmic -a router1:57400 \\ --tls-cert /path/to/certificate/file \\ --tls-key /path/to/certificate/file \\ get --path /configure/system/name It is also possible to control the negotiated TLS version using the --tls-min-version , --tls-max-version and --tls-version (preferred TLS version) flags.","title":"secure connection"},{"location":"user_guide/targets/#target-configuration-options","text":"Target supported options: targets : # target name or an address (IP or DNS name). # if an address is set it can include a port number or not, # if a port is not included, the default gRPC port will be added. target_key : # target name, will default to the target_key if not specified name : target_key # target address, if missing the target_key is used as an address. # supports comma separated addresses. # if any of the addresses is missing a port, the default gRPC port will be added. # if multiple addresses are set, all of them will be tried simultaneously, # the first established gRPC connection will be used, the other attempts will be canceled. address : # target username username : # target password password : # authentication token, # applied only in the case of a secure gRPC connection. token : # target RPC timeout timeout : # establish an insecure connection insecure : # path to tls ca file tls-ca : # path to tls certificate tls-cert : # path to tls key tls-key : # max tls version to use during negotiation tls-max-version : # min tls version to use during negotiation tls-min-version : # preferred tls version to use during negotiation tls-version : # enable logging of a pre-master TLS secret log-tls-secret : # do not verify the target certificate when using tls skip-verify : # list of subscription names to establish for this target. # if empty it defaults to all subscriptions defined under # the main level `subscriptions` field subscriptions : # list of output names to which the gnmi data will be written. # if empty if defaults to all outputs defined under # the main level `outputs` field outputs : # number of subscribe responses to keep in buffer before writing # the target outputs buffer-size : # target retry period retry : # list of tags, relevant when clustering is enabled. tags : # a mapping of static tags to add to all events from this target. # each key/value pair in this mapping will be added to metadata # on all events event-tags : # list of proto file names to decode protoBytes values proto-files : # list of directories to look for the proto files proto-dirs : # enable grpc gzip compression gzip : # proxy type and address, only SOCKS5 is supported currently # example: socks5://<address>:<port> proxy :","title":"target configuration options"},{"location":"user_guide/targets/#example","text":"Whatever configuration option you choose, the multi-targeted operations will uniformly work across the commands that support them. Consider the get command acting on two routers getting their names: \u276f gnmic -a router1.lab.net:57400 \\ -a router2.lab.net:57400 \\ get --path /configure/system/name [ router1.lab.net:57400 ] { [ router1.lab.net:57400 ] \"source\" : \"router1.lab.net:57400\" , [ router1.lab.net:57400 ] \"timestamp\" : 1593009759618786781 , [ router1.lab.net:57400 ] \"time\" : \"2020-06-24T16:42:39.618786781+02:00\" , [ router1.lab.net:57400 ] \"updates\" : [ [ router1.lab.net:57400 ] { [ router1.lab.net:57400 ] \"Path\" : \"configure/system/name\" , [ router1.lab.net:57400 ] \"values\" : { [ router1.lab.net:57400 ] \"configure/system/name\" : \"gnmic_r1\" [ router1.lab.net:57400 ] } [ router1.lab.net:57400 ] } [ router1.lab.net:57400 ] ] [ router1.lab.net:57400 ] } [ router2.lab.net:57400 ] { [ router2.lab.net:57400 ] \"source\" : \"router2.lab.net:57400\" , [ router2.lab.net:57400 ] \"timestamp\" : 1593009759748265232 , [ router2.lab.net:57400 ] \"time\" : \"2020-06-24T16:42:39.748265232+02:00\" , [ router2.lab.net:57400 ] \"updates\" : [ [ router2.lab.net:57400 ] { [ router2.lab.net:57400 ] \"Path\" : \"configure/system/name\" , [ router2.lab.net:57400 ] \"values\" : { [ router2.lab.net:57400 ] \"configure/system/name\" : \"gnmic_r2\" [ router2.lab.net:57400 ] } [ router2.lab.net:57400 ] } [ router2.lab.net:57400 ] ] [ router2.lab.net:57400 ] } Notice how in the output the different gNMI targets are prefixed with the target address to make the output easy to read. If those prefixes are not needed, you can make them disappear with --no-prefix global flag.","title":"Example"},{"location":"user_guide/tunnel_server/","text":"Tunnel Server # Introduction # gNMIc supports gNMI Dial-out as defined by openconfig/grpctunnel . gNMIc embeds a tunnel server to which the gNMI targets register. Once registered, gNMIc triggers the request gNMI RPC towards the target via the established tunnel. This use case is described here Server operation # When running a Subscribe RPC using gNMIc with the flag --use-tunnel-server , gNMIc starts by running the Tunnel server as defined under tunnel-server . The next steps depend on the type of RPC (Unary/Stream) and/or Subscribe Mode (poll/once/stream) Unary RPCs # gNMIc waits for tunnel-server.target-wait-time for targets to register with the tunnel server, after which it requests a new session from the server for the specified target(s) and runs the RPC through the newly established tunnel. Note that if no target is specified, the RPC runs for all registered targets. $ cat tunnel_server_config.yaml insecure: true log: true username: admin password: admin tunnel-server: address: \":57401\" $ gnmic --config tunnel_server_config.yaml \\ --use-tunnel-server \\ get \\ --path /configure/system/name 2022 /03/09 10 :12:34.729037 [ gnmic ] version = dev, commit = none, date = unknown, gitURL = , docs = https://gnmic.kmrd.dev 2022 /03/09 10 :12:34.729063 [ gnmic ] using config file \"tunnel_server_config.yaml\" 2022 /03/09 10 :12:34.730472 [ gnmic ] waiting for targets to register with the tunnel server... 2022 /03/09 10 :12:36.435521 [ gnmic ] tunnel server discovered target { ID:sr1 Type:GNMI_GNOI } 2022 /03/09 10 :12:36.436332 [ gnmic ] tunnel server discovered target { ID:sr2 Type:GNMI_GNOI } 2022 /03/09 10 :12:36.731125 [ gnmic ] adding target { \"name\" : \"sr1\" , \"address\" : \"sr1\" , \"username\" : \"admin\" , \"password\" : \"admin\" , \"timeout\" :10000000000, \"insecure\" :true, \"skip-verify\" :false, \"subscriptions\" : [ \"sub1\" ] , \"retry-timer\" :10000000000, \"log-tls-secret\" :false, \"gzip\" :false, \"token\" : \"\" } 2022 /03/09 10 :12:36.731158 [ gnmic ] adding target { \"name\" : \"sr2\" , \"address\" : \"sr2\" , \"username\" : \"admin\" , \"password\" : \"admin\" , \"timeout\" :10000000000, \"insecure\" :true, \"skip-verify\" :false, \"subscriptions\" : [ \"sub1\" ] , \"retry-timer\" :10000000000, \"log-tls-secret\" :false, \"gzip\" :false, \"token\" : \"\" } 2022 /03/09 10 :12:36.731651 [ gnmic ] sending gNMI GetRequest: prefix = '<nil>' , path = '[elem:{name:\"configure\"} elem:{name:\"system\"} elem:{name:\"name\"}]' , type = 'ALL' , encoding = 'JSON' , models = '[]' , extension = '[]' to sr1 2022 /03/09 10 :12:36.731742 [ gnmic ] sending gNMI GetRequest: prefix = '<nil>' , path = '[elem:{name:\"configure\"} elem:{name:\"system\"} elem:{name:\"name\"}]' , type = 'ALL' , encoding = 'JSON' , models = '[]' , extension = '[]' to sr2 2022 /03/09 10 :12:36.732337 [ gnmic ] dialing tunnel connection for tunnel target \"sr2\" 2022 /03/09 10 :12:36.732572 [ gnmic ] dialing tunnel connection for tunnel target \"sr1\" [ sr1 ] [ [ sr1 ] { [ sr1 ] \"source\" : \"sr1\" , [ sr1 ] \"timestamp\" : 1646849561604621769 , [ sr1 ] \"time\" : \"2022-03-09T10:12:41.604621769-08:00\" , [ sr1 ] \"updates\" : [ [ sr1 ] { [ sr1 ] \"Path\" : \"configure/system/name\" , [ sr1 ] \"values\" : { [ sr1 ] \"configure/system/name\" : \"sr1\" [ sr1 ] } [ sr1 ] } [ sr1 ] ] [ sr1 ] } [ sr1 ] ] [ sr2 ] [ [ sr2 ] { [ sr2 ] \"source\" : \"sr2\" , [ sr2 ] \"timestamp\" : 1646849562004804732 , [ sr2 ] \"time\" : \"2022-03-09T10:12:42.004804732-08:00\" , [ sr2 ] \"updates\" : [ [ sr2 ] { [ sr2 ] \"Path\" : \"configure/system/name\" , [ sr2 ] \"values\" : { [ sr2 ] \"configure/system/name\" : \"sr2\" [ sr2 ] } [ sr2 ] } [ sr2 ] ] [ sr2 ] } [ sr2 ] ] Subscribe RPC # Poll and Once subscription # When a Poll or Once subscription are requested, gNMIc behaves the same way as for a unary RPC, i.e waits for targets to register then runs the RPC. Stream subscription # In the case of a stream subscription, gNMIc triggers the Subscribe RPC as soon as a target registers. Similarly, a stream subscription will be stopped when a target deregisters from the tunnel server. Configuration # tunnel-server : # the address the tunnel server will listen to address : # if true, the server will not verify the client's certificates skip-verify : false # path to the CA certificate file to be used, irrelevant if `skip-verify` is true ca-file : # path to the server certificate file cert-file : # path to the server key file key-file : # the wait time before triggering unary RPCs or subscribe poll/once target-wait-time : 2s # enables the collection of Prometheus gRPC server metrics enable-metrics : false # enable additional debug logs debug : false Combining Tunnel server with a gNMI server # It is possible to start gNMIc with both a gnmi-server and tunnel-server enabled. This mode allows to run gNMI RPCs against gNMIc 's gNMI server, they will routed to the relevant targets ( --target flag) or to all known target (i.e registered targets) The configuration file would look like: insecure : true username : admin password : admin subscriptions : sub1 : paths : - /state/port sample-interface : 10s gnmi-server : address : :57400 tunnel-server : address : :57401 targets : - id : .* type : GNMI_GNOI config : subscriptions : - sub1 Running a Get RPC towards all registered targets $ gnmic -a localhost:57400 --insecure get \\ --path /configure/system/name [ { \"source\" : \"localhost\" , \"timestamp\" : 1646850987401608313 , \"time\" : \"2022-03-09T10:36:27.401608313-08:00\" , \"target\" : \"sr2\" , \"updates\" : [ { \"Path\" : \"configure/system/name\" , \"values\" : { \"configure/system/name\" : \"sr2\" } } ] } , { \"source\" : \"localhost\" , \"timestamp\" : 1646850987205206394 , \"time\" : \"2022-03-09T10:36:27.205206394-08:00\" , \"target\" : \"sr1\" , \"updates\" : [ { \"Path\" : \"configure/system/name\" , \"values\" : { \"configure/system/name\" : \"sr1\" } } ] } ] Running a Get RPC towards a single target $ gnmic -a localhost:57400 --insecure \\ --target sr1 \\ get --path /configure/system/name [ { \"source\" : \"localhost\" , \"timestamp\" : 1646851044004381267 , \"time\" : \"2022-03-09T10:37:24.004381267-08:00\" , \"target\" : \"sr1\" , \"updates\" : [ { \"Path\" : \"configure/system/name\" , \"values\" : { \"configure/system/name\" : \"sr1\" } } ] } ] For detailed configuration of the gnmi-server check this page","title":"Tunnel Server"},{"location":"user_guide/tunnel_server/#tunnel-server","text":"","title":"Tunnel Server"},{"location":"user_guide/tunnel_server/#introduction","text":"gNMIc supports gNMI Dial-out as defined by openconfig/grpctunnel . gNMIc embeds a tunnel server to which the gNMI targets register. Once registered, gNMIc triggers the request gNMI RPC towards the target via the established tunnel. This use case is described here","title":"Introduction"},{"location":"user_guide/tunnel_server/#server-operation","text":"When running a Subscribe RPC using gNMIc with the flag --use-tunnel-server , gNMIc starts by running the Tunnel server as defined under tunnel-server . The next steps depend on the type of RPC (Unary/Stream) and/or Subscribe Mode (poll/once/stream)","title":"Server operation"},{"location":"user_guide/tunnel_server/#unary-rpcs","text":"gNMIc waits for tunnel-server.target-wait-time for targets to register with the tunnel server, after which it requests a new session from the server for the specified target(s) and runs the RPC through the newly established tunnel. Note that if no target is specified, the RPC runs for all registered targets. $ cat tunnel_server_config.yaml insecure: true log: true username: admin password: admin tunnel-server: address: \":57401\" $ gnmic --config tunnel_server_config.yaml \\ --use-tunnel-server \\ get \\ --path /configure/system/name 2022 /03/09 10 :12:34.729037 [ gnmic ] version = dev, commit = none, date = unknown, gitURL = , docs = https://gnmic.kmrd.dev 2022 /03/09 10 :12:34.729063 [ gnmic ] using config file \"tunnel_server_config.yaml\" 2022 /03/09 10 :12:34.730472 [ gnmic ] waiting for targets to register with the tunnel server... 2022 /03/09 10 :12:36.435521 [ gnmic ] tunnel server discovered target { ID:sr1 Type:GNMI_GNOI } 2022 /03/09 10 :12:36.436332 [ gnmic ] tunnel server discovered target { ID:sr2 Type:GNMI_GNOI } 2022 /03/09 10 :12:36.731125 [ gnmic ] adding target { \"name\" : \"sr1\" , \"address\" : \"sr1\" , \"username\" : \"admin\" , \"password\" : \"admin\" , \"timeout\" :10000000000, \"insecure\" :true, \"skip-verify\" :false, \"subscriptions\" : [ \"sub1\" ] , \"retry-timer\" :10000000000, \"log-tls-secret\" :false, \"gzip\" :false, \"token\" : \"\" } 2022 /03/09 10 :12:36.731158 [ gnmic ] adding target { \"name\" : \"sr2\" , \"address\" : \"sr2\" , \"username\" : \"admin\" , \"password\" : \"admin\" , \"timeout\" :10000000000, \"insecure\" :true, \"skip-verify\" :false, \"subscriptions\" : [ \"sub1\" ] , \"retry-timer\" :10000000000, \"log-tls-secret\" :false, \"gzip\" :false, \"token\" : \"\" } 2022 /03/09 10 :12:36.731651 [ gnmic ] sending gNMI GetRequest: prefix = '<nil>' , path = '[elem:{name:\"configure\"} elem:{name:\"system\"} elem:{name:\"name\"}]' , type = 'ALL' , encoding = 'JSON' , models = '[]' , extension = '[]' to sr1 2022 /03/09 10 :12:36.731742 [ gnmic ] sending gNMI GetRequest: prefix = '<nil>' , path = '[elem:{name:\"configure\"} elem:{name:\"system\"} elem:{name:\"name\"}]' , type = 'ALL' , encoding = 'JSON' , models = '[]' , extension = '[]' to sr2 2022 /03/09 10 :12:36.732337 [ gnmic ] dialing tunnel connection for tunnel target \"sr2\" 2022 /03/09 10 :12:36.732572 [ gnmic ] dialing tunnel connection for tunnel target \"sr1\" [ sr1 ] [ [ sr1 ] { [ sr1 ] \"source\" : \"sr1\" , [ sr1 ] \"timestamp\" : 1646849561604621769 , [ sr1 ] \"time\" : \"2022-03-09T10:12:41.604621769-08:00\" , [ sr1 ] \"updates\" : [ [ sr1 ] { [ sr1 ] \"Path\" : \"configure/system/name\" , [ sr1 ] \"values\" : { [ sr1 ] \"configure/system/name\" : \"sr1\" [ sr1 ] } [ sr1 ] } [ sr1 ] ] [ sr1 ] } [ sr1 ] ] [ sr2 ] [ [ sr2 ] { [ sr2 ] \"source\" : \"sr2\" , [ sr2 ] \"timestamp\" : 1646849562004804732 , [ sr2 ] \"time\" : \"2022-03-09T10:12:42.004804732-08:00\" , [ sr2 ] \"updates\" : [ [ sr2 ] { [ sr2 ] \"Path\" : \"configure/system/name\" , [ sr2 ] \"values\" : { [ sr2 ] \"configure/system/name\" : \"sr2\" [ sr2 ] } [ sr2 ] } [ sr2 ] ] [ sr2 ] } [ sr2 ] ]","title":"Unary RPCs"},{"location":"user_guide/tunnel_server/#subscribe-rpc","text":"","title":"Subscribe RPC"},{"location":"user_guide/tunnel_server/#poll-and-once-subscription","text":"When a Poll or Once subscription are requested, gNMIc behaves the same way as for a unary RPC, i.e waits for targets to register then runs the RPC.","title":"Poll and Once subscription"},{"location":"user_guide/tunnel_server/#stream-subscription","text":"In the case of a stream subscription, gNMIc triggers the Subscribe RPC as soon as a target registers. Similarly, a stream subscription will be stopped when a target deregisters from the tunnel server.","title":"Stream subscription"},{"location":"user_guide/tunnel_server/#configuration","text":"tunnel-server : # the address the tunnel server will listen to address : # if true, the server will not verify the client's certificates skip-verify : false # path to the CA certificate file to be used, irrelevant if `skip-verify` is true ca-file : # path to the server certificate file cert-file : # path to the server key file key-file : # the wait time before triggering unary RPCs or subscribe poll/once target-wait-time : 2s # enables the collection of Prometheus gRPC server metrics enable-metrics : false # enable additional debug logs debug : false","title":"Configuration"},{"location":"user_guide/tunnel_server/#combining-tunnel-server-with-a-gnmi-server","text":"It is possible to start gNMIc with both a gnmi-server and tunnel-server enabled. This mode allows to run gNMI RPCs against gNMIc 's gNMI server, they will routed to the relevant targets ( --target flag) or to all known target (i.e registered targets) The configuration file would look like: insecure : true username : admin password : admin subscriptions : sub1 : paths : - /state/port sample-interface : 10s gnmi-server : address : :57400 tunnel-server : address : :57401 targets : - id : .* type : GNMI_GNOI config : subscriptions : - sub1 Running a Get RPC towards all registered targets $ gnmic -a localhost:57400 --insecure get \\ --path /configure/system/name [ { \"source\" : \"localhost\" , \"timestamp\" : 1646850987401608313 , \"time\" : \"2022-03-09T10:36:27.401608313-08:00\" , \"target\" : \"sr2\" , \"updates\" : [ { \"Path\" : \"configure/system/name\" , \"values\" : { \"configure/system/name\" : \"sr2\" } } ] } , { \"source\" : \"localhost\" , \"timestamp\" : 1646850987205206394 , \"time\" : \"2022-03-09T10:36:27.205206394-08:00\" , \"target\" : \"sr1\" , \"updates\" : [ { \"Path\" : \"configure/system/name\" , \"values\" : { \"configure/system/name\" : \"sr1\" } } ] } ] Running a Get RPC towards a single target $ gnmic -a localhost:57400 --insecure \\ --target sr1 \\ get --path /configure/system/name [ { \"source\" : \"localhost\" , \"timestamp\" : 1646851044004381267 , \"time\" : \"2022-03-09T10:37:24.004381267-08:00\" , \"target\" : \"sr1\" , \"updates\" : [ { \"Path\" : \"configure/system/name\" , \"values\" : { \"configure/system/name\" : \"sr1\" } } ] } ] For detailed configuration of the gnmi-server check this page","title":"Combining Tunnel server with a gNMI server"},{"location":"user_guide/actions/actions/","text":"Actions # gNMIc supports running actions as result of an event, possible triggering events are: A gNMI SubscribeResponse or GetReponse message is received and matches certain criteria. A target is discovered or deleted by a target loader. There are 4 types of actions: http : build and send an HTTP request gNMI : run a Get, Set or Subscribe ONCE gNMI RPC as a gNMI client template : execute a Go template against the received input script : run arbitrary shell scripts/commands. The actions are executed in sequence. An action can use the result of any previous action as one of it inputs using the Go Template syntax {{ .Env.$action_name }} or {{ index .Env \"$action_name\"}} HTTP Action # Using the HTTP action you can send an HTTP request to a server. The request body can be customized using Go Templates that take the event message or the discovered target as input. actions : counter1_alert : # action type type : http # HTTP method method : POST # target url, can be a go template url : http://remote-server:8080/ # http headers to add to the request headers : content-type : application/text # http request timeout timeout : 5s # go template used to build the request body. # if left empty the whole event message is added as a json object to the request's body body : '\"counter1\" crossed threshold, value={{ index .Values \"counter1\" }}' # enable extra logging debug : false gNMI Action # Using the gNMI action you can trigger a gNMI Get, Set or Subscribe ONCE RPC. Just like the HTTP action the RPC fields can be customized using Go Templates actions : my_gnmi_action : # action type type : gnmi # gNMI rpc, defaults to `get`, # if `set` is used it will default to a set update. # to trigger a set replace, use `set-replace`. # `subscribe` is always a subscribe with mode=ONCE # possible values: `get`, `set`, `set-update`, `set-replace`, `set-delete`, `sub`, `subscribe` rpc : set # the target router, it defaults to the value in tag \"source\" # the value `all` means all known targets target : '{{ index .Event.Tags \"source\" }}' # paths templates to build xpaths paths : - | {{ if eq ( index .Event.Tags \"interface_name\" ) \"ethernet-1/1\"}} {{$interfaceName := \"ethernet-1/2\"}} {{else}} {{$interfaceName := \"ethernet-1/1\"}} {{end}} /interfaces/interface[name={{$interfaceName}}]/admin-state # values templates to build the values in case of set-update or set-replace values : - \"enable\" # data-type in case of get RPC, one of: ALL, CONFIG, STATE, OPERATIONAL data-type : ALL # gNMI encoding, defaults to json encoding : json # debug, enable extra logging debug : false Template Action # The Template action allows to combine different data sources and produce custom payloads to be writen to a remote server or simply to a file. The template is a Go Template that is executed against the Input message that triggered the action, any variable defined by the trigger processor as well as the results of any previous action. Data Template syntax Input Messge {{ .Input }} Trigger Variables {{ .Vars }} Previous actions results {{ .Env.$action_name }} or {{ index .Env \"$action_name\"}} actions : awesome_template : # action type type : template # template string, if not present template-file applies. template : '{{ . }}' # path to a file, or a glob. # applies only if `.template `is not set. # if not template and template-file are not set, # the default template `{{ . }}` is used. template-file : # string, either `stdout` or a path to a file # the result of executing to template will be written to the file # specified by .output output : # debug, enable extra logging debug : false Script Action # The Script action allows to run arbitrary scripts as a result of an event trigger. The commands to be executed can be specified using the field command , e.g: actions : weather : type : script shell : /bin/bash command : | curl wttr.in curl cheat.sh Or using the field file , e.g: actions : exec : type : script file : ./my_executable_script.sh When using command , the shell interpreter can be set using shell field. Otherwise it defaults to /bin/bash . Examples # Add basic configuration to targets upon discovery # Referencing Actions under a target loader allows to run then in sequence when a target is discovered. This allows to add some basic configuration to a target upon discovery before starting the gNMI subscriptions In the below example, a docker loader is defined. It discovers Docker containers with label clab-node-kind=srl and adds them as gNMI targets. Before the targets are added to the target's list for subscriptions, a list of actions are executed: config_interfaces , config_subinterfaces and config_network_instances username : admin password : admin skip-verify : true encoding : ascii log : true subscriptions : sub1 : paths : - /interface/statistics - /network-instance/statistics loader : type : docker filters : - containers : - label : clab-node-kind=srl on-add : - config_interfaces - config_sub_interfaces - config_netins outputs : out : type : file format : event filename : /path/to/file actions : config_interfaces : name : config_interfaces type : gnmi target : '{{ .Input }}' rpc : set encoding : json_ietf debug : true paths : - /interface[name=ethernet-1/1]/admin-state - /interface[name=ethernet-1/2]/admin-state values : - enable - enable config_subinterfaces : name : config_subinterfaces type : gnmi target : '{{ .Input }}' rpc : set encoding : json_ietf debug : true paths : - /interface[name=ethernet-1/1]/subinterface[index=0]/admin-state - /interface[name=ethernet-1/2]/subinterface[index=0]/admin-state values : - enable - enable config_network_instances : name : config_network_instances type : gnmi target : '{{ .Input }}' rpc : set encoding : json_ietf debug : true paths : - /network-instance[name=default]/admin-state - /network-instance[name=default]/interface - /network-instance[name=default]/interface values : - enable - '{\"name\": \"ethernet-1/1.0\"}' - '{\"name\": \"ethernet-1/2.0\"}' Clone a network topology and deploy it using containerlab # Using lldp neighbor information it's possible to build a containerlab topology using gnmic actions. In the below confoguration file, an event processor called clone-topology is defined. When triggered it will run a series of actions to gather information (chassis type, lldp neighbors, configuration,...) from the defined targets. It then builds a containerlab topology from a defined template and the gathered info, writes it to a file and runs a clab deploy command. username : admin password : admin skip-verify : true encoding : json_ietf # log: true targets : srl1 : srl2 : srl3 : processors : clone-topology : event-trigger : # debug: true actions : - chassis - lldp - read_config - write_config - clab_topo - deploy_topo actions : chassis : name : chassis type : gnmi target : all rpc : sub encoding : json_ietf #debug: true format : event paths : - /platform/chassis/type lldp : name : lldp type : gnmi target : all rpc : sub encoding : json_ietf #debug: true format : event paths : - /system/lldp/interface[name=ethernet-*] read_config : name : read_config type : gnmi target : all rpc : get data-type : config encoding : json_ietf #debug: true paths : - / write_config : name : write_config type : template template : | {{- range $n, $m := .Env.read_config }} {{- $filename := print $n \".json\"}} {{ file.Write $filename (index $m 0 \"updates\" 0 \"values\" \"\" | data.ToJSONPretty \" \" ) }} {{- end }} #debug: true clab_topo : name : clab_topo type : template #debug: true output : gnmic.clab.yaml template : | name: gNMIc-action-generated topology: defaults: kind: srl kinds: srl: image: ghcr.io/nokia/srlinux:latest nodes: {{- range $n, $m := .Env.lldp }} {{- $type := index $.Env.chassis $n 0 0 \"values\" \"/srl_nokia-platform:platform/srl_nokia-platform-chassis:chassis/type\" }} {{- $type = $type | strings.ReplaceAll \"7220 IXR-D1\" \"ixrd1\" }} {{- $type = $type | strings.ReplaceAll \"7220 IXR-D2\" \"ixrd2\" }} {{- $type = $type | strings.ReplaceAll \"7220 IXR-D3\" \"ixrd3\" }} {{- $type = $type | strings.ReplaceAll \"7250 IXR-6\" \"ixr6\" }} {{- $type = $type | strings.ReplaceAll \"7250 IXR-10\" \"ixr10\" }} {{- $type = $type | strings.ReplaceAll \"7220 IXR-H1\" \"ixrh1\" }} {{- $type = $type | strings.ReplaceAll \"7220 IXR-H2\" \"ixrh2\" }} {{- $type = $type | strings.ReplaceAll \"7220 IXR-H3\" \"ixrh3\" }} {{ $n | strings.TrimPrefix \"clab-test1-\" }}: type: {{ $type }} startup-config: {{ print $n \".json\"}} {{- end }} links: {{- range $n, $m := .Env.lldp }} {{- range $rsp := $m }} {{- range $ev := $rsp }} {{- if index $ev.values \"/srl_nokia-system:system/srl_nokia-lldp:lldp/interface/neighbor/system-name\" }} {{- $node1 := $ev.tags.source | strings.TrimPrefix \"clab-test1-\" }} {{- $iface1 := $ev.tags.interface_name | strings.ReplaceAll \"ethernet-\" \"e\" | strings.ReplaceAll \"/\" \"-\" }} {{- $node2 := index $ev.values \"/srl_nokia-system:system/srl_nokia-lldp:lldp/interface/neighbor/system-name\" }} {{- $iface2 := index $ev.values \"/srl_nokia-system:system/srl_nokia-lldp:lldp/interface/neighbor/port-id\" | strings.ReplaceAll \"ethernet-\" \"e\" | strings.ReplaceAll \"/\" \"-\" }} {{- if lt $node1 $node2 }} - endpoints: [\"{{ $node1 }}:{{ $iface1 }}\", \"{{ $node2 }}:{{ $iface2 }}\"] {{- end }} {{- end }} {{- end }} {{- end }} {{- end }} deploy_topo : name : deploy_topo type : script command : sudo clab dep -t gnmic.clab.yaml --reconfigure debug : true The above described processor can be triggered with the below command: gnmic --config clone.yaml get --path /system/name --processor clone-topology","title":"Actions"},{"location":"user_guide/actions/actions/#actions","text":"gNMIc supports running actions as result of an event, possible triggering events are: A gNMI SubscribeResponse or GetReponse message is received and matches certain criteria. A target is discovered or deleted by a target loader. There are 4 types of actions: http : build and send an HTTP request gNMI : run a Get, Set or Subscribe ONCE gNMI RPC as a gNMI client template : execute a Go template against the received input script : run arbitrary shell scripts/commands. The actions are executed in sequence. An action can use the result of any previous action as one of it inputs using the Go Template syntax {{ .Env.$action_name }} or {{ index .Env \"$action_name\"}}","title":"Actions"},{"location":"user_guide/actions/actions/#http-action","text":"Using the HTTP action you can send an HTTP request to a server. The request body can be customized using Go Templates that take the event message or the discovered target as input. actions : counter1_alert : # action type type : http # HTTP method method : POST # target url, can be a go template url : http://remote-server:8080/ # http headers to add to the request headers : content-type : application/text # http request timeout timeout : 5s # go template used to build the request body. # if left empty the whole event message is added as a json object to the request's body body : '\"counter1\" crossed threshold, value={{ index .Values \"counter1\" }}' # enable extra logging debug : false","title":"HTTP Action"},{"location":"user_guide/actions/actions/#gnmi-action","text":"Using the gNMI action you can trigger a gNMI Get, Set or Subscribe ONCE RPC. Just like the HTTP action the RPC fields can be customized using Go Templates actions : my_gnmi_action : # action type type : gnmi # gNMI rpc, defaults to `get`, # if `set` is used it will default to a set update. # to trigger a set replace, use `set-replace`. # `subscribe` is always a subscribe with mode=ONCE # possible values: `get`, `set`, `set-update`, `set-replace`, `set-delete`, `sub`, `subscribe` rpc : set # the target router, it defaults to the value in tag \"source\" # the value `all` means all known targets target : '{{ index .Event.Tags \"source\" }}' # paths templates to build xpaths paths : - | {{ if eq ( index .Event.Tags \"interface_name\" ) \"ethernet-1/1\"}} {{$interfaceName := \"ethernet-1/2\"}} {{else}} {{$interfaceName := \"ethernet-1/1\"}} {{end}} /interfaces/interface[name={{$interfaceName}}]/admin-state # values templates to build the values in case of set-update or set-replace values : - \"enable\" # data-type in case of get RPC, one of: ALL, CONFIG, STATE, OPERATIONAL data-type : ALL # gNMI encoding, defaults to json encoding : json # debug, enable extra logging debug : false","title":"gNMI Action"},{"location":"user_guide/actions/actions/#template-action","text":"The Template action allows to combine different data sources and produce custom payloads to be writen to a remote server or simply to a file. The template is a Go Template that is executed against the Input message that triggered the action, any variable defined by the trigger processor as well as the results of any previous action. Data Template syntax Input Messge {{ .Input }} Trigger Variables {{ .Vars }} Previous actions results {{ .Env.$action_name }} or {{ index .Env \"$action_name\"}} actions : awesome_template : # action type type : template # template string, if not present template-file applies. template : '{{ . }}' # path to a file, or a glob. # applies only if `.template `is not set. # if not template and template-file are not set, # the default template `{{ . }}` is used. template-file : # string, either `stdout` or a path to a file # the result of executing to template will be written to the file # specified by .output output : # debug, enable extra logging debug : false","title":"Template Action"},{"location":"user_guide/actions/actions/#script-action","text":"The Script action allows to run arbitrary scripts as a result of an event trigger. The commands to be executed can be specified using the field command , e.g: actions : weather : type : script shell : /bin/bash command : | curl wttr.in curl cheat.sh Or using the field file , e.g: actions : exec : type : script file : ./my_executable_script.sh When using command , the shell interpreter can be set using shell field. Otherwise it defaults to /bin/bash .","title":"Script Action"},{"location":"user_guide/actions/actions/#examples","text":"","title":"Examples"},{"location":"user_guide/actions/actions/#add-basic-configuration-to-targets-upon-discovery","text":"Referencing Actions under a target loader allows to run then in sequence when a target is discovered. This allows to add some basic configuration to a target upon discovery before starting the gNMI subscriptions In the below example, a docker loader is defined. It discovers Docker containers with label clab-node-kind=srl and adds them as gNMI targets. Before the targets are added to the target's list for subscriptions, a list of actions are executed: config_interfaces , config_subinterfaces and config_network_instances username : admin password : admin skip-verify : true encoding : ascii log : true subscriptions : sub1 : paths : - /interface/statistics - /network-instance/statistics loader : type : docker filters : - containers : - label : clab-node-kind=srl on-add : - config_interfaces - config_sub_interfaces - config_netins outputs : out : type : file format : event filename : /path/to/file actions : config_interfaces : name : config_interfaces type : gnmi target : '{{ .Input }}' rpc : set encoding : json_ietf debug : true paths : - /interface[name=ethernet-1/1]/admin-state - /interface[name=ethernet-1/2]/admin-state values : - enable - enable config_subinterfaces : name : config_subinterfaces type : gnmi target : '{{ .Input }}' rpc : set encoding : json_ietf debug : true paths : - /interface[name=ethernet-1/1]/subinterface[index=0]/admin-state - /interface[name=ethernet-1/2]/subinterface[index=0]/admin-state values : - enable - enable config_network_instances : name : config_network_instances type : gnmi target : '{{ .Input }}' rpc : set encoding : json_ietf debug : true paths : - /network-instance[name=default]/admin-state - /network-instance[name=default]/interface - /network-instance[name=default]/interface values : - enable - '{\"name\": \"ethernet-1/1.0\"}' - '{\"name\": \"ethernet-1/2.0\"}'","title":"Add basic configuration to targets upon discovery"},{"location":"user_guide/actions/actions/#clone-a-network-topology-and-deploy-it-using-containerlab","text":"Using lldp neighbor information it's possible to build a containerlab topology using gnmic actions. In the below confoguration file, an event processor called clone-topology is defined. When triggered it will run a series of actions to gather information (chassis type, lldp neighbors, configuration,...) from the defined targets. It then builds a containerlab topology from a defined template and the gathered info, writes it to a file and runs a clab deploy command. username : admin password : admin skip-verify : true encoding : json_ietf # log: true targets : srl1 : srl2 : srl3 : processors : clone-topology : event-trigger : # debug: true actions : - chassis - lldp - read_config - write_config - clab_topo - deploy_topo actions : chassis : name : chassis type : gnmi target : all rpc : sub encoding : json_ietf #debug: true format : event paths : - /platform/chassis/type lldp : name : lldp type : gnmi target : all rpc : sub encoding : json_ietf #debug: true format : event paths : - /system/lldp/interface[name=ethernet-*] read_config : name : read_config type : gnmi target : all rpc : get data-type : config encoding : json_ietf #debug: true paths : - / write_config : name : write_config type : template template : | {{- range $n, $m := .Env.read_config }} {{- $filename := print $n \".json\"}} {{ file.Write $filename (index $m 0 \"updates\" 0 \"values\" \"\" | data.ToJSONPretty \" \" ) }} {{- end }} #debug: true clab_topo : name : clab_topo type : template #debug: true output : gnmic.clab.yaml template : | name: gNMIc-action-generated topology: defaults: kind: srl kinds: srl: image: ghcr.io/nokia/srlinux:latest nodes: {{- range $n, $m := .Env.lldp }} {{- $type := index $.Env.chassis $n 0 0 \"values\" \"/srl_nokia-platform:platform/srl_nokia-platform-chassis:chassis/type\" }} {{- $type = $type | strings.ReplaceAll \"7220 IXR-D1\" \"ixrd1\" }} {{- $type = $type | strings.ReplaceAll \"7220 IXR-D2\" \"ixrd2\" }} {{- $type = $type | strings.ReplaceAll \"7220 IXR-D3\" \"ixrd3\" }} {{- $type = $type | strings.ReplaceAll \"7250 IXR-6\" \"ixr6\" }} {{- $type = $type | strings.ReplaceAll \"7250 IXR-10\" \"ixr10\" }} {{- $type = $type | strings.ReplaceAll \"7220 IXR-H1\" \"ixrh1\" }} {{- $type = $type | strings.ReplaceAll \"7220 IXR-H2\" \"ixrh2\" }} {{- $type = $type | strings.ReplaceAll \"7220 IXR-H3\" \"ixrh3\" }} {{ $n | strings.TrimPrefix \"clab-test1-\" }}: type: {{ $type }} startup-config: {{ print $n \".json\"}} {{- end }} links: {{- range $n, $m := .Env.lldp }} {{- range $rsp := $m }} {{- range $ev := $rsp }} {{- if index $ev.values \"/srl_nokia-system:system/srl_nokia-lldp:lldp/interface/neighbor/system-name\" }} {{- $node1 := $ev.tags.source | strings.TrimPrefix \"clab-test1-\" }} {{- $iface1 := $ev.tags.interface_name | strings.ReplaceAll \"ethernet-\" \"e\" | strings.ReplaceAll \"/\" \"-\" }} {{- $node2 := index $ev.values \"/srl_nokia-system:system/srl_nokia-lldp:lldp/interface/neighbor/system-name\" }} {{- $iface2 := index $ev.values \"/srl_nokia-system:system/srl_nokia-lldp:lldp/interface/neighbor/port-id\" | strings.ReplaceAll \"ethernet-\" \"e\" | strings.ReplaceAll \"/\" \"-\" }} {{- if lt $node1 $node2 }} - endpoints: [\"{{ $node1 }}:{{ $iface1 }}\", \"{{ $node2 }}:{{ $iface2 }}\"] {{- end }} {{- end }} {{- end }} {{- end }} {{- end }} deploy_topo : name : deploy_topo type : script command : sudo clab dep -t gnmic.clab.yaml --reconfigure debug : true The above described processor can be triggered with the below command: gnmic --config clone.yaml get --path /system/name --processor clone-topology","title":"Clone a network topology and deploy it using containerlab"},{"location":"user_guide/api/api_intro/","text":"A limited set of REST endpoints are supported, these are mainly used to allow for a clustered deployment for multiple gnmic instances. The API can be used to automate (to a certain extent) the targets configuration loading and starting/stopping subscriptions. Configuration # Enabling the API server can be done via a command line flag: gnmic --config gnmic.yaml subscribe --api \":7890\" via ENV variable: GNMIC_API=':7890' Or via file configuration, by adding the below line to the config file: api : \":7890\" More advanced API configuration options (like a secure API Server) can be achieved by setting the fields under api-server . api-server : # string, in the form IP:port, the IP part can be omitted. # if not set, it defaults to the value of `api` in the file main level. # if `api` is not set, the default is `:7890` address : :7890 # duration, the server timeout. # The set value is equally split between read and write timeouts timeout : 10s # boolean, if true, the server will not verify the client's certificates skip-verify : false # path to the CA certificate file to be used, # irrelevant if `skip-verify` is true ca-file : # path to the server certificate file cert-file : # path to the server key file key-file : # boolean, if true, the server will also handle the path /metrics and serve # gNMIc's enabled prometheus metrics. enable-metrics : false # boolean, enables extra debug log printing debug : false API Endpoints # Configuration Targets Cluster","title":"Introduction"},{"location":"user_guide/api/api_intro/#configuration","text":"Enabling the API server can be done via a command line flag: gnmic --config gnmic.yaml subscribe --api \":7890\" via ENV variable: GNMIC_API=':7890' Or via file configuration, by adding the below line to the config file: api : \":7890\" More advanced API configuration options (like a secure API Server) can be achieved by setting the fields under api-server . api-server : # string, in the form IP:port, the IP part can be omitted. # if not set, it defaults to the value of `api` in the file main level. # if `api` is not set, the default is `:7890` address : :7890 # duration, the server timeout. # The set value is equally split between read and write timeouts timeout : 10s # boolean, if true, the server will not verify the client's certificates skip-verify : false # path to the CA certificate file to be used, # irrelevant if `skip-verify` is true ca-file : # path to the server certificate file cert-file : # path to the server key file key-file : # boolean, if true, the server will also handle the path /metrics and serve # gNMIc's enabled prometheus metrics. enable-metrics : false # boolean, enables extra debug log printing debug : false","title":"Configuration"},{"location":"user_guide/api/api_intro/#api-endpoints","text":"Configuration Targets Cluster","title":"API Endpoints"},{"location":"user_guide/api/cluster/","text":"GET /api/v1/cluster # Request gNMIc cluster state and details Returns gNMIc cluster state and details Request curl --request GET gnmic-api-address:port/api/v1/cluster 200 OK { \"name\" : \"collectors\" , \"number-of-locked-targets\" : 70 , \"leader\" : \"clab-telemetry-gnmic1\" , \"members\" : [ { \"name\" : \"clab-telemetry-gnmic1\" , \"api-endpoint\" : \"clab-telemetry-gnmic1:7890\" , \"is-leader\" : true , \"number-of-locked-nodes\" : 23 , \"locked-targets\" : [ \"clab-lab2-leaf6\" , \"clab-lab5-spine2\" , \"clab-lab4-leaf4\" , \"clab-lab2-leaf8\" , \"clab-lab3-leaf2\" , \"clab-lab5-spine1\" , \"clab-lab1-spine1\" , \"clab-lab2-super-spine2\" , \"clab-lab3-super-spine1\" , \"clab-lab4-spine3\" , \"clab-lab2-spine3\" , \"clab-lab3-leaf7\" , \"clab-lab5-leaf7\" , \"clab-lab5-leaf8\" , \"clab-lab1-spine2\" , \"clab-lab4-leaf8\" , \"clab-lab4-leaf1\" , \"clab-lab4-spine1\" , \"clab-lab2-spine2\" , \"clab-lab3-spine2\" , \"clab-lab1-leaf8\" , \"clab-lab3-leaf8\" , \"clab-lab4-leaf2\" ] }, { \"name\" : \"clab-telemetry-gnmic2\" , \"api-endpoint\" : \"clab-telemetry-gnmic2:7891\" , \"number-of-locked-nodes\" : 24 , \"locked-targets\" : [ \"clab-lab3-leaf6\" , \"clab-lab1-leaf7\" , \"clab-lab2-leaf3\" , \"clab-lab5-leaf5\" , \"clab-lab1-super-spine1\" , \"clab-lab3-leaf5\" , \"clab-lab4-super-spine1\" , \"clab-lab5-leaf6\" , \"clab-lab2-spine1\" , \"clab-lab3-leaf3\" , \"clab-lab4-leaf3\" , \"clab-lab2-leaf4\" , \"clab-lab4-super-spine2\" , \"clab-lab1-spine3\" , \"clab-lab3-leaf4\" , \"clab-lab5-spine4\" , \"clab-lab1-leaf4\" , \"clab-lab2-leaf2\" , \"clab-lab2-super-spine1\" , \"clab-lab4-spine4\" , \"clab-lab5-leaf2\" , \"clab-lab5-leaf4\" , \"clab-lab4-leaf7\" , \"clab-lab1-spine4\" ] }, { \"name\" : \"clab-telemetry-gnmic3\" , \"api-endpoint\" : \"clab-telemetry-gnmic3:7892\" , \"number-of-locked-nodes\" : 23 , \"locked-targets\" : [ \"clab-lab1-leaf5\" , \"clab-lab3-spine3\" , \"clab-lab1-leaf1\" , \"clab-lab2-spine4\" , \"clab-lab1-super-spine2\" , \"clab-lab5-leaf3\" , \"clab-lab4-spine2\" , \"clab-lab1-leaf3\" , \"clab-lab5-spine3\" , \"clab-lab3-super-spine2\" , \"clab-lab2-leaf5\" , \"clab-lab1-leaf2\" , \"clab-lab1-leaf6\" , \"clab-lab4-leaf5\" , \"clab-lab2-leaf7\" , \"clab-lab3-leaf1\" , \"clab-lab2-leaf1\" , \"clab-lab3-spine1\" , \"clab-lab5-leaf1\" , \"clab-lab5-super-spine2\" , \"clab-lab4-leaf6\" , \"clab-lab3-spine4\" , \"clab-lab5-super-spine1\" ] } ] } 500 Internal Server Error { \"errors\" : [ \"Error Text\" ] } GET /api/v1/cluster/members # Query gNMIc cluster members Returns a list of gNMIc cluster members with details Request curl --request GET gnmic-api-address:port/api/v1/cluster/members 200 OK [ { \"name\" : \"clab-telemetry-gnmic1\" , \"api-endpoint\" : \"http://clab-telemetry-gnmic1:7890\" , \"is-leader\" : true , \"number-of-locked-nodes\" : 23 , \"locked-targets\" : [ \"clab-lab2-spine3\" , \"clab-lab5-spine1\" , \"clab-lab2-super-spine2\" , \"clab-lab4-leaf2\" , \"clab-lab4-leaf4\" , \"clab-lab5-spine2\" , \"clab-lab1-leaf8\" , \"clab-lab4-spine1\" , \"clab-lab5-leaf7\" , \"clab-lab2-spine2\" , \"clab-lab3-super-spine1\" , \"clab-lab1-spine1\" , \"clab-lab3-leaf2\" , \"clab-lab3-spine2\" , \"clab-lab2-leaf6\" , \"clab-lab4-leaf1\" , \"clab-lab4-spine3\" , \"clab-lab1-spine2\" , \"clab-lab2-leaf8\" , \"clab-lab3-leaf8\" , \"clab-lab5-leaf8\" , \"clab-lab3-leaf7\" , \"clab-lab4-leaf8\" ] }, { \"name\" : \"clab-telemetry-gnmic2\" , \"api-endpoint\" : \"http://clab-telemetry-gnmic2:7891\" , \"number-of-locked-nodes\" : 24 , \"locked-targets\" : [ \"clab-lab1-spine4\" , \"clab-lab2-leaf2\" , \"clab-lab3-leaf3\" , \"clab-lab4-super-spine1\" , \"clab-lab5-leaf4\" , \"clab-lab1-spine3\" , \"clab-lab1-leaf4\" , \"clab-lab3-leaf6\" , \"clab-lab5-leaf2\" , \"clab-lab2-leaf4\" , \"clab-lab3-leaf4\" , \"clab-lab4-leaf3\" , \"clab-lab5-spine4\" , \"clab-lab3-leaf5\" , \"clab-lab4-super-spine2\" , \"clab-lab1-leaf7\" , \"clab-lab2-leaf3\" , \"clab-lab2-super-spine1\" , \"clab-lab5-leaf6\" , \"clab-lab2-spine1\" , \"clab-lab1-super-spine1\" , \"clab-lab4-leaf7\" , \"clab-lab4-spine4\" , \"clab-lab5-leaf5\" ] }, { \"name\" : \"clab-telemetry-gnmic3\" , \"api-endpoint\" : \"http://clab-telemetry-gnmic3:7892\" , \"number-of-locked-nodes\" : 23 , \"locked-targets\" : [ \"clab-lab1-leaf3\" , \"clab-lab1-leaf5\" , \"clab-lab3-spine4\" , \"clab-lab3-spine3\" , \"clab-lab1-leaf1\" , \"clab-lab1-leaf6\" , \"clab-lab2-leaf5\" , \"clab-lab4-leaf6\" , \"clab-lab5-leaf1\" , \"clab-lab5-leaf3\" , \"clab-lab5-super-spine2\" , \"clab-lab2-spine4\" , \"clab-lab5-super-spine1\" , \"clab-lab4-spine2\" , \"clab-lab3-spine1\" , \"clab-lab4-leaf5\" , \"clab-lab5-spine3\" , \"clab-lab1-super-spine2\" , \"clab-lab2-leaf1\" , \"clab-lab3-super-spine2\" , \"clab-lab3-leaf1\" , \"clab-lab1-leaf2\" , \"clab-lab2-leaf7\" ] } ] 500 Internal Server Error { \"errors\" : [ \"Error Text\" ] } GET /api/v1/cluster/leader # Queries the cluster leader deatils Returns details of the gNMIc cluster leader. Request curl --request POST gnmic-api-address:port/api/v1/cluster/leader 200 OK [ { \"name\" : \"clab-telemetry-gnmic1\" , \"api-endpoint\" : \"http://clab-telemetry-gnmic1:7890\" , \"is-leader\" : true , \"number-of-locked-nodes\" : 23 , \"locked-targets\" : [ \"clab-lab4-leaf8\" , \"clab-lab5-leaf8\" , \"clab-lab1-spine2\" , \"clab-lab3-leaf7\" , \"clab-lab4-leaf4\" , \"clab-lab2-leaf8\" , \"clab-lab2-spine3\" , \"clab-lab4-leaf1\" , \"clab-lab4-leaf2\" , \"clab-lab4-spine3\" , \"clab-lab5-spine2\" , \"clab-lab1-spine1\" , \"clab-lab2-leaf6\" , \"clab-lab5-leaf7\" , \"clab-lab1-leaf8\" , \"clab-lab3-leaf8\" , \"clab-lab3-spine2\" , \"clab-lab3-super-spine1\" , \"clab-lab5-spine1\" , \"clab-lab2-super-spine2\" , \"clab-lab3-leaf2\" , \"clab-lab2-spine2\" , \"clab-lab4-spine1\" ] } ] 500 Internal Server Error { \"errors\" : [ \"Error Text\" ] }","title":"Cluster"},{"location":"user_guide/api/cluster/#get-apiv1cluster","text":"Request gNMIc cluster state and details Returns gNMIc cluster state and details Request curl --request GET gnmic-api-address:port/api/v1/cluster 200 OK { \"name\" : \"collectors\" , \"number-of-locked-targets\" : 70 , \"leader\" : \"clab-telemetry-gnmic1\" , \"members\" : [ { \"name\" : \"clab-telemetry-gnmic1\" , \"api-endpoint\" : \"clab-telemetry-gnmic1:7890\" , \"is-leader\" : true , \"number-of-locked-nodes\" : 23 , \"locked-targets\" : [ \"clab-lab2-leaf6\" , \"clab-lab5-spine2\" , \"clab-lab4-leaf4\" , \"clab-lab2-leaf8\" , \"clab-lab3-leaf2\" , \"clab-lab5-spine1\" , \"clab-lab1-spine1\" , \"clab-lab2-super-spine2\" , \"clab-lab3-super-spine1\" , \"clab-lab4-spine3\" , \"clab-lab2-spine3\" , \"clab-lab3-leaf7\" , \"clab-lab5-leaf7\" , \"clab-lab5-leaf8\" , \"clab-lab1-spine2\" , \"clab-lab4-leaf8\" , \"clab-lab4-leaf1\" , \"clab-lab4-spine1\" , \"clab-lab2-spine2\" , \"clab-lab3-spine2\" , \"clab-lab1-leaf8\" , \"clab-lab3-leaf8\" , \"clab-lab4-leaf2\" ] }, { \"name\" : \"clab-telemetry-gnmic2\" , \"api-endpoint\" : \"clab-telemetry-gnmic2:7891\" , \"number-of-locked-nodes\" : 24 , \"locked-targets\" : [ \"clab-lab3-leaf6\" , \"clab-lab1-leaf7\" , \"clab-lab2-leaf3\" , \"clab-lab5-leaf5\" , \"clab-lab1-super-spine1\" , \"clab-lab3-leaf5\" , \"clab-lab4-super-spine1\" , \"clab-lab5-leaf6\" , \"clab-lab2-spine1\" , \"clab-lab3-leaf3\" , \"clab-lab4-leaf3\" , \"clab-lab2-leaf4\" , \"clab-lab4-super-spine2\" , \"clab-lab1-spine3\" , \"clab-lab3-leaf4\" , \"clab-lab5-spine4\" , \"clab-lab1-leaf4\" , \"clab-lab2-leaf2\" , \"clab-lab2-super-spine1\" , \"clab-lab4-spine4\" , \"clab-lab5-leaf2\" , \"clab-lab5-leaf4\" , \"clab-lab4-leaf7\" , \"clab-lab1-spine4\" ] }, { \"name\" : \"clab-telemetry-gnmic3\" , \"api-endpoint\" : \"clab-telemetry-gnmic3:7892\" , \"number-of-locked-nodes\" : 23 , \"locked-targets\" : [ \"clab-lab1-leaf5\" , \"clab-lab3-spine3\" , \"clab-lab1-leaf1\" , \"clab-lab2-spine4\" , \"clab-lab1-super-spine2\" , \"clab-lab5-leaf3\" , \"clab-lab4-spine2\" , \"clab-lab1-leaf3\" , \"clab-lab5-spine3\" , \"clab-lab3-super-spine2\" , \"clab-lab2-leaf5\" , \"clab-lab1-leaf2\" , \"clab-lab1-leaf6\" , \"clab-lab4-leaf5\" , \"clab-lab2-leaf7\" , \"clab-lab3-leaf1\" , \"clab-lab2-leaf1\" , \"clab-lab3-spine1\" , \"clab-lab5-leaf1\" , \"clab-lab5-super-spine2\" , \"clab-lab4-leaf6\" , \"clab-lab3-spine4\" , \"clab-lab5-super-spine1\" ] } ] } 500 Internal Server Error { \"errors\" : [ \"Error Text\" ] }","title":"GET /api/v1/cluster"},{"location":"user_guide/api/cluster/#get-apiv1clustermembers","text":"Query gNMIc cluster members Returns a list of gNMIc cluster members with details Request curl --request GET gnmic-api-address:port/api/v1/cluster/members 200 OK [ { \"name\" : \"clab-telemetry-gnmic1\" , \"api-endpoint\" : \"http://clab-telemetry-gnmic1:7890\" , \"is-leader\" : true , \"number-of-locked-nodes\" : 23 , \"locked-targets\" : [ \"clab-lab2-spine3\" , \"clab-lab5-spine1\" , \"clab-lab2-super-spine2\" , \"clab-lab4-leaf2\" , \"clab-lab4-leaf4\" , \"clab-lab5-spine2\" , \"clab-lab1-leaf8\" , \"clab-lab4-spine1\" , \"clab-lab5-leaf7\" , \"clab-lab2-spine2\" , \"clab-lab3-super-spine1\" , \"clab-lab1-spine1\" , \"clab-lab3-leaf2\" , \"clab-lab3-spine2\" , \"clab-lab2-leaf6\" , \"clab-lab4-leaf1\" , \"clab-lab4-spine3\" , \"clab-lab1-spine2\" , \"clab-lab2-leaf8\" , \"clab-lab3-leaf8\" , \"clab-lab5-leaf8\" , \"clab-lab3-leaf7\" , \"clab-lab4-leaf8\" ] }, { \"name\" : \"clab-telemetry-gnmic2\" , \"api-endpoint\" : \"http://clab-telemetry-gnmic2:7891\" , \"number-of-locked-nodes\" : 24 , \"locked-targets\" : [ \"clab-lab1-spine4\" , \"clab-lab2-leaf2\" , \"clab-lab3-leaf3\" , \"clab-lab4-super-spine1\" , \"clab-lab5-leaf4\" , \"clab-lab1-spine3\" , \"clab-lab1-leaf4\" , \"clab-lab3-leaf6\" , \"clab-lab5-leaf2\" , \"clab-lab2-leaf4\" , \"clab-lab3-leaf4\" , \"clab-lab4-leaf3\" , \"clab-lab5-spine4\" , \"clab-lab3-leaf5\" , \"clab-lab4-super-spine2\" , \"clab-lab1-leaf7\" , \"clab-lab2-leaf3\" , \"clab-lab2-super-spine1\" , \"clab-lab5-leaf6\" , \"clab-lab2-spine1\" , \"clab-lab1-super-spine1\" , \"clab-lab4-leaf7\" , \"clab-lab4-spine4\" , \"clab-lab5-leaf5\" ] }, { \"name\" : \"clab-telemetry-gnmic3\" , \"api-endpoint\" : \"http://clab-telemetry-gnmic3:7892\" , \"number-of-locked-nodes\" : 23 , \"locked-targets\" : [ \"clab-lab1-leaf3\" , \"clab-lab1-leaf5\" , \"clab-lab3-spine4\" , \"clab-lab3-spine3\" , \"clab-lab1-leaf1\" , \"clab-lab1-leaf6\" , \"clab-lab2-leaf5\" , \"clab-lab4-leaf6\" , \"clab-lab5-leaf1\" , \"clab-lab5-leaf3\" , \"clab-lab5-super-spine2\" , \"clab-lab2-spine4\" , \"clab-lab5-super-spine1\" , \"clab-lab4-spine2\" , \"clab-lab3-spine1\" , \"clab-lab4-leaf5\" , \"clab-lab5-spine3\" , \"clab-lab1-super-spine2\" , \"clab-lab2-leaf1\" , \"clab-lab3-super-spine2\" , \"clab-lab3-leaf1\" , \"clab-lab1-leaf2\" , \"clab-lab2-leaf7\" ] } ] 500 Internal Server Error { \"errors\" : [ \"Error Text\" ] }","title":"GET /api/v1/cluster/members"},{"location":"user_guide/api/cluster/#get-apiv1clusterleader","text":"Queries the cluster leader deatils Returns details of the gNMIc cluster leader. Request curl --request POST gnmic-api-address:port/api/v1/cluster/leader 200 OK [ { \"name\" : \"clab-telemetry-gnmic1\" , \"api-endpoint\" : \"http://clab-telemetry-gnmic1:7890\" , \"is-leader\" : true , \"number-of-locked-nodes\" : 23 , \"locked-targets\" : [ \"clab-lab4-leaf8\" , \"clab-lab5-leaf8\" , \"clab-lab1-spine2\" , \"clab-lab3-leaf7\" , \"clab-lab4-leaf4\" , \"clab-lab2-leaf8\" , \"clab-lab2-spine3\" , \"clab-lab4-leaf1\" , \"clab-lab4-leaf2\" , \"clab-lab4-spine3\" , \"clab-lab5-spine2\" , \"clab-lab1-spine1\" , \"clab-lab2-leaf6\" , \"clab-lab5-leaf7\" , \"clab-lab1-leaf8\" , \"clab-lab3-leaf8\" , \"clab-lab3-spine2\" , \"clab-lab3-super-spine1\" , \"clab-lab5-spine1\" , \"clab-lab2-super-spine2\" , \"clab-lab3-leaf2\" , \"clab-lab2-spine2\" , \"clab-lab4-spine1\" ] } ] 500 Internal Server Error { \"errors\" : [ \"Error Text\" ] }","title":"GET /api/v1/cluster/leader"},{"location":"user_guide/api/configuration/","text":"/api/v1/config # /api/v1/config # GET /api/v1/config # Request all gnmic configuration Returns the whole configuration as json Request curl --request GET gnmic-api-address:port/api/v1/config 200 OK { \"username\" : \"admin\" , \"password\" : \"admin\" , \"port\" : \"57400\" , \"encoding\" : \"json_ietf\" , \"insecure\" : true , \"timeout\" : 10000000000 , \"log\" : true , \"max-msg-size\" : 536870912 , \"prometheus-address\" : \":8989\" , \"retry\" : 10000000000 , \"api\" : \":7890\" , \"get-type\" : \"ALL\" , \"set-delimiter\" : \":::\" , \"subscribe-mode\" : \"stream\" , \"subscribe-stream-mode\" : \"target-defined\" , \"subscribe-cluster-name\" : \"default-cluster\" , \"subscribe-lock-retry\" : 5000000000 , \"path-path-type\" : \"xpath\" , \"prompt-max-suggestions\" : 10 , \"prompt-prefix-color\" : \"dark_blue\" , \"prompt-suggestions-bg-color\" : \"dark_blue\" , \"prompt-description-bg-color\" : \"dark_gray\" , \"targets\" : { \"192.168.1.131:57400\" : { \"name\" : \"192.168.1.131:57400\" , \"address\" : \"192.168.1.131:57400\" , \"username\" : \"admin\" , \"password\" : \"admin\" , \"timeout\" : 10000000000 , \"insecure\" : true , \"skip-verify\" : false , \"buffer-size\" : 1000 , \"retry-timer\" : 10000000000 }, \"192.168.1.132:57400\" : { \"name\" : \"192.168.1.132:57400\" , \"address\" : \"192.168.1.131:57400\" , \"username\" : \"admin\" , \"password\" : \"admin\" , \"timeout\" : 10000000000 , \"insecure\" : true , \"skip-verify\" : false , \"buffer-size\" : 1000 , \"retry-timer\" : 10000000000 } }, \"subscriptions\" : { \"sub1\" : { \"name\" : \"sub1\" , \"paths\" : [ \"/interface/statistics\" ], \"mode\" : \"stream\" , \"stream-mode\" : \"sample\" , \"encoding\" : \"json_ietf\" , \"sample-interval\" : 1000000000 } }, \"Outputs\" : { \"output2\" : { \"address\" : \"192.168.1.131:4222\" , \"format\" : \"event\" , \"subject\" : \"telemetry\" , \"type\" : \"nats\" , \"write-timeout\" : \"10s\" } }, \"inputs\" : {}, \"processors\" : {}, \"clustering\" : { \"cluster-name\" : \"cluster1\" , \"instance-name\" : \"gnmic1\" , \"service-address\" : \"gnmic1\" , \"services-watch-timer\" : 60000000000 , \"targets-watch-timer\" : 5000000000 , \"leader-wait-timer\" : 5000000000 , \"locker\" : { \"address\" : \"consul-agent:8500\" , \"type\" : \"consul\" } } } 500 Internal Server Error { \"errors\" : [ \"Error Text\" ] } /api/v1/config/targets # GET /api/v1/config/targets # Request all targets configuration returns the targets configuration as json Request curl --request GET gnmic-api-address:port/api/v1/config/targets 200 OK { \"192.168.1.131:57400\" : { \"name\" : \"192.168.1.131:57400\" , \"address\" : \"192.168.1.131:57400\" , \"username\" : \"admin\" , \"password\" : \"admin\" , \"timeout\" : 10000000000 , \"insecure\" : true , \"skip-verify\" : false , \"buffer-size\" : 1000 , \"retry-timer\" : 10000000000 }, \"192.168.1.132:57400\" : { \"name\" : \"192.168.1.132:57400\" , \"address\" : \"192.168.1.131:57400\" , \"username\" : \"admin\" , \"password\" : \"admin\" , \"timeout\" : 10000000000 , \"insecure\" : true , \"skip-verify\" : false , \"buffer-size\" : 1000 , \"retry-timer\" : 10000000000 } } 404 Not found { \"errors\" : [ \"no targets found\" , ] } 500 Internal Server Error { \"errors\" : [ \"Error Text\" ] } GET /api/v1/config/targets/{id} # Request a single target configuration Returns a single target configuration as json, where {id} is the target ID Request curl --request GET gnmic-api-address:port/api/v1/config/targets/192.168.1.131:57400 200 OK { \"name\" : \"192.168.1.131:57400\" , \"address\" : \"192.168.1.131:57400\" , \"username\" : \"admin\" , \"password\" : \"admin\" , \"timeout\" : 10000000000 , \"insecure\" : true , \"skip-verify\" : false , \"buffer-size\" : 1000 , \"retry-timer\" : 10000000000 } 404 Not found { \"errors\" : [ \"target $target not found\" , ] } 500 Internal Server Error { \"errors\" : [ \"Error Text\" ] } POST /api/v1/config/targets # Add a new target to gnmic configuration Expected request body is a single target config as json Returns an empty body if successful. Request curl --request POST -H \"Content-Type: application/json\" \\ -d '{\"address\": \"10.10.10.10:57400\", \"username\": \"admin\", \"password\": \"admin\", \"insecure\": true}' \\ gnmic-api-address:port/api/v1/config/targets 200 OK 400 Bad Request 500 Internal Server Error { \"errors\" : [ \"Error Text\" ] } DELETE /api/v1/config/targets/{id} # Deletes a target {id} configuration, all active subscriptions are terminated. Returns an empty body Request curl --request DELETE gnmic-api-address:port/api/v1/config/targets/192.168.1.131:57400 200 OK /api/v1/config/subscriptions # GET /api/v1/config/subscriptions # Request all the configured subscriptions. Returns the subscriptions configuration as json /api/v1/config/outputs # GET /api/v1/config/outputs # Request all the configured outputs. Returns the outputs configuration as json /api/v1/config/inputs # GET /api/v1/config/inputs # Request all the configured inputs. Returns the outputs configuration as json /api/v1/config/processors # GET /api/v1/config/processors # Request all the configured processors. Returns the processors configuration as json /api/v1/config/clustering # GET /api/v1/config/clustering # Request the clustering configuration. Returns the clustering configuration as json","title":"Configuration"},{"location":"user_guide/api/configuration/#apiv1config","text":"","title":"/api/v1/config"},{"location":"user_guide/api/configuration/#apiv1config_1","text":"","title":"/api/v1/config"},{"location":"user_guide/api/configuration/#get-apiv1config","text":"Request all gnmic configuration Returns the whole configuration as json Request curl --request GET gnmic-api-address:port/api/v1/config 200 OK { \"username\" : \"admin\" , \"password\" : \"admin\" , \"port\" : \"57400\" , \"encoding\" : \"json_ietf\" , \"insecure\" : true , \"timeout\" : 10000000000 , \"log\" : true , \"max-msg-size\" : 536870912 , \"prometheus-address\" : \":8989\" , \"retry\" : 10000000000 , \"api\" : \":7890\" , \"get-type\" : \"ALL\" , \"set-delimiter\" : \":::\" , \"subscribe-mode\" : \"stream\" , \"subscribe-stream-mode\" : \"target-defined\" , \"subscribe-cluster-name\" : \"default-cluster\" , \"subscribe-lock-retry\" : 5000000000 , \"path-path-type\" : \"xpath\" , \"prompt-max-suggestions\" : 10 , \"prompt-prefix-color\" : \"dark_blue\" , \"prompt-suggestions-bg-color\" : \"dark_blue\" , \"prompt-description-bg-color\" : \"dark_gray\" , \"targets\" : { \"192.168.1.131:57400\" : { \"name\" : \"192.168.1.131:57400\" , \"address\" : \"192.168.1.131:57400\" , \"username\" : \"admin\" , \"password\" : \"admin\" , \"timeout\" : 10000000000 , \"insecure\" : true , \"skip-verify\" : false , \"buffer-size\" : 1000 , \"retry-timer\" : 10000000000 }, \"192.168.1.132:57400\" : { \"name\" : \"192.168.1.132:57400\" , \"address\" : \"192.168.1.131:57400\" , \"username\" : \"admin\" , \"password\" : \"admin\" , \"timeout\" : 10000000000 , \"insecure\" : true , \"skip-verify\" : false , \"buffer-size\" : 1000 , \"retry-timer\" : 10000000000 } }, \"subscriptions\" : { \"sub1\" : { \"name\" : \"sub1\" , \"paths\" : [ \"/interface/statistics\" ], \"mode\" : \"stream\" , \"stream-mode\" : \"sample\" , \"encoding\" : \"json_ietf\" , \"sample-interval\" : 1000000000 } }, \"Outputs\" : { \"output2\" : { \"address\" : \"192.168.1.131:4222\" , \"format\" : \"event\" , \"subject\" : \"telemetry\" , \"type\" : \"nats\" , \"write-timeout\" : \"10s\" } }, \"inputs\" : {}, \"processors\" : {}, \"clustering\" : { \"cluster-name\" : \"cluster1\" , \"instance-name\" : \"gnmic1\" , \"service-address\" : \"gnmic1\" , \"services-watch-timer\" : 60000000000 , \"targets-watch-timer\" : 5000000000 , \"leader-wait-timer\" : 5000000000 , \"locker\" : { \"address\" : \"consul-agent:8500\" , \"type\" : \"consul\" } } } 500 Internal Server Error { \"errors\" : [ \"Error Text\" ] }","title":"GET /api/v1/config"},{"location":"user_guide/api/configuration/#apiv1configtargets","text":"","title":"/api/v1/config/targets"},{"location":"user_guide/api/configuration/#get-apiv1configtargets","text":"Request all targets configuration returns the targets configuration as json Request curl --request GET gnmic-api-address:port/api/v1/config/targets 200 OK { \"192.168.1.131:57400\" : { \"name\" : \"192.168.1.131:57400\" , \"address\" : \"192.168.1.131:57400\" , \"username\" : \"admin\" , \"password\" : \"admin\" , \"timeout\" : 10000000000 , \"insecure\" : true , \"skip-verify\" : false , \"buffer-size\" : 1000 , \"retry-timer\" : 10000000000 }, \"192.168.1.132:57400\" : { \"name\" : \"192.168.1.132:57400\" , \"address\" : \"192.168.1.131:57400\" , \"username\" : \"admin\" , \"password\" : \"admin\" , \"timeout\" : 10000000000 , \"insecure\" : true , \"skip-verify\" : false , \"buffer-size\" : 1000 , \"retry-timer\" : 10000000000 } } 404 Not found { \"errors\" : [ \"no targets found\" , ] } 500 Internal Server Error { \"errors\" : [ \"Error Text\" ] }","title":"GET /api/v1/config/targets"},{"location":"user_guide/api/configuration/#get-apiv1configtargetsid","text":"Request a single target configuration Returns a single target configuration as json, where {id} is the target ID Request curl --request GET gnmic-api-address:port/api/v1/config/targets/192.168.1.131:57400 200 OK { \"name\" : \"192.168.1.131:57400\" , \"address\" : \"192.168.1.131:57400\" , \"username\" : \"admin\" , \"password\" : \"admin\" , \"timeout\" : 10000000000 , \"insecure\" : true , \"skip-verify\" : false , \"buffer-size\" : 1000 , \"retry-timer\" : 10000000000 } 404 Not found { \"errors\" : [ \"target $target not found\" , ] } 500 Internal Server Error { \"errors\" : [ \"Error Text\" ] }","title":"GET /api/v1/config/targets/{id}"},{"location":"user_guide/api/configuration/#post-apiv1configtargets","text":"Add a new target to gnmic configuration Expected request body is a single target config as json Returns an empty body if successful. Request curl --request POST -H \"Content-Type: application/json\" \\ -d '{\"address\": \"10.10.10.10:57400\", \"username\": \"admin\", \"password\": \"admin\", \"insecure\": true}' \\ gnmic-api-address:port/api/v1/config/targets 200 OK 400 Bad Request 500 Internal Server Error { \"errors\" : [ \"Error Text\" ] }","title":"POST /api/v1/config/targets"},{"location":"user_guide/api/configuration/#delete-apiv1configtargetsid","text":"Deletes a target {id} configuration, all active subscriptions are terminated. Returns an empty body Request curl --request DELETE gnmic-api-address:port/api/v1/config/targets/192.168.1.131:57400 200 OK","title":"DELETE /api/v1/config/targets/{id}"},{"location":"user_guide/api/configuration/#apiv1configsubscriptions","text":"","title":"/api/v1/config/subscriptions"},{"location":"user_guide/api/configuration/#get-apiv1configsubscriptions","text":"Request all the configured subscriptions. Returns the subscriptions configuration as json","title":"GET /api/v1/config/subscriptions"},{"location":"user_guide/api/configuration/#apiv1configoutputs","text":"","title":"/api/v1/config/outputs"},{"location":"user_guide/api/configuration/#get-apiv1configoutputs","text":"Request all the configured outputs. Returns the outputs configuration as json","title":"GET /api/v1/config/outputs"},{"location":"user_guide/api/configuration/#apiv1configinputs","text":"","title":"/api/v1/config/inputs"},{"location":"user_guide/api/configuration/#get-apiv1configinputs","text":"Request all the configured inputs. Returns the outputs configuration as json","title":"GET /api/v1/config/inputs"},{"location":"user_guide/api/configuration/#apiv1configprocessors","text":"","title":"/api/v1/config/processors"},{"location":"user_guide/api/configuration/#get-apiv1configprocessors","text":"Request all the configured processors. Returns the processors configuration as json","title":"GET /api/v1/config/processors"},{"location":"user_guide/api/configuration/#apiv1configclustering","text":"","title":"/api/v1/config/clustering"},{"location":"user_guide/api/configuration/#get-apiv1configclustering","text":"Request the clustering configuration. Returns the clustering configuration as json","title":"GET /api/v1/config/clustering"},{"location":"user_guide/api/targets/","text":"GET /api/v1/targets # Request all active targets details. Returns all active targets as json Request curl --request GET gnmic-api-address:port/api/v1/targets 200 OK { \"192.168.1.131:57400\" : { \"config\" : { \"name\" : \"192.168.1.131:57400\" , \"address\" : \"192.168.1.131:57400\" , \"username\" : \"admin\" , \"password\" : \"admin\" , \"timeout\" : 10000000000 , \"insecure\" : true , \"skip-verify\" : false , \"buffer-size\" : 1000 , \"retry-timer\" : 10000000000 }, \"subscriptions\" : { \"sub1\" : { \"name\" : \"sub1\" , \"paths\" : [ \"/interface/statistics\" ], \"mode\" : \"stream\" , \"stream-mode\" : \"sample\" , \"encoding\" : \"json_ietf\" , \"sample-interval\" : 1000000000 } } }, \"192.168.1.131:57401\" : { \"config\" : { \"name\" : \"192.168.1.131:57401\" , \"address\" : \"192.168.1.131:57401\" , \"username\" : \"admin\" , \"password\" : \"admin\" , \"timeout\" : 10000000000 , \"insecure\" : true , \"skip-verify\" : false , \"buffer-size\" : 1000 , \"retry-timer\" : 10000000000 }, \"subscriptions\" : { \"sub1\" : { \"name\" : \"sub1\" , \"paths\" : [ \"/interface/statistics\" ], \"mode\" : \"stream\" , \"stream-mode\" : \"sample\" , \"encoding\" : \"json_ietf\" , \"sample-interval\" : 1000000000 } } } } 404 Not found { \"errors\" : [ \"no targets found\" ] } 500 Internal Server Error { \"errors\" : [ \"Error Text\" ] } GET /api/v1/targets/{id} # Query a single target details, if active. Returns a single target if active as json, where {id} is the target ID Request curl --request GET gnmic-api-address:port/targets/192.168.1.131:57400 200 OK { \"config\" : { \"name\" : \"192.168.1.131:57400\" , \"address\" : \"192.168.1.131:57400\" , \"username\" : \"admin\" , \"password\" : \"admin\" , \"timeout\" : 10000000000 , \"insecure\" : true , \"skip-verify\" : false , \"buffer-size\" : 1000 , \"retry-timer\" : 10000000000 }, \"subscriptions\" : { \"sub1\" : { \"name\" : \"sub1\" , \"paths\" : [ \"/interface/statistics\" ], \"mode\" : \"stream\" , \"stream-mode\" : \"sample\" , \"encoding\" : \"json_ietf\" , \"sample-interval\" : 1000000000 } } } 404 Not found { \"errors\" : [ \"no targets found\" ] } 500 Internal Server Error { \"errors\" : [ \"Error Text\" ] } POST /api/v1/targets/{id} # Starts a single target subscriptions, where {id} is the target ID Returns an empty body if successful. Request curl --request POST gnmic-api-address:port/api/v1/targets/192.168.1.131:57400 200 OK 404 Not found { \"errors\" : [ \"target $target not found\" ] } 500 Internal Server Error { \"errors\" : [ \"Error Text\" ] } DELETE /api/v1/targets/{id} # Stops a single target active subscriptions, where {id} is the target ID Returns an empty body if successful. Request curl --request DELETE gnmic-api-address:port/api/v1/targets/192.168.1.131:57400 200 OK 404 Not found { \"errors\" : [ \"target $target not found\" ] } 500 Internal Server Error { \"errors\" : [ \"Error Text\" ] }","title":"Targets"},{"location":"user_guide/api/targets/#get-apiv1targets","text":"Request all active targets details. Returns all active targets as json Request curl --request GET gnmic-api-address:port/api/v1/targets 200 OK { \"192.168.1.131:57400\" : { \"config\" : { \"name\" : \"192.168.1.131:57400\" , \"address\" : \"192.168.1.131:57400\" , \"username\" : \"admin\" , \"password\" : \"admin\" , \"timeout\" : 10000000000 , \"insecure\" : true , \"skip-verify\" : false , \"buffer-size\" : 1000 , \"retry-timer\" : 10000000000 }, \"subscriptions\" : { \"sub1\" : { \"name\" : \"sub1\" , \"paths\" : [ \"/interface/statistics\" ], \"mode\" : \"stream\" , \"stream-mode\" : \"sample\" , \"encoding\" : \"json_ietf\" , \"sample-interval\" : 1000000000 } } }, \"192.168.1.131:57401\" : { \"config\" : { \"name\" : \"192.168.1.131:57401\" , \"address\" : \"192.168.1.131:57401\" , \"username\" : \"admin\" , \"password\" : \"admin\" , \"timeout\" : 10000000000 , \"insecure\" : true , \"skip-verify\" : false , \"buffer-size\" : 1000 , \"retry-timer\" : 10000000000 }, \"subscriptions\" : { \"sub1\" : { \"name\" : \"sub1\" , \"paths\" : [ \"/interface/statistics\" ], \"mode\" : \"stream\" , \"stream-mode\" : \"sample\" , \"encoding\" : \"json_ietf\" , \"sample-interval\" : 1000000000 } } } } 404 Not found { \"errors\" : [ \"no targets found\" ] } 500 Internal Server Error { \"errors\" : [ \"Error Text\" ] }","title":"GET /api/v1/targets"},{"location":"user_guide/api/targets/#get-apiv1targetsid","text":"Query a single target details, if active. Returns a single target if active as json, where {id} is the target ID Request curl --request GET gnmic-api-address:port/targets/192.168.1.131:57400 200 OK { \"config\" : { \"name\" : \"192.168.1.131:57400\" , \"address\" : \"192.168.1.131:57400\" , \"username\" : \"admin\" , \"password\" : \"admin\" , \"timeout\" : 10000000000 , \"insecure\" : true , \"skip-verify\" : false , \"buffer-size\" : 1000 , \"retry-timer\" : 10000000000 }, \"subscriptions\" : { \"sub1\" : { \"name\" : \"sub1\" , \"paths\" : [ \"/interface/statistics\" ], \"mode\" : \"stream\" , \"stream-mode\" : \"sample\" , \"encoding\" : \"json_ietf\" , \"sample-interval\" : 1000000000 } } } 404 Not found { \"errors\" : [ \"no targets found\" ] } 500 Internal Server Error { \"errors\" : [ \"Error Text\" ] }","title":"GET /api/v1/targets/{id}"},{"location":"user_guide/api/targets/#post-apiv1targetsid","text":"Starts a single target subscriptions, where {id} is the target ID Returns an empty body if successful. Request curl --request POST gnmic-api-address:port/api/v1/targets/192.168.1.131:57400 200 OK 404 Not found { \"errors\" : [ \"target $target not found\" ] } 500 Internal Server Error { \"errors\" : [ \"Error Text\" ] }","title":"POST /api/v1/targets/{id}"},{"location":"user_guide/api/targets/#delete-apiv1targetsid","text":"Stops a single target active subscriptions, where {id} is the target ID Returns an empty body if successful. Request curl --request DELETE gnmic-api-address:port/api/v1/targets/192.168.1.131:57400 200 OK 404 Not found { \"errors\" : [ \"target $target not found\" ] } 500 Internal Server Error { \"errors\" : [ \"Error Text\" ] }","title":"DELETE /api/v1/targets/{id}"},{"location":"user_guide/event_processors/event_add_tag/","text":"The event-add-tag processor, adds a set of tags to an event message if one of the configured regular expressions in the values, value names, tags or tag names sections matches. It is possible to overwrite a tag if it's name already exists. processors : # processor name sample-processor : # processor type event-add-tag : # jq expression, if evaluated to true, the tags are added condition : # list of regular expressions to be matched against the tags names, if matched, the tags are added tag-names : # list of regular expressions to be matched against the tags values, if matched, the tags are added tags : # list of regular expressions to be matched against the values names, if matched, the tags are added value-names : # list of regular expressions to be matched against the values, if matched, the tags are added values : # boolean, if true tags are over-written with the added ones if they already exist. overwrite : # map of tags to be added add : tag_name : tag_value Examples # processors : # processor name sample-processor : # processor type event-add-tag : value-names : - \".\" add : tag_name : tag_value Event format before { \"name\" : \"sub1\" , \"timestamp\" : 1607678293684962443 , \"tags\" : { \"interface_name\" : \"mgmt0\" , \"source\" : \"172.20.20.5:57400\" }, \"values\" : { \"Carrier_Transitions\" : 1 , \"In_Broadcast_Packets\" : 448 , \"In_Error_Packets\" : 0 , \"In_Fcs_Error_Packets\" : 0 , \"In_Multicast_Packets\" : 47578 , \"In_Octets\" : 15557349 , \"In_Unicast_Packets\" : 6482 , \"Out_Broadcast_Packets\" : 110 , \"Out_Error_Packets\" : 0 , \"Out_Multicast_Packets\" : 10 , \"Out_Octets\" : 464766 } } Event format after { \"name\" : \"sub1\" , \"timestamp\" : 1607678293684962443 , \"tags\" : { \"interface_name\" : \"mgmt0\" , \"source\" : \"172.20.20.5:57400\" , \"tag_name\" : \"tag_value\" }, \"values\" : { \"Carrier_Transitions\" : 1 , \"In_Broadcast_Packets\" : 448 , \"In_Error_Packets\" : 0 , \"In_Fcs_Error_Packets\" : 0 , \"In_Multicast_Packets\" : 47578 , \"In_Octets\" : 15557349 , \"In_Unicast_Packets\" : 6482 , \"Out_Broadcast_Packets\" : 110 , \"Out_Error_Packets\" : 0 , \"Out_Multicast_Packets\" : 10 , \"Out_Octets\" : 464766 } }","title":"Add Tag"},{"location":"user_guide/event_processors/event_add_tag/#examples","text":"processors : # processor name sample-processor : # processor type event-add-tag : value-names : - \".\" add : tag_name : tag_value Event format before { \"name\" : \"sub1\" , \"timestamp\" : 1607678293684962443 , \"tags\" : { \"interface_name\" : \"mgmt0\" , \"source\" : \"172.20.20.5:57400\" }, \"values\" : { \"Carrier_Transitions\" : 1 , \"In_Broadcast_Packets\" : 448 , \"In_Error_Packets\" : 0 , \"In_Fcs_Error_Packets\" : 0 , \"In_Multicast_Packets\" : 47578 , \"In_Octets\" : 15557349 , \"In_Unicast_Packets\" : 6482 , \"Out_Broadcast_Packets\" : 110 , \"Out_Error_Packets\" : 0 , \"Out_Multicast_Packets\" : 10 , \"Out_Octets\" : 464766 } } Event format after { \"name\" : \"sub1\" , \"timestamp\" : 1607678293684962443 , \"tags\" : { \"interface_name\" : \"mgmt0\" , \"source\" : \"172.20.20.5:57400\" , \"tag_name\" : \"tag_value\" }, \"values\" : { \"Carrier_Transitions\" : 1 , \"In_Broadcast_Packets\" : 448 , \"In_Error_Packets\" : 0 , \"In_Fcs_Error_Packets\" : 0 , \"In_Multicast_Packets\" : 47578 , \"In_Octets\" : 15557349 , \"In_Unicast_Packets\" : 6482 , \"Out_Broadcast_Packets\" : 110 , \"Out_Error_Packets\" : 0 , \"Out_Multicast_Packets\" : 10 , \"Out_Octets\" : 464766 } }","title":"Examples"},{"location":"user_guide/event_processors/event_allow/","text":"The event-allow processor, allows only messages matching the configured condition or one of the regular expressions under tags , tag-names , values or value-names . Non matching messages are dropped. processors : # processor name sample-processor : # processor type event-allow : # jq expression, if evaluated to true, the message is allowed condition : # list of regular expressions to be matched against the tags names, # if matched, the message is allowed tag-names : # list of regular expressions to be matched against the tags values, # if matched, the message is allowed tags : # list of regular expressions to be matched against the values names, # if matched, the message is allowed value-names : # list of regular expressions to be matched against the values, # if matched, the message is allowed values : Examples # processors : # processor name allow-processor : # processor type event-allow : condition : \".tags.interface_name == 1/1/1\" Event format before [ { \"name\" : \"default\" , \"timestamp\" : 1607291271894072397 , \"tags\" : { \"interface_name\" : \"mgmt0\" , \"source\" : \"172.23.23.2:57400\" , \"subscription-name\" : \"default\" }, \"values\" : { \"/srl_nokia-interfaces:interface/statistics/carrier-transitions\" : \"1\" , \"/srl_nokia-interfaces:interface/statistics/in-broadcast-packets\" : \"3797\" , \"/srl_nokia-interfaces:interface/statistics/in-error-packets\" : \"0\" , \"/srl_nokia-interfaces:interface/statistics/in-fcs-error-packets\" : \"0\" , \"/srl_nokia-interfaces:interface/statistics/in-multicast-packets\" : \"288033\" , \"/srl_nokia-interfaces:interface/statistics/in-octets\" : \"65382630\" , \"/srl_nokia-interfaces:interface/statistics/in-unicast-packets\" : \"107154\" , \"/srl_nokia-interfaces:interface/statistics/out-broadcast-packets\" : \"614\" , \"/srl_nokia-interfaces:interface/statistics/out-error-packets\" : \"0\" , \"/srl_nokia-interfaces:interface/statistics/out-multicast-packets\" : \"11\" , \"/srl_nokia-interfaces:interface/statistics/out-octets\" : \"64721394\" , \"/srl_nokia-interfaces:interface/statistics/out-unicast-packets\" : \"105876\" } }, { \"name\" : \"default\" , \"timestamp\" : 1607291271894072397 , \"tags\" : { \"interface_name\" : \"1/1/1\" , \"source\" : \"172.23.23.3:57400\" , \"subscription-name\" : \"default\" }, \"values\" : { \"/srl_nokia-interfaces:interface/statistics/carrier-transitions\" : \"1\" , \"/srl_nokia-interfaces:interface/statistics/in-broadcast-packets\" : \"3797\" , \"/srl_nokia-interfaces:interface/statistics/in-error-packets\" : \"0\" , \"/srl_nokia-interfaces:interface/statistics/in-fcs-error-packets\" : \"0\" , \"/srl_nokia-interfaces:interface/statistics/in-multicast-packets\" : \"288033\" , \"/srl_nokia-interfaces:interface/statistics/in-octets\" : \"65382630\" , \"/srl_nokia-interfaces:interface/statistics/in-unicast-packets\" : \"107154\" , \"/srl_nokia-interfaces:interface/statistics/out-broadcast-packets\" : \"614\" , \"/srl_nokia-interfaces:interface/statistics/out-error-packets\" : \"0\" , \"/srl_nokia-interfaces:interface/statistics/out-multicast-packets\" : \"11\" , \"/srl_nokia-interfaces:interface/statistics/out-octets\" : \"64721394\" , \"/srl_nokia-interfaces:interface/statistics/out-unicast-packets\" : \"105876\" } } ] Event format after [ { }, { \"name\" : \"default\" , \"timestamp\" : 1607291271894072397 , \"tags\" : { \"interface_name\" : \"1/1/1\" , \"source\" : \"172.23.23.3:57400\" , \"subscription-name\" : \"default\" }, \"values\" : { \"/srl_nokia-interfaces:interface/statistics/carrier-transitions\" : \"1\" , \"/srl_nokia-interfaces:interface/statistics/in-broadcast-packets\" : \"3797\" , \"/srl_nokia-interfaces:interface/statistics/in-error-packets\" : \"0\" , \"/srl_nokia-interfaces:interface/statistics/in-fcs-error-packets\" : \"0\" , \"/srl_nokia-interfaces:interface/statistics/in-multicast-packets\" : \"288033\" , \"/srl_nokia-interfaces:interface/statistics/in-octets\" : \"65382630\" , \"/srl_nokia-interfaces:interface/statistics/in-unicast-packets\" : \"107154\" , \"/srl_nokia-interfaces:interface/statistics/out-broadcast-packets\" : \"614\" , \"/srl_nokia-interfaces:interface/statistics/out-error-packets\" : \"0\" , \"/srl_nokia-interfaces:interface/statistics/out-multicast-packets\" : \"11\" , \"/srl_nokia-interfaces:interface/statistics/out-octets\" : \"64721394\" , \"/srl_nokia-interfaces:interface/statistics/out-unicast-packets\" : \"105876\" } } ]","title":"Allow"},{"location":"user_guide/event_processors/event_allow/#examples","text":"processors : # processor name allow-processor : # processor type event-allow : condition : \".tags.interface_name == 1/1/1\" Event format before [ { \"name\" : \"default\" , \"timestamp\" : 1607291271894072397 , \"tags\" : { \"interface_name\" : \"mgmt0\" , \"source\" : \"172.23.23.2:57400\" , \"subscription-name\" : \"default\" }, \"values\" : { \"/srl_nokia-interfaces:interface/statistics/carrier-transitions\" : \"1\" , \"/srl_nokia-interfaces:interface/statistics/in-broadcast-packets\" : \"3797\" , \"/srl_nokia-interfaces:interface/statistics/in-error-packets\" : \"0\" , \"/srl_nokia-interfaces:interface/statistics/in-fcs-error-packets\" : \"0\" , \"/srl_nokia-interfaces:interface/statistics/in-multicast-packets\" : \"288033\" , \"/srl_nokia-interfaces:interface/statistics/in-octets\" : \"65382630\" , \"/srl_nokia-interfaces:interface/statistics/in-unicast-packets\" : \"107154\" , \"/srl_nokia-interfaces:interface/statistics/out-broadcast-packets\" : \"614\" , \"/srl_nokia-interfaces:interface/statistics/out-error-packets\" : \"0\" , \"/srl_nokia-interfaces:interface/statistics/out-multicast-packets\" : \"11\" , \"/srl_nokia-interfaces:interface/statistics/out-octets\" : \"64721394\" , \"/srl_nokia-interfaces:interface/statistics/out-unicast-packets\" : \"105876\" } }, { \"name\" : \"default\" , \"timestamp\" : 1607291271894072397 , \"tags\" : { \"interface_name\" : \"1/1/1\" , \"source\" : \"172.23.23.3:57400\" , \"subscription-name\" : \"default\" }, \"values\" : { \"/srl_nokia-interfaces:interface/statistics/carrier-transitions\" : \"1\" , \"/srl_nokia-interfaces:interface/statistics/in-broadcast-packets\" : \"3797\" , \"/srl_nokia-interfaces:interface/statistics/in-error-packets\" : \"0\" , \"/srl_nokia-interfaces:interface/statistics/in-fcs-error-packets\" : \"0\" , \"/srl_nokia-interfaces:interface/statistics/in-multicast-packets\" : \"288033\" , \"/srl_nokia-interfaces:interface/statistics/in-octets\" : \"65382630\" , \"/srl_nokia-interfaces:interface/statistics/in-unicast-packets\" : \"107154\" , \"/srl_nokia-interfaces:interface/statistics/out-broadcast-packets\" : \"614\" , \"/srl_nokia-interfaces:interface/statistics/out-error-packets\" : \"0\" , \"/srl_nokia-interfaces:interface/statistics/out-multicast-packets\" : \"11\" , \"/srl_nokia-interfaces:interface/statistics/out-octets\" : \"64721394\" , \"/srl_nokia-interfaces:interface/statistics/out-unicast-packets\" : \"105876\" } } ] Event format after [ { }, { \"name\" : \"default\" , \"timestamp\" : 1607291271894072397 , \"tags\" : { \"interface_name\" : \"1/1/1\" , \"source\" : \"172.23.23.3:57400\" , \"subscription-name\" : \"default\" }, \"values\" : { \"/srl_nokia-interfaces:interface/statistics/carrier-transitions\" : \"1\" , \"/srl_nokia-interfaces:interface/statistics/in-broadcast-packets\" : \"3797\" , \"/srl_nokia-interfaces:interface/statistics/in-error-packets\" : \"0\" , \"/srl_nokia-interfaces:interface/statistics/in-fcs-error-packets\" : \"0\" , \"/srl_nokia-interfaces:interface/statistics/in-multicast-packets\" : \"288033\" , \"/srl_nokia-interfaces:interface/statistics/in-octets\" : \"65382630\" , \"/srl_nokia-interfaces:interface/statistics/in-unicast-packets\" : \"107154\" , \"/srl_nokia-interfaces:interface/statistics/out-broadcast-packets\" : \"614\" , \"/srl_nokia-interfaces:interface/statistics/out-error-packets\" : \"0\" , \"/srl_nokia-interfaces:interface/statistics/out-multicast-packets\" : \"11\" , \"/srl_nokia-interfaces:interface/statistics/out-octets\" : \"64721394\" , \"/srl_nokia-interfaces:interface/statistics/out-unicast-packets\" : \"105876\" } } ]","title":"Examples"},{"location":"user_guide/event_processors/event_convert/","text":"The event-convert processor, converts the values matching one of the regular expressions to a specific type: uint , int , string , float or bool Examples # processors : # processor name convert-int-processor : # processor type event-convert : # list of regex to be matched with the values names value-names : - \".*octets$\" # the desired value type, one of: int, uint, string, float, bool type : int Event format before { \"name\" : \"default\" , \"timestamp\" : 1607290633806716620 , \"tags\" : { \"port_port-id\" : \"A/1\" , \"source\" : \"172.17.0.100:57400\" , \"subscription-name\" : \"default\" }, \"values\" : { \"/state/port/ethernet/statistics/in-octets\" : \"7753940\" } } Event format after { \"name\" : \"default\" , \"timestamp\" : 1607290633806716620 , \"tags\" : { \"port_port-id\" : \"A/1\" , \"source\" : \"172.17.0.100:57400\" , \"subscription-name\" : \"default\" }, \"values\" : { \"/state/port/ethernet/statistics/in-octets\" : 7753940 } }","title":"Convert"},{"location":"user_guide/event_processors/event_convert/#examples","text":"processors : # processor name convert-int-processor : # processor type event-convert : # list of regex to be matched with the values names value-names : - \".*octets$\" # the desired value type, one of: int, uint, string, float, bool type : int Event format before { \"name\" : \"default\" , \"timestamp\" : 1607290633806716620 , \"tags\" : { \"port_port-id\" : \"A/1\" , \"source\" : \"172.17.0.100:57400\" , \"subscription-name\" : \"default\" }, \"values\" : { \"/state/port/ethernet/statistics/in-octets\" : \"7753940\" } } Event format after { \"name\" : \"default\" , \"timestamp\" : 1607290633806716620 , \"tags\" : { \"port_port-id\" : \"A/1\" , \"source\" : \"172.17.0.100:57400\" , \"subscription-name\" : \"default\" }, \"values\" : { \"/state/port/ethernet/statistics/in-octets\" : 7753940 } }","title":"Examples"},{"location":"user_guide/event_processors/event_data_convert/","text":"The event-data-convert processor, converts data values matching one of the regular expressions from/to a specific data unit: Symbol Unit Symbol Unit Symbol Unit b Bit B Byte KiB KibiByte kb kiloBit KB KiloByte MiB MebiByte mb MegaBit MB MegaByte GiB GibiByte gb GigaBit GB GigaByte TiB TebiByte tb TeraBit TB TeraByte EiB ExbiByte eb ExaBit EB ExaByte ZiB ZebiByte ZB ZetaByte YiB YobiByte YB YottaByte The source values can be of any numeric type including a string with or without a unit, e.g: 2.3 , 1KB or 1.1 TB . The unit of the original value can be derived as Byte from its name if it ends with -bytes , -octets , _bytes or _octets . Examples # simple conversion # The below processor will convert any value with a name ending in -octets from Byte to KiloByte . processors : # processor name convert-data-unit : # processor type event-data-convert : # list of regex to be matched with the values names value-names : - \".*-octets$\" # the source value unit, defaults to B (Byte) from : B # the desired value unit, defaults to B (Byte) to : KB # keep the original value, # a new value name will be added with the converted value, # the new value name will be the original name with _$to as suffix # if no regex renaming is defined using `old` and `new` keep : false # old, a regex to be used to rename the converted value old : # new, the replacement string new : # debug, enables this processor logging debug : false Event format before { \"name\" : \"default\" , \"timestamp\" : 1607290633806716620 , \"tags\" : { \"port_port-id\" : \"A/1\" , \"source\" : \"172.17.0.100:57400\" , \"subscription-name\" : \"default\" }, \"values\" : { \"/state/port/ethernet/statistics/in-octets\" : \"2048\" } } Event format after { \"name\" : \"default\" , \"timestamp\" : 1607290633806716620 , \"tags\" : { \"port_port-id\" : \"A/1\" , \"source\" : \"172.17.0.100:57400\" , \"subscription-name\" : \"default\" }, \"values\" : { \"/state/port/ethernet/statistics/in-octets\" : 2 } } conversion with renaming # The below data convert processor converts any value with a name ending in -octets from Byte to Kilobyte. It will retain the original value while renaming the new value name by replacing -octets with -kilobytes . processors : # processor name convert-data-unit : # processor type event-data-convert : # list of regex to be matched with the values names value-names : - \".*-octets$\" # the source value unit, defaults to B (Byte) from : B # the desired value unit, defaults to B (Byte) to : KB # keep the original value, # a new value name will be added with the converted value, # the new value name will be the original name with _$to as suffix # if no regex renaming is defined using `old` and `new` keep : true # old, a regex to be used to rename the converted value old : ^(\\S+)-octets$ # new, the replacement string new : ${1}-kilobytes # debug, enables this processor logging debug : false Event format before { \"name\" : \"default\" , \"timestamp\" : 1607290633806716620 , \"tags\" : { \"port_port-id\" : \"A/1\" , \"source\" : \"172.17.0.100:57400\" , \"subscription-name\" : \"default\" }, \"values\" : { \"/state/port/ethernet/statistics/in-octets\" : \"2048\" } } Event format after { \"name\" : \"default\" , \"timestamp\" : 1607290633806716620 , \"tags\" : { \"port_port-id\" : \"A/1\" , \"source\" : \"172.17.0.100:57400\" , \"subscription-name\" : \"default\" }, \"values\" : { \"/state/port/ethernet/statistics/in-octets\" : \"2048\" \"/state/port/ethernet/statistics/in-kilobytes\" : 2 } }","title":"Data Convert"},{"location":"user_guide/event_processors/event_data_convert/#examples","text":"","title":"Examples"},{"location":"user_guide/event_processors/event_data_convert/#simple-conversion","text":"The below processor will convert any value with a name ending in -octets from Byte to KiloByte . processors : # processor name convert-data-unit : # processor type event-data-convert : # list of regex to be matched with the values names value-names : - \".*-octets$\" # the source value unit, defaults to B (Byte) from : B # the desired value unit, defaults to B (Byte) to : KB # keep the original value, # a new value name will be added with the converted value, # the new value name will be the original name with _$to as suffix # if no regex renaming is defined using `old` and `new` keep : false # old, a regex to be used to rename the converted value old : # new, the replacement string new : # debug, enables this processor logging debug : false Event format before { \"name\" : \"default\" , \"timestamp\" : 1607290633806716620 , \"tags\" : { \"port_port-id\" : \"A/1\" , \"source\" : \"172.17.0.100:57400\" , \"subscription-name\" : \"default\" }, \"values\" : { \"/state/port/ethernet/statistics/in-octets\" : \"2048\" } } Event format after { \"name\" : \"default\" , \"timestamp\" : 1607290633806716620 , \"tags\" : { \"port_port-id\" : \"A/1\" , \"source\" : \"172.17.0.100:57400\" , \"subscription-name\" : \"default\" }, \"values\" : { \"/state/port/ethernet/statistics/in-octets\" : 2 } }","title":"simple conversion"},{"location":"user_guide/event_processors/event_data_convert/#conversion-with-renaming","text":"The below data convert processor converts any value with a name ending in -octets from Byte to Kilobyte. It will retain the original value while renaming the new value name by replacing -octets with -kilobytes . processors : # processor name convert-data-unit : # processor type event-data-convert : # list of regex to be matched with the values names value-names : - \".*-octets$\" # the source value unit, defaults to B (Byte) from : B # the desired value unit, defaults to B (Byte) to : KB # keep the original value, # a new value name will be added with the converted value, # the new value name will be the original name with _$to as suffix # if no regex renaming is defined using `old` and `new` keep : true # old, a regex to be used to rename the converted value old : ^(\\S+)-octets$ # new, the replacement string new : ${1}-kilobytes # debug, enables this processor logging debug : false Event format before { \"name\" : \"default\" , \"timestamp\" : 1607290633806716620 , \"tags\" : { \"port_port-id\" : \"A/1\" , \"source\" : \"172.17.0.100:57400\" , \"subscription-name\" : \"default\" }, \"values\" : { \"/state/port/ethernet/statistics/in-octets\" : \"2048\" } } Event format after { \"name\" : \"default\" , \"timestamp\" : 1607290633806716620 , \"tags\" : { \"port_port-id\" : \"A/1\" , \"source\" : \"172.17.0.100:57400\" , \"subscription-name\" : \"default\" }, \"values\" : { \"/state/port/ethernet/statistics/in-octets\" : \"2048\" \"/state/port/ethernet/statistics/in-kilobytes\" : 2 } }","title":"conversion with renaming"},{"location":"user_guide/event_processors/event_date_string/","text":"The event-date-string processor, converts a specific timestamp value (under tags or values) to a string representation. The format and location can be configured. Examples # processors : # processor name convert-timestamp-processor : # processor type event-date-string : # list of regex to be matched with the values names value-names : - \"timestamp\" # received timestamp unit precision : ms # desired date string format, defaults to RFC3339 format : \"2006-01-02T15:04:05Z07:00\" # timezone, defaults to the local timezone location : Asia/Taipei","title":"Date string"},{"location":"user_guide/event_processors/event_date_string/#examples","text":"processors : # processor name convert-timestamp-processor : # processor type event-date-string : # list of regex to be matched with the values names value-names : - \"timestamp\" # received timestamp unit precision : ms # desired date string format, defaults to RFC3339 format : \"2006-01-02T15:04:05Z07:00\" # timezone, defaults to the local timezone location : Asia/Taipei","title":"Examples"},{"location":"user_guide/event_processors/event_delete/","text":"The event-delete processor, deletes all tags or values matching a set of regular expressions from the event message. Examples # processors : # processor name delete-processor : # processor type event-delete : value-names : - \".*multicast.*\" - \".*broadcast.*\" Event format before { \"name\" : \"default\" , \"timestamp\" : 1607291271894072397 , \"tags\" : { \"interface_name\" : \"mgmt0\" , \"source\" : \"172.23.23.2:57400\" , \"subscription-name\" : \"default\" }, \"values\" : { \"/srl_nokia-interfaces:interface/statistics/carrier-transitions\" : \"1\" , \"/srl_nokia-interfaces:interface/statistics/in-broadcast-packets\" : \"3797\" , \"/srl_nokia-interfaces:interface/statistics/in-error-packets\" : \"0\" , \"/srl_nokia-interfaces:interface/statistics/in-fcs-error-packets\" : \"0\" , \"/srl_nokia-interfaces:interface/statistics/in-multicast-packets\" : \"288033\" , \"/srl_nokia-interfaces:interface/statistics/in-octets\" : \"65382630\" , \"/srl_nokia-interfaces:interface/statistics/in-unicast-packets\" : \"107154\" , \"/srl_nokia-interfaces:interface/statistics/out-broadcast-packets\" : \"614\" , \"/srl_nokia-interfaces:interface/statistics/out-error-packets\" : \"0\" , \"/srl_nokia-interfaces:interface/statistics/out-multicast-packets\" : \"11\" , \"/srl_nokia-interfaces:interface/statistics/out-octets\" : \"64721394\" , \"/srl_nokia-interfaces:interface/statistics/out-unicast-packets\" : \"105876\" } } Event format after { \"name\" : \"default\" , \"timestamp\" : 1607291271894072397 , \"tags\" : { \"interface_name\" : \"mgmt0\" , \"source\" : \"172.23.23.2:57400\" , \"subscription-name\" : \"default\" }, \"values\" : { \"/srl_nokia-interfaces:interface/statistics/carrier-transitions\" : \"1\" , \"/srl_nokia-interfaces:interface/statistics/in-error-packets\" : \"0\" , \"/srl_nokia-interfaces:interface/statistics/in-fcs-error-packets\" : \"0\" , \"/srl_nokia-interfaces:interface/statistics/in-octets\" : \"65382630\" , \"/srl_nokia-interfaces:interface/statistics/in-unicast-packets\" : \"107154\" , \"/srl_nokia-interfaces:interface/statistics/out-error-packets\" : \"0\" , \"/srl_nokia-interfaces:interface/statistics/out-octets\" : \"64721394\" , \"/srl_nokia-interfaces:interface/statistics/out-unicast-packets\" : \"105876\" } }","title":"Delete"},{"location":"user_guide/event_processors/event_delete/#examples","text":"processors : # processor name delete-processor : # processor type event-delete : value-names : - \".*multicast.*\" - \".*broadcast.*\" Event format before { \"name\" : \"default\" , \"timestamp\" : 1607291271894072397 , \"tags\" : { \"interface_name\" : \"mgmt0\" , \"source\" : \"172.23.23.2:57400\" , \"subscription-name\" : \"default\" }, \"values\" : { \"/srl_nokia-interfaces:interface/statistics/carrier-transitions\" : \"1\" , \"/srl_nokia-interfaces:interface/statistics/in-broadcast-packets\" : \"3797\" , \"/srl_nokia-interfaces:interface/statistics/in-error-packets\" : \"0\" , \"/srl_nokia-interfaces:interface/statistics/in-fcs-error-packets\" : \"0\" , \"/srl_nokia-interfaces:interface/statistics/in-multicast-packets\" : \"288033\" , \"/srl_nokia-interfaces:interface/statistics/in-octets\" : \"65382630\" , \"/srl_nokia-interfaces:interface/statistics/in-unicast-packets\" : \"107154\" , \"/srl_nokia-interfaces:interface/statistics/out-broadcast-packets\" : \"614\" , \"/srl_nokia-interfaces:interface/statistics/out-error-packets\" : \"0\" , \"/srl_nokia-interfaces:interface/statistics/out-multicast-packets\" : \"11\" , \"/srl_nokia-interfaces:interface/statistics/out-octets\" : \"64721394\" , \"/srl_nokia-interfaces:interface/statistics/out-unicast-packets\" : \"105876\" } } Event format after { \"name\" : \"default\" , \"timestamp\" : 1607291271894072397 , \"tags\" : { \"interface_name\" : \"mgmt0\" , \"source\" : \"172.23.23.2:57400\" , \"subscription-name\" : \"default\" }, \"values\" : { \"/srl_nokia-interfaces:interface/statistics/carrier-transitions\" : \"1\" , \"/srl_nokia-interfaces:interface/statistics/in-error-packets\" : \"0\" , \"/srl_nokia-interfaces:interface/statistics/in-fcs-error-packets\" : \"0\" , \"/srl_nokia-interfaces:interface/statistics/in-octets\" : \"65382630\" , \"/srl_nokia-interfaces:interface/statistics/in-unicast-packets\" : \"107154\" , \"/srl_nokia-interfaces:interface/statistics/out-error-packets\" : \"0\" , \"/srl_nokia-interfaces:interface/statistics/out-octets\" : \"64721394\" , \"/srl_nokia-interfaces:interface/statistics/out-unicast-packets\" : \"105876\" } }","title":"Examples"},{"location":"user_guide/event_processors/event_drop/","text":"The event-drop processor, drops the whole message if it matches the configured condition or one of the regexes under tags , tag-names , values or value-names . processors : # processor name sample-processor : # processor type event-drop : # jq expression, if evaluated to true, the message is dropped condition : # list of regular expressions to be matched against the tags names, if matched, the message is dropped tag-names : # list of regular expressions to be matched against the tags values, if matched, the message is dropped tags : # list of regular expressions to be matched against the values names, if matched, the message is dropped value-names : # list of regular expressions to be matched against the values, if matched, the message is dropped values : Examples # processors : # processor name drop-processor : # processor type event-drop : tags : - \"172.23.23.2*\" Event format before { \"name\" : \"default\" , \"timestamp\" : 1607291271894072397 , \"tags\" : { \"interface_name\" : \"mgmt0\" , \"source\" : \"172.23.23.2:57400\" , \"subscription-name\" : \"default\" }, \"values\" : { \"/srl_nokia-interfaces:interface/statistics/carrier-transitions\" : \"1\" , \"/srl_nokia-interfaces:interface/statistics/in-broadcast-packets\" : \"3797\" , \"/srl_nokia-interfaces:interface/statistics/in-error-packets\" : \"0\" , \"/srl_nokia-interfaces:interface/statistics/in-fcs-error-packets\" : \"0\" , \"/srl_nokia-interfaces:interface/statistics/in-multicast-packets\" : \"288033\" , \"/srl_nokia-interfaces:interface/statistics/in-octets\" : \"65382630\" , \"/srl_nokia-interfaces:interface/statistics/in-unicast-packets\" : \"107154\" , \"/srl_nokia-interfaces:interface/statistics/out-broadcast-packets\" : \"614\" , \"/srl_nokia-interfaces:interface/statistics/out-error-packets\" : \"0\" , \"/srl_nokia-interfaces:interface/statistics/out-multicast-packets\" : \"11\" , \"/srl_nokia-interfaces:interface/statistics/out-octets\" : \"64721394\" , \"/srl_nokia-interfaces:interface/statistics/out-unicast-packets\" : \"105876\" } } Event format after { }","title":"Drop"},{"location":"user_guide/event_processors/event_drop/#examples","text":"processors : # processor name drop-processor : # processor type event-drop : tags : - \"172.23.23.2*\" Event format before { \"name\" : \"default\" , \"timestamp\" : 1607291271894072397 , \"tags\" : { \"interface_name\" : \"mgmt0\" , \"source\" : \"172.23.23.2:57400\" , \"subscription-name\" : \"default\" }, \"values\" : { \"/srl_nokia-interfaces:interface/statistics/carrier-transitions\" : \"1\" , \"/srl_nokia-interfaces:interface/statistics/in-broadcast-packets\" : \"3797\" , \"/srl_nokia-interfaces:interface/statistics/in-error-packets\" : \"0\" , \"/srl_nokia-interfaces:interface/statistics/in-fcs-error-packets\" : \"0\" , \"/srl_nokia-interfaces:interface/statistics/in-multicast-packets\" : \"288033\" , \"/srl_nokia-interfaces:interface/statistics/in-octets\" : \"65382630\" , \"/srl_nokia-interfaces:interface/statistics/in-unicast-packets\" : \"107154\" , \"/srl_nokia-interfaces:interface/statistics/out-broadcast-packets\" : \"614\" , \"/srl_nokia-interfaces:interface/statistics/out-error-packets\" : \"0\" , \"/srl_nokia-interfaces:interface/statistics/out-multicast-packets\" : \"11\" , \"/srl_nokia-interfaces:interface/statistics/out-octets\" : \"64721394\" , \"/srl_nokia-interfaces:interface/statistics/out-unicast-packets\" : \"105876\" } } Event format after { }","title":"Examples"},{"location":"user_guide/event_processors/event_duration_convert/","text":"The event-duration-convert processor, converts duration written as string to a integer with second precision. The string format supported is a series of digits and a single letter indicating the unit, e.g 1w3d (1 week 3 days) The highest unit is w for week and the lowest is s for second. Any of the units may or may not be present. Examples # simple conversion # processors : # processor name convert-uptime : # processor type event-duration-convert : # list of regex to be matched with the values names value-names : - \".*_uptime$\" # keep the original value, # a new value name will be added with the converted value, # the new value name will be the original name with _seconds as suffix keep : false # debug, enables this processor logging debug : false Event format before { \"name\" : \"default\" , \"timestamp\" : 1607290633806716620 , \"tags\" : { \"port_port-id\" : \"A/1\" , \"source\" : \"172.17.0.100:57400\" , \"subscription-name\" : \"default\" }, \"values\" : { \"connection_uptime\" : \"1w5s\" } } Event format after { \"name\" : \"default\" , \"timestamp\" : 1607290633806716620 , \"tags\" : { \"port_port-id\" : \"A/1\" , \"source\" : \"172.17.0.100:57400\" , \"subscription-name\" : \"default\" }, \"values\" : { \"connection_uptime\" : 604805 } }","title":"Duration Convert"},{"location":"user_guide/event_processors/event_duration_convert/#examples","text":"","title":"Examples"},{"location":"user_guide/event_processors/event_duration_convert/#simple-conversion","text":"processors : # processor name convert-uptime : # processor type event-duration-convert : # list of regex to be matched with the values names value-names : - \".*_uptime$\" # keep the original value, # a new value name will be added with the converted value, # the new value name will be the original name with _seconds as suffix keep : false # debug, enables this processor logging debug : false Event format before { \"name\" : \"default\" , \"timestamp\" : 1607290633806716620 , \"tags\" : { \"port_port-id\" : \"A/1\" , \"source\" : \"172.17.0.100:57400\" , \"subscription-name\" : \"default\" }, \"values\" : { \"connection_uptime\" : \"1w5s\" } } Event format after { \"name\" : \"default\" , \"timestamp\" : 1607290633806716620 , \"tags\" : { \"port_port-id\" : \"A/1\" , \"source\" : \"172.17.0.100:57400\" , \"subscription-name\" : \"default\" }, \"values\" : { \"connection_uptime\" : 604805 } }","title":"simple conversion"},{"location":"user_guide/event_processors/event_extract_tags/","text":"The event-extract-tags processor, extracts tags from a value, a value name, a tag name or a tag value using regex named groups. It is possible to overwrite a tag if its name already exists. processors : # processor name sample-processor : # processor type event-extract-tags : # list of regular expressions to be used to extract strings to be added as a tag. tag-names : # list of regular expressions to be used to extract strings to be added as a tag. tags : # list of regular expressions to be used to extract strings to be added as a tag. value-names : # list of regular expressions to be used to extract strings to be added as a tag. values : # boolean, if true tags are over-written with the added ones if they already exist. overwrite : # boolean, enable extra logging debug : Examples # processors : # processor name sample-processor : # processor type event-extract-tags : value-names : - ` /(\\w+)/(?P<group>\\w+)/(\\w+)` Event format before { \"name\" : \"default\" , \"timestamp\" : 1607291271894072397 , \"tags\" : { \"interface_name\" : \"mgmt0\" , \"source\" : \"172.23.23.2:57400\" , \"subscription-name\" : \"default\" }, \"values\" : { \"/srl_nokia-interfaces:interface/statistics/carrier-transitions\" : \"1\" , \"/srl_nokia-interfaces:interface/statistics/in-broadcast-packets\" : \"3797\" , \"/srl_nokia-interfaces:interface/statistics/in-error-packets\" : \"0\" , \"/srl_nokia-interfaces:interface/statistics/in-fcs-error-packets\" : \"0\" , \"/srl_nokia-interfaces:interface/statistics/in-multicast-packets\" : \"288033\" , \"/srl_nokia-interfaces:interface/statistics/in-octets\" : \"65382630\" , \"/srl_nokia-interfaces:interface/statistics/in-unicast-packets\" : \"107154\" , \"/srl_nokia-interfaces:interface/statistics/out-broadcast-packets\" : \"614\" , \"/srl_nokia-interfaces:interface/statistics/out-error-packets\" : \"0\" , \"/srl_nokia-interfaces:interface/statistics/out-multicast-packets\" : \"11\" , \"/srl_nokia-interfaces:interface/statistics/out-octets\" : \"64721394\" , \"/srl_nokia-interfaces:interface/statistics/out-unicast-packets\" : \"105876\" } } Event format after { \"name\" : \"default\" , \"timestamp\" : 1607291271894072397 , \"tags\" : { \"interface_name\" : \"mgmt0\" , \"source\" : \"172.23.23.2:57400\" , \"group\" : \"statistics\" , \"subscription-name\" : \"default\" }, \"values\" : { \"/srl_nokia-interfaces:interface/statistics/carrier-transitions\" : \"1\" , \"/srl_nokia-interfaces:interface/statistics/in-broadcast-packets\" : \"3797\" , \"/srl_nokia-interfaces:interface/statistics/in-error-packets\" : \"0\" , \"/srl_nokia-interfaces:interface/statistics/in-fcs-error-packets\" : \"0\" , \"/srl_nokia-interfaces:interface/statistics/in-multicast-packets\" : \"288033\" , \"/srl_nokia-interfaces:interface/statistics/in-octets\" : \"65382630\" , \"/srl_nokia-interfaces:interface/statistics/in-unicast-packets\" : \"107154\" , \"/srl_nokia-interfaces:interface/statistics/out-broadcast-packets\" : \"614\" , \"/srl_nokia-interfaces:interface/statistics/out-error-packets\" : \"0\" , \"/srl_nokia-interfaces:interface/statistics/out-multicast-packets\" : \"11\" , \"/srl_nokia-interfaces:interface/statistics/out-octets\" : \"64721394\" , \"/srl_nokia-interfaces:interface/statistics/out-unicast-packets\" : \"105876\" } }","title":"Extract Tags"},{"location":"user_guide/event_processors/event_extract_tags/#examples","text":"processors : # processor name sample-processor : # processor type event-extract-tags : value-names : - ` /(\\w+)/(?P<group>\\w+)/(\\w+)` Event format before { \"name\" : \"default\" , \"timestamp\" : 1607291271894072397 , \"tags\" : { \"interface_name\" : \"mgmt0\" , \"source\" : \"172.23.23.2:57400\" , \"subscription-name\" : \"default\" }, \"values\" : { \"/srl_nokia-interfaces:interface/statistics/carrier-transitions\" : \"1\" , \"/srl_nokia-interfaces:interface/statistics/in-broadcast-packets\" : \"3797\" , \"/srl_nokia-interfaces:interface/statistics/in-error-packets\" : \"0\" , \"/srl_nokia-interfaces:interface/statistics/in-fcs-error-packets\" : \"0\" , \"/srl_nokia-interfaces:interface/statistics/in-multicast-packets\" : \"288033\" , \"/srl_nokia-interfaces:interface/statistics/in-octets\" : \"65382630\" , \"/srl_nokia-interfaces:interface/statistics/in-unicast-packets\" : \"107154\" , \"/srl_nokia-interfaces:interface/statistics/out-broadcast-packets\" : \"614\" , \"/srl_nokia-interfaces:interface/statistics/out-error-packets\" : \"0\" , \"/srl_nokia-interfaces:interface/statistics/out-multicast-packets\" : \"11\" , \"/srl_nokia-interfaces:interface/statistics/out-octets\" : \"64721394\" , \"/srl_nokia-interfaces:interface/statistics/out-unicast-packets\" : \"105876\" } } Event format after { \"name\" : \"default\" , \"timestamp\" : 1607291271894072397 , \"tags\" : { \"interface_name\" : \"mgmt0\" , \"source\" : \"172.23.23.2:57400\" , \"group\" : \"statistics\" , \"subscription-name\" : \"default\" }, \"values\" : { \"/srl_nokia-interfaces:interface/statistics/carrier-transitions\" : \"1\" , \"/srl_nokia-interfaces:interface/statistics/in-broadcast-packets\" : \"3797\" , \"/srl_nokia-interfaces:interface/statistics/in-error-packets\" : \"0\" , \"/srl_nokia-interfaces:interface/statistics/in-fcs-error-packets\" : \"0\" , \"/srl_nokia-interfaces:interface/statistics/in-multicast-packets\" : \"288033\" , \"/srl_nokia-interfaces:interface/statistics/in-octets\" : \"65382630\" , \"/srl_nokia-interfaces:interface/statistics/in-unicast-packets\" : \"107154\" , \"/srl_nokia-interfaces:interface/statistics/out-broadcast-packets\" : \"614\" , \"/srl_nokia-interfaces:interface/statistics/out-error-packets\" : \"0\" , \"/srl_nokia-interfaces:interface/statistics/out-multicast-packets\" : \"11\" , \"/srl_nokia-interfaces:interface/statistics/out-octets\" : \"64721394\" , \"/srl_nokia-interfaces:interface/statistics/out-unicast-packets\" : \"105876\" } }","title":"Examples"},{"location":"user_guide/event_processors/event_group_by/","text":"The event-group-by processor, groups values under the same event message based on a list of tag names. This processor is intended to be used together with a output with cached gNMI notifications, like prometheus output with gnmi-cache: true . Configuration # processors : # processor name sample-processor : # processor type event-group-by : # list of strings defining the tags to group by the values under # a single event tags : [] # a boolean, if true only the values from events of the same name # are grouped together according to the list of tags by-name : # boolean debug : false Examples # group by a single tag # processors : group-by-source : event-group-by : tags : - source Event format before [ { \"name\" : \"sub2\" , \"timestamp\" : 1615284691523204299 , \"tags\" : { \"neighbor_peer-address\" : \"2002::1:1:1:1\" , \"network-instance_name\" : \"default\" , \"source\" : \"leaf1:57400\" , \"subscription-name\" : \"sub2\" }, \"values\" : { \"bgp_neighbor_sent_messages_queue_depth\" : 0 , \"bgp_neighbor_sent_messages_total_messages\" : \"423\" , \"bgp_neighbor_sent_messages_total_non_updates\" : \"415\" , \"bgp_neighbor_sent_messages_total_updates\" : \"8\" } }, { \"name\" : \"sub2\" , \"timestamp\" : 1615284691523204299 , \"tags\" : { \"neighbor_peer-address\" : \"2002::1:1:1:1\" , \"network-instance_name\" : \"default\" , \"source\" : \"leaf1:57400\" , \"subscription-name\" : \"sub2\" }, \"values\" : { \"bgp_neighbor_received_messages_malformed_updates\" : \"0\" , \"bgp_neighbor_received_messages_queue_depth\" : 0 , \"bgp_neighbor_received_messages_total_messages\" : \"424\" , \"bgp_neighbor_received_messages_total_non_updates\" : \"418\" , \"bgp_neighbor_received_messages_total_updates\" : \"6\" } } ] Event format after [ { \"name\" : \"sub2\" , \"timestamp\" : 1615284691523204299 , \"tags\" : { \"neighbor_peer-address\" : \"2002::1:1:1:1\" , \"network-instance_name\" : \"default\" , \"source\" : \"leaf1:57400\" , \"subscription-name\" : \"sub2\" }, \"values\" : { \"bgp_neighbor_sent_messages_queue_depth\" : 0 , \"bgp_neighbor_sent_messages_total_messages\" : \"423\" , \"bgp_neighbor_sent_messages_total_non_updates\" : \"415\" , \"bgp_neighbor_sent_messages_total_updates\" : \"8\" , \"bgp_neighbor_received_messages_malformed_updates\" : \"0\" , \"bgp_neighbor_received_messages_queue_depth\" : 0 , \"bgp_neighbor_received_messages_total_messages\" : \"424\" , \"bgp_neighbor_received_messages_total_non_updates\" : \"418\" , \"bgp_neighbor_received_messages_total_updates\" : \"6\" } } ] group by multiple tags # processors : group-by-queue-id : event-group-by : tags : - source - interface_name - multicast-queue_queue-id Event Format Before [ { \"name\" : \"sub1\" , \"timestamp\" : 1627997491187771616 , \"tags\" : { \"interface_name\" : \"ethernet-1/1\" , \"multicast-queue_queue-id\" : \"5\" , \"source\" : \"clab-ndk-srl1:57400\" , \"subscription-name\" : \"sub1\" , }, \"values\" : { \"/interface/qos/output/multicast-queue/queue-depth/maximum-burst-size\" : \"0\" } }, { \"name\" : \"sub1\" , \"timestamp\" : 1627997491187771616 , \"tags\" : { \"interface_name\" : \"ethernet-1/1\" , \"multicast-queue_queue-id\" : \"5\" , \"source\" : \"clab-ndk-srl1:57400\" , \"subscription-name\" : \"sub1\" , }, \"values\" : { \"/interface/qos/output/multicast-queue/scheduling/peak-rate-bps\" : \"0\" } } ] Event Format After [ { \"name\" : \"sub1\" , \"timestamp\" : 1627997491187771616 , \"tags\" : { \"interface_name\" : \"ethernet-1/1\" , \"multicast-queue_queue-id\" : \"5\" , \"source\" : \"clab-ndk-srl1:57400\" , \"subscription-name\" : \"sub1\" , }, \"values\" : { \"/interface/qos/output/multicast-queue/queue-depth/maximum-burst-size\" : \"0\" , \"/interface/qos/output/multicast-queue/scheduling/peak-rate-bps\" : \"0\" } } ]","title":"Group by"},{"location":"user_guide/event_processors/event_group_by/#configuration","text":"processors : # processor name sample-processor : # processor type event-group-by : # list of strings defining the tags to group by the values under # a single event tags : [] # a boolean, if true only the values from events of the same name # are grouped together according to the list of tags by-name : # boolean debug : false","title":"Configuration"},{"location":"user_guide/event_processors/event_group_by/#examples","text":"","title":"Examples"},{"location":"user_guide/event_processors/event_group_by/#group-by-a-single-tag","text":"processors : group-by-source : event-group-by : tags : - source Event format before [ { \"name\" : \"sub2\" , \"timestamp\" : 1615284691523204299 , \"tags\" : { \"neighbor_peer-address\" : \"2002::1:1:1:1\" , \"network-instance_name\" : \"default\" , \"source\" : \"leaf1:57400\" , \"subscription-name\" : \"sub2\" }, \"values\" : { \"bgp_neighbor_sent_messages_queue_depth\" : 0 , \"bgp_neighbor_sent_messages_total_messages\" : \"423\" , \"bgp_neighbor_sent_messages_total_non_updates\" : \"415\" , \"bgp_neighbor_sent_messages_total_updates\" : \"8\" } }, { \"name\" : \"sub2\" , \"timestamp\" : 1615284691523204299 , \"tags\" : { \"neighbor_peer-address\" : \"2002::1:1:1:1\" , \"network-instance_name\" : \"default\" , \"source\" : \"leaf1:57400\" , \"subscription-name\" : \"sub2\" }, \"values\" : { \"bgp_neighbor_received_messages_malformed_updates\" : \"0\" , \"bgp_neighbor_received_messages_queue_depth\" : 0 , \"bgp_neighbor_received_messages_total_messages\" : \"424\" , \"bgp_neighbor_received_messages_total_non_updates\" : \"418\" , \"bgp_neighbor_received_messages_total_updates\" : \"6\" } } ] Event format after [ { \"name\" : \"sub2\" , \"timestamp\" : 1615284691523204299 , \"tags\" : { \"neighbor_peer-address\" : \"2002::1:1:1:1\" , \"network-instance_name\" : \"default\" , \"source\" : \"leaf1:57400\" , \"subscription-name\" : \"sub2\" }, \"values\" : { \"bgp_neighbor_sent_messages_queue_depth\" : 0 , \"bgp_neighbor_sent_messages_total_messages\" : \"423\" , \"bgp_neighbor_sent_messages_total_non_updates\" : \"415\" , \"bgp_neighbor_sent_messages_total_updates\" : \"8\" , \"bgp_neighbor_received_messages_malformed_updates\" : \"0\" , \"bgp_neighbor_received_messages_queue_depth\" : 0 , \"bgp_neighbor_received_messages_total_messages\" : \"424\" , \"bgp_neighbor_received_messages_total_non_updates\" : \"418\" , \"bgp_neighbor_received_messages_total_updates\" : \"6\" } } ]","title":"group by a single tag"},{"location":"user_guide/event_processors/event_group_by/#group-by-multiple-tags","text":"processors : group-by-queue-id : event-group-by : tags : - source - interface_name - multicast-queue_queue-id Event Format Before [ { \"name\" : \"sub1\" , \"timestamp\" : 1627997491187771616 , \"tags\" : { \"interface_name\" : \"ethernet-1/1\" , \"multicast-queue_queue-id\" : \"5\" , \"source\" : \"clab-ndk-srl1:57400\" , \"subscription-name\" : \"sub1\" , }, \"values\" : { \"/interface/qos/output/multicast-queue/queue-depth/maximum-burst-size\" : \"0\" } }, { \"name\" : \"sub1\" , \"timestamp\" : 1627997491187771616 , \"tags\" : { \"interface_name\" : \"ethernet-1/1\" , \"multicast-queue_queue-id\" : \"5\" , \"source\" : \"clab-ndk-srl1:57400\" , \"subscription-name\" : \"sub1\" , }, \"values\" : { \"/interface/qos/output/multicast-queue/scheduling/peak-rate-bps\" : \"0\" } } ] Event Format After [ { \"name\" : \"sub1\" , \"timestamp\" : 1627997491187771616 , \"tags\" : { \"interface_name\" : \"ethernet-1/1\" , \"multicast-queue_queue-id\" : \"5\" , \"source\" : \"clab-ndk-srl1:57400\" , \"subscription-name\" : \"sub1\" , }, \"values\" : { \"/interface/qos/output/multicast-queue/queue-depth/maximum-burst-size\" : \"0\" , \"/interface/qos/output/multicast-queue/scheduling/peak-rate-bps\" : \"0\" } } ]","title":"group by multiple tags"},{"location":"user_guide/event_processors/event_jq/","text":"The event-jq processor, applies a jq expression on the received event messages. jq expressions are a powerful tool that can be used to slice, filter, map, transform JSON object. The event-jq processor uses two configuration fields, condition and expression , both support jq expressions. condition (that needs to return a boolean value) determines if the processor is to be applied on the event message. if false the message is returned as is. expression is used to transform, filter and/or enrich the messages. It needs to return a JSON object that can be mapped to an array of event messages. The event messages resulting from a single gNMI Notification are passed to the jq expression as a JSON array. Some jq expression examples: Select messages with name \"sub1\" that include a value called \"counter1\" with value higher than 90 expression : .[] | select(.name==\"sub1\" and .values.counter1 > 90) Delete values with name \"counter1\" expression : .[] | del(.values.counter1) Delete values with names \"counter1\" or \"counter2\" expression : .[] | del(.values.[\"counter1\", \"counter2\"]) Delete tags with names \"tag1\" or \"tag2\" expression : .[] | del(.tags.[\"tag1\", \"tag2\"]) Add a tag called \"my_new_tag\" with value \"tag1\" expression : .[] |= (.tags.my_new_tag = \"tag1\") Move a value to tag under a custom key expression : .[] |= (.tags.my_new_tag_name = .values.value_name) Configuration # processors : # processor name sample-processor : # processor type event-jq : # condition of application of the processor condition : # jq expression to transform/filter/enrich the message expression : # boolean enabling extra logging debug :","title":"JQ"},{"location":"user_guide/event_processors/event_jq/#configuration","text":"processors : # processor name sample-processor : # processor type event-jq : # condition of application of the processor condition : # jq expression to transform/filter/enrich the message expression : # boolean enabling extra logging debug :","title":"Configuration"},{"location":"user_guide/event_processors/event_merge/","text":"The event-merge processor, merges multiple event messages together based on some criteria. Each gNMI subscribe Response Update in a gNMI subscribe Response Notification is transformed into an Event Message The event-merge processor is used to merge the updates into one event message if it's needed. The default merge strategy is based on the timestamp, the updates with the same timestamp will be merged into the same event message. processors : # processor name sample-processor : # processor type event-merge : # if always is set to true, # the updates are merged regardless of the timestamp values always : false debug : false Event format before [ { \"name\" : \"sub2\" , \"timestamp\" : 1615284691523204299 , \"tags\" : { \"neighbor_peer-address\" : \"2002::1:1:1:1\" , \"network-instance_name\" : \"default\" , \"source\" : \"leaf1:57400\" , \"subscription-name\" : \"sub2\" }, \"values\" : { \"bgp_neighbor_sent_messages_queue_depth\" : 0 , \"bgp_neighbor_sent_messages_total_messages\" : \"423\" , \"bgp_neighbor_sent_messages_total_non_updates\" : \"415\" , \"bgp_neighbor_sent_messages_total_updates\" : \"8\" } }, { \"name\" : \"sub2\" , \"timestamp\" : 1615284691523204299 , \"tags\" : { \"neighbor_peer-address\" : \"2002::1:1:1:1\" , \"network-instance_name\" : \"default\" , \"source\" : \"leaf1:57400\" , \"subscription-name\" : \"sub2\" }, \"values\" : { \"bgp_neighbor_received_messages_malformed_updates\" : \"0\" , \"bgp_neighbor_received_messages_queue_depth\" : 0 , \"bgp_neighbor_received_messages_total_messages\" : \"424\" , \"bgp_neighbor_received_messages_total_non_updates\" : \"418\" , \"bgp_neighbor_received_messages_total_updates\" : \"6\" } } ] Event format after [ { \"name\" : \"sub2\" , \"timestamp\" : 1615284691523204299 , \"tags\" : { \"neighbor_peer-address\" : \"2002::1:1:1:1\" , \"network-instance_name\" : \"default\" , \"source\" : \"leaf1:57400\" , \"subscription-name\" : \"sub2\" }, \"values\" : { \"bgp_neighbor_sent_messages_queue_depth\" : 0 , \"bgp_neighbor_sent_messages_total_messages\" : \"423\" , \"bgp_neighbor_sent_messages_total_non_updates\" : \"415\" , \"bgp_neighbor_sent_messages_total_updates\" : \"8\" , \"bgp_neighbor_received_messages_malformed_updates\" : \"0\" , \"bgp_neighbor_received_messages_queue_depth\" : 0 , \"bgp_neighbor_received_messages_total_messages\" : \"424\" , \"bgp_neighbor_received_messages_total_non_updates\" : \"418\" , \"bgp_neighbor_received_messages_total_updates\" : \"6\" } } ]","title":"Merge"},{"location":"user_guide/event_processors/event_override_ts/","text":"The event-override-ts processor, overrides the message timestamp with time.Now() . The precision s , ms , us or ns (default) can be configured. Examples # processors : # processor name set-timestamp-processor : # processor type event-override-ts : # timestamp precision, s, ms, us, ns (default) precision : ms","title":"Override TS"},{"location":"user_guide/event_processors/event_override_ts/#examples","text":"processors : # processor name set-timestamp-processor : # processor type event-override-ts : # timestamp precision, s, ms, us, ns (default) precision : ms","title":"Examples"},{"location":"user_guide/event_processors/event_strings/","text":"The event-strings processor, exposes a few of Golang strings transformation functions, there functions can be applied to tags, tag names, values or value names. Supported functions: strings.Replace strings.TrimPrefix strings.TrimSuffix strings.Title strings.ToLower strings.ToUpper strings.Split filepath.Base processors : # processor name sample-processor : # processor type event-strings : value-names : [] tag-names : [] values : [] tags : [] transforms : # strings function name - replace : apply-on : # apply the transformation on name or value keep : # keep the old value or not if the name changed old : # string to be replaced new : #replacement string of old - trim-prefix : apply-on : # apply the transformation on name or value prefix : # prefix to be trimmed - trim_suffix : apply-on : # apply the transformation on name or value suffix : # suffix to be trimmed - title : apply-on : # apply the transformation on name or value - to-upper : apply-on : # apply the transformation on name or value - to-lower : apply-on : # apply the transformation on name or value - split : apply-on : # apply the transformation on name or value split-on : # character to split on join-with : # character to join with ignore-first : # number of first items to ignore when joining ignore-last : # number of last items to ignore when joining - path-base : apply-on : # apply the transformation on name or value Examples # replace # processors : # processor name sample-processor : # processor type event-strings : value-names : - \".*\" transforms : # strings function name - replace : apply-on : \"name\" old : \"-\" new : \"_\" Event format before { \"name\" : \"default\" , \"timestamp\" : 1607291271894072397 , \"tags\" : { \"interface_name\" : \"mgmt0\" , \"source\" : \"172.23.23.2:57400\" , \"subscription-name\" : \"default\" }, \"values\" : { \"carrier-transitions\" : \"1\" , \"in-error-packets\" : \"0\" , \"in-fcs-error-packets\" : \"0\" , \"in-octets\" : \"65382630\" , \"in-unicast-packets\" : \"107154\" , \"out-error-packets\" : \"0\" , \"out-octets\" : \"64721394\" , \"out-unicast-packets\" : \"105876\" } } Event format after { \"name\" : \"default\" , \"timestamp\" : 1607291271894072397 , \"tags\" : { \"interface_name\" : \"mgmt0\" , \"source\" : \"172.23.23.2:57400\" , \"subscription-name\" : \"default\" }, \"values\" : { \"carrier_transitions\" : \"1\" , \"in_error_packets\" : \"0\" , \"in_fcs_error_packets\" : \"0\" , \"in_octets\" : \"65382630\" , \"in_unicast_packets\" : \"107154\" , \"out_error_packets\" : \"0\" , \"out_octets\" : \"64721394\" , \"out_unicast_packets\" : \"105876\" } } trim-prefix # processors : # processor name sample-processor : # processor type event-strings : value-names : - \".*\" transforms : # strings function name - trim-prefix : apply-on : \"name\" prefix : \"/srl_nokia-interfaces:interface/statistics/\" Event format before { \"name\" : \"default\" , \"timestamp\" : 1607291271894072397 , \"tags\" : { \"interface_name\" : \"mgmt0\" , \"source\" : \"172.23.23.2:57400\" , \"subscription-name\" : \"default\" }, \"values\" : { \"/srl_nokia-interfaces:interface/statistics/carrier-transitions\" : \"1\" , \"/srl_nokia-interfaces:interface/statistics/in-broadcast-packets\" : \"3797\" , \"/srl_nokia-interfaces:interface/statistics/in-error-packets\" : \"0\" , \"/srl_nokia-interfaces:interface/statistics/in-fcs-error-packets\" : \"0\" , \"/srl_nokia-interfaces:interface/statistics/in-multicast-packets\" : \"288033\" , \"/srl_nokia-interfaces:interface/statistics/in-octets\" : \"65382630\" , \"/srl_nokia-interfaces:interface/statistics/in-unicast-packets\" : \"107154\" , \"/srl_nokia-interfaces:interface/statistics/out-broadcast-packets\" : \"614\" , \"/srl_nokia-interfaces:interface/statistics/out-error-packets\" : \"0\" , \"/srl_nokia-interfaces:interface/statistics/out-multicast-packets\" : \"11\" , \"/srl_nokia-interfaces:interface/statistics/out-octets\" : \"64721394\" , \"/srl_nokia-interfaces:interface/statistics/out-unicast-packets\" : \"105876\" } } Event format after { \"name\" : \"default\" , \"timestamp\" : 1607291271894072397 , \"tags\" : { \"interface_name\" : \"mgmt0\" , \"source\" : \"172.23.23.2:57400\" , \"subscription-name\" : \"default\" }, \"values\" : { \"carrier-transitions\" : \"1\" , \"in-broadcast-packets\" : \"3797\" , \"in-error-packets\" : \"0\" , \"in-fcs-error-packets\" : \"0\" , \"in-multicast-packets\" : \"288033\" , \"in-octets\" : \"65382630\" , \"in-unicast-packets\" : \"107154\" , \"out-broadcast-packets\" : \"614\" , \"out-error-packets\" : \"0\" , \"out-multicast-packets\" : \"11\" , \"out-octets\" : \"64721394\" , \"out-unicast-packets\" : \"105876\" } } to-upper # processors : # processor name sample-processor : # processor type event-strings : tag-names : - \"interface_name\" - \"subscription-name\" transforms : # strings function name - to-upper : apply-on : \"value\" Event format before { \"name\" : \"default\" , \"timestamp\" : 1607291271894072397 , \"tags\" : { \"interface_name\" : \"mgmt0\" , \"source\" : \"172.23.23.2:57400\" , \"subscription-name\" : \"default\" }, \"values\" : { \"/srl_nokia-interfaces:interface/statistics/carrier-transitions\" : \"1\" , \"/srl_nokia-interfaces:interface/statistics/in-broadcast-packets\" : \"3797\" , \"/srl_nokia-interfaces:interface/statistics/in-error-packets\" : \"0\" , \"/srl_nokia-interfaces:interface/statistics/in-fcs-error-packets\" : \"0\" , \"/srl_nokia-interfaces:interface/statistics/in-multicast-packets\" : \"288033\" , \"/srl_nokia-interfaces:interface/statistics/in-octets\" : \"65382630\" , \"/srl_nokia-interfaces:interface/statistics/in-unicast-packets\" : \"107154\" , \"/srl_nokia-interfaces:interface/statistics/out-broadcast-packets\" : \"614\" , \"/srl_nokia-interfaces:interface/statistics/out-error-packets\" : \"0\" , \"/srl_nokia-interfaces:interface/statistics/out-multicast-packets\" : \"11\" , \"/srl_nokia-interfaces:interface/statistics/out-octets\" : \"64721394\" , \"/srl_nokia-interfaces:interface/statistics/out-unicast-packets\" : \"105876\" } } Event format after { \"name\" : \"default\" , \"timestamp\" : 1607291271894072397 , \"tags\" : { \"interface_name\" : \"MGMT0\" , \"source\" : \"172.23.23.2:57400\" , \"subscription-name\" : \"DEFAULT\" }, \"values\" : { \"/srl_nokia-interfaces:interface/statistics/carrier-transitions\" : \"1\" , \"/srl_nokia-interfaces:interface/statistics/in-broadcast-packets\" : \"3797\" , \"/srl_nokia-interfaces:interface/statistics/in-error-packets\" : \"0\" , \"/srl_nokia-interfaces:interface/statistics/in-fcs-error-packets\" : \"0\" , \"/srl_nokia-interfaces:interface/statistics/in-multicast-packets\" : \"288033\" , \"/srl_nokia-interfaces:interface/statistics/in-octets\" : \"65382630\" , \"/srl_nokia-interfaces:interface/statistics/in-unicast-packets\" : \"107154\" , \"/srl_nokia-interfaces:interface/statistics/out-broadcast-packets\" : \"614\" , \"/srl_nokia-interfaces:interface/statistics/out-error-packets\" : \"0\" , \"/srl_nokia-interfaces:interface/statistics/out-multicast-packets\" : \"11\" , \"/srl_nokia-interfaces:interface/statistics/out-octets\" : \"64721394\" , \"/srl_nokia-interfaces:interface/statistics/out-unicast-packets\" : \"105876\" } } path-base # processors : # processor name sample-processor : # processor type event-strings : value-names : - \".*\" transforms : # strings function name - path-base : apply-on : \"name\" Event format before { \"name\" : \"default\" , \"timestamp\" : 1607291271894072397 , \"tags\" : { \"interface_name\" : \"mgmt0\" , \"source\" : \"172.23.23.2:57400\" , \"subscription-name\" : \"default\" }, \"values\" : { \"/srl_nokia-interfaces:interface/statistics/carrier-transitions\" : \"1\" , \"/srl_nokia-interfaces:interface/statistics/in-broadcast-packets\" : \"3797\" , \"/srl_nokia-interfaces:interface/statistics/in-error-packets\" : \"0\" , \"/srl_nokia-interfaces:interface/statistics/in-fcs-error-packets\" : \"0\" , \"/srl_nokia-interfaces:interface/statistics/in-multicast-packets\" : \"288033\" , \"/srl_nokia-interfaces:interface/statistics/in-octets\" : \"65382630\" , \"/srl_nokia-interfaces:interface/statistics/in-unicast-packets\" : \"107154\" , \"/srl_nokia-interfaces:interface/statistics/out-broadcast-packets\" : \"614\" , \"/srl_nokia-interfaces:interface/statistics/out-error-packets\" : \"0\" , \"/srl_nokia-interfaces:interface/statistics/out-multicast-packets\" : \"11\" , \"/srl_nokia-interfaces:interface/statistics/out-octets\" : \"64721394\" , \"/srl_nokia-interfaces:interface/statistics/out-unicast-packets\" : \"105876\" } } Event format after { \"name\" : \"default\" , \"timestamp\" : 1607291271894072397 , \"tags\" : { \"interface_name\" : \"mgmt0\" , \"source\" : \"172.23.23.2:57400\" , \"subscription-name\" : \"default\" }, \"values\" : { \"carrier-transitions\" : \"1\" , \"in-broadcast-packets\" : \"3797\" , \"in-error-packets\" : \"0\" , \"in-fcs-error-packets\" : \"0\" , \"in-multicast-packets\" : \"288033\" , \"in-octets\" : \"65382630\" , \"in-unicast-packets\" : \"107154\" , \"out-broadcast-packets\" : \"614\" , \"out-error-packets\" : \"0\" , \"out-multicast-packets\" : \"11\" , \"out-octets\" : \"64721394\" , \"out-unicast-packets\" : \"105876\" } } split # processors : # processor name sample-processor : # processor type event-strings : value-names : - \".*\" transforms : # strings function name - split : on : \"name\" split-on : \"/\" join-with : \"_\" ignore-first : 1 Event format before { \"name\" : \"default\" , \"timestamp\" : 1607291271894072397 , \"tags\" : { \"interface_name\" : \"mgmt0\" , \"source\" : \"172.23.23.2:57400\" , \"subscription-name\" : \"default\" }, \"values\" : { \"/srl_nokia-interfaces:interface/statistics/carrier-transitions\" : \"1\" , \"/srl_nokia-interfaces:interface/statistics/in-broadcast-packets\" : \"3797\" , \"/srl_nokia-interfaces:interface/statistics/in-error-packets\" : \"0\" , \"/srl_nokia-interfaces:interface/statistics/in-fcs-error-packets\" : \"0\" , \"/srl_nokia-interfaces:interface/statistics/in-multicast-packets\" : \"288033\" , \"/srl_nokia-interfaces:interface/statistics/in-octets\" : \"65382630\" , \"/srl_nokia-interfaces:interface/statistics/in-unicast-packets\" : \"107154\" , \"/srl_nokia-interfaces:interface/statistics/out-broadcast-packets\" : \"614\" , \"/srl_nokia-interfaces:interface/statistics/out-error-packets\" : \"0\" , \"/srl_nokia-interfaces:interface/statistics/out-multicast-packets\" : \"11\" , \"/srl_nokia-interfaces:interface/statistics/out-octets\" : \"64721394\" , \"/srl_nokia-interfaces:interface/statistics/out-unicast-packets\" : \"105876\" } } Event format after { \"name\" : \"default\" , \"timestamp\" : 1607291271894072397 , \"tags\" : { \"interface_name\" : \"mgmt0\" , \"source\" : \"172.23.23.2:57400\" , \"subscription-name\" : \"default\" }, \"values\" : { \"statistics_carrier-transitions\" : \"1\" , \"statistics_in-broadcast-packets\" : \"3797\" , \"statistics_in-error-packets\" : \"0\" , \"statistics_in-fcs-error-packets\" : \"0\" , \"statistics_in-multicast-packets\" : \"288033\" , \"statistics_in-octets\" : \"65382630\" , \"statistics_in-unicast-packets\" : \"107154\" , \"statistics_out-broadcast-packets\" : \"614\" , \"statistics_out-error-packets\" : \"0\" , \"statistics_out-multicast-packets\" : \"11\" , \"statistics_out-octets\" : \"64721394\" , \"statistics_out-unicast-packets\" : \"105876\" } } multiple transforms # processors : # processor name sample-processor : # processor type event-strings : value-names : - \".*\" transforms : # strings function name - path-base : apply-on : \"name\" - title : apply-on : \"name\" - replace : apply-on : \"name\" old : \"-\" new : \"_\" Event format before { \"name\" : \"default\" , \"timestamp\" : 1607291271894072397 , \"tags\" : { \"interface_name\" : \"mgmt0\" , \"source\" : \"172.23.23.2:57400\" , \"subscription-name\" : \"default\" }, \"values\" : { \"/srl_nokia-interfaces:interface/statistics/carrier-transitions\" : \"1\" , \"/srl_nokia-interfaces:interface/statistics/in-broadcast-packets\" : \"3797\" , \"/srl_nokia-interfaces:interface/statistics/in-error-packets\" : \"0\" , \"/srl_nokia-interfaces:interface/statistics/in-fcs-error-packets\" : \"0\" , \"/srl_nokia-interfaces:interface/statistics/in-multicast-packets\" : \"288033\" , \"/srl_nokia-interfaces:interface/statistics/in-octets\" : \"65382630\" , \"/srl_nokia-interfaces:interface/statistics/in-unicast-packets\" : \"107154\" , \"/srl_nokia-interfaces:interface/statistics/out-broadcast-packets\" : \"614\" , \"/srl_nokia-interfaces:interface/statistics/out-error-packets\" : \"0\" , \"/srl_nokia-interfaces:interface/statistics/out-multicast-packets\" : \"11\" , \"/srl_nokia-interfaces:interface/statistics/out-octets\" : \"64721394\" , \"/srl_nokia-interfaces:interface/statistics/out-unicast-packets\" : \"105876\" } } Event format after { \"name\" : \"default\" , \"timestamp\" : 1607291271894072397 , \"tags\" : { \"interface_name\" : \"mgmt0\" , \"source\" : \"172.23.23.2:57400\" , \"subscription-name\" : \"default\" }, \"values\" : { \"Carrier_transitions\" : \"1\" , \"In_broadcast_packets\" : \"3797\" , \"In_error_packets\" : \"0\" , \"In_fcs_error_packets\" : \"0\" , \"In_multicast_packets\" : \"288033\" , \"In_octets\" : \"65382630\" , \"In_unicast_packets\" : \"107154\" , \"Out_broadcast_packets\" : \"614\" , \"Out_error_packets\" : \"0\" , \"Out_multicast_packets\" : \"11\" , \"Out_octets\" : \"64721394\" , \"Out_unicast_packets\" : \"105876\" } }","title":"Strings"},{"location":"user_guide/event_processors/event_strings/#examples","text":"","title":"Examples"},{"location":"user_guide/event_processors/event_strings/#replace","text":"processors : # processor name sample-processor : # processor type event-strings : value-names : - \".*\" transforms : # strings function name - replace : apply-on : \"name\" old : \"-\" new : \"_\" Event format before { \"name\" : \"default\" , \"timestamp\" : 1607291271894072397 , \"tags\" : { \"interface_name\" : \"mgmt0\" , \"source\" : \"172.23.23.2:57400\" , \"subscription-name\" : \"default\" }, \"values\" : { \"carrier-transitions\" : \"1\" , \"in-error-packets\" : \"0\" , \"in-fcs-error-packets\" : \"0\" , \"in-octets\" : \"65382630\" , \"in-unicast-packets\" : \"107154\" , \"out-error-packets\" : \"0\" , \"out-octets\" : \"64721394\" , \"out-unicast-packets\" : \"105876\" } } Event format after { \"name\" : \"default\" , \"timestamp\" : 1607291271894072397 , \"tags\" : { \"interface_name\" : \"mgmt0\" , \"source\" : \"172.23.23.2:57400\" , \"subscription-name\" : \"default\" }, \"values\" : { \"carrier_transitions\" : \"1\" , \"in_error_packets\" : \"0\" , \"in_fcs_error_packets\" : \"0\" , \"in_octets\" : \"65382630\" , \"in_unicast_packets\" : \"107154\" , \"out_error_packets\" : \"0\" , \"out_octets\" : \"64721394\" , \"out_unicast_packets\" : \"105876\" } }","title":"replace"},{"location":"user_guide/event_processors/event_strings/#trim-prefix","text":"processors : # processor name sample-processor : # processor type event-strings : value-names : - \".*\" transforms : # strings function name - trim-prefix : apply-on : \"name\" prefix : \"/srl_nokia-interfaces:interface/statistics/\" Event format before { \"name\" : \"default\" , \"timestamp\" : 1607291271894072397 , \"tags\" : { \"interface_name\" : \"mgmt0\" , \"source\" : \"172.23.23.2:57400\" , \"subscription-name\" : \"default\" }, \"values\" : { \"/srl_nokia-interfaces:interface/statistics/carrier-transitions\" : \"1\" , \"/srl_nokia-interfaces:interface/statistics/in-broadcast-packets\" : \"3797\" , \"/srl_nokia-interfaces:interface/statistics/in-error-packets\" : \"0\" , \"/srl_nokia-interfaces:interface/statistics/in-fcs-error-packets\" : \"0\" , \"/srl_nokia-interfaces:interface/statistics/in-multicast-packets\" : \"288033\" , \"/srl_nokia-interfaces:interface/statistics/in-octets\" : \"65382630\" , \"/srl_nokia-interfaces:interface/statistics/in-unicast-packets\" : \"107154\" , \"/srl_nokia-interfaces:interface/statistics/out-broadcast-packets\" : \"614\" , \"/srl_nokia-interfaces:interface/statistics/out-error-packets\" : \"0\" , \"/srl_nokia-interfaces:interface/statistics/out-multicast-packets\" : \"11\" , \"/srl_nokia-interfaces:interface/statistics/out-octets\" : \"64721394\" , \"/srl_nokia-interfaces:interface/statistics/out-unicast-packets\" : \"105876\" } } Event format after { \"name\" : \"default\" , \"timestamp\" : 1607291271894072397 , \"tags\" : { \"interface_name\" : \"mgmt0\" , \"source\" : \"172.23.23.2:57400\" , \"subscription-name\" : \"default\" }, \"values\" : { \"carrier-transitions\" : \"1\" , \"in-broadcast-packets\" : \"3797\" , \"in-error-packets\" : \"0\" , \"in-fcs-error-packets\" : \"0\" , \"in-multicast-packets\" : \"288033\" , \"in-octets\" : \"65382630\" , \"in-unicast-packets\" : \"107154\" , \"out-broadcast-packets\" : \"614\" , \"out-error-packets\" : \"0\" , \"out-multicast-packets\" : \"11\" , \"out-octets\" : \"64721394\" , \"out-unicast-packets\" : \"105876\" } }","title":"trim-prefix"},{"location":"user_guide/event_processors/event_strings/#to-upper","text":"processors : # processor name sample-processor : # processor type event-strings : tag-names : - \"interface_name\" - \"subscription-name\" transforms : # strings function name - to-upper : apply-on : \"value\" Event format before { \"name\" : \"default\" , \"timestamp\" : 1607291271894072397 , \"tags\" : { \"interface_name\" : \"mgmt0\" , \"source\" : \"172.23.23.2:57400\" , \"subscription-name\" : \"default\" }, \"values\" : { \"/srl_nokia-interfaces:interface/statistics/carrier-transitions\" : \"1\" , \"/srl_nokia-interfaces:interface/statistics/in-broadcast-packets\" : \"3797\" , \"/srl_nokia-interfaces:interface/statistics/in-error-packets\" : \"0\" , \"/srl_nokia-interfaces:interface/statistics/in-fcs-error-packets\" : \"0\" , \"/srl_nokia-interfaces:interface/statistics/in-multicast-packets\" : \"288033\" , \"/srl_nokia-interfaces:interface/statistics/in-octets\" : \"65382630\" , \"/srl_nokia-interfaces:interface/statistics/in-unicast-packets\" : \"107154\" , \"/srl_nokia-interfaces:interface/statistics/out-broadcast-packets\" : \"614\" , \"/srl_nokia-interfaces:interface/statistics/out-error-packets\" : \"0\" , \"/srl_nokia-interfaces:interface/statistics/out-multicast-packets\" : \"11\" , \"/srl_nokia-interfaces:interface/statistics/out-octets\" : \"64721394\" , \"/srl_nokia-interfaces:interface/statistics/out-unicast-packets\" : \"105876\" } } Event format after { \"name\" : \"default\" , \"timestamp\" : 1607291271894072397 , \"tags\" : { \"interface_name\" : \"MGMT0\" , \"source\" : \"172.23.23.2:57400\" , \"subscription-name\" : \"DEFAULT\" }, \"values\" : { \"/srl_nokia-interfaces:interface/statistics/carrier-transitions\" : \"1\" , \"/srl_nokia-interfaces:interface/statistics/in-broadcast-packets\" : \"3797\" , \"/srl_nokia-interfaces:interface/statistics/in-error-packets\" : \"0\" , \"/srl_nokia-interfaces:interface/statistics/in-fcs-error-packets\" : \"0\" , \"/srl_nokia-interfaces:interface/statistics/in-multicast-packets\" : \"288033\" , \"/srl_nokia-interfaces:interface/statistics/in-octets\" : \"65382630\" , \"/srl_nokia-interfaces:interface/statistics/in-unicast-packets\" : \"107154\" , \"/srl_nokia-interfaces:interface/statistics/out-broadcast-packets\" : \"614\" , \"/srl_nokia-interfaces:interface/statistics/out-error-packets\" : \"0\" , \"/srl_nokia-interfaces:interface/statistics/out-multicast-packets\" : \"11\" , \"/srl_nokia-interfaces:interface/statistics/out-octets\" : \"64721394\" , \"/srl_nokia-interfaces:interface/statistics/out-unicast-packets\" : \"105876\" } }","title":"to-upper"},{"location":"user_guide/event_processors/event_strings/#path-base","text":"processors : # processor name sample-processor : # processor type event-strings : value-names : - \".*\" transforms : # strings function name - path-base : apply-on : \"name\" Event format before { \"name\" : \"default\" , \"timestamp\" : 1607291271894072397 , \"tags\" : { \"interface_name\" : \"mgmt0\" , \"source\" : \"172.23.23.2:57400\" , \"subscription-name\" : \"default\" }, \"values\" : { \"/srl_nokia-interfaces:interface/statistics/carrier-transitions\" : \"1\" , \"/srl_nokia-interfaces:interface/statistics/in-broadcast-packets\" : \"3797\" , \"/srl_nokia-interfaces:interface/statistics/in-error-packets\" : \"0\" , \"/srl_nokia-interfaces:interface/statistics/in-fcs-error-packets\" : \"0\" , \"/srl_nokia-interfaces:interface/statistics/in-multicast-packets\" : \"288033\" , \"/srl_nokia-interfaces:interface/statistics/in-octets\" : \"65382630\" , \"/srl_nokia-interfaces:interface/statistics/in-unicast-packets\" : \"107154\" , \"/srl_nokia-interfaces:interface/statistics/out-broadcast-packets\" : \"614\" , \"/srl_nokia-interfaces:interface/statistics/out-error-packets\" : \"0\" , \"/srl_nokia-interfaces:interface/statistics/out-multicast-packets\" : \"11\" , \"/srl_nokia-interfaces:interface/statistics/out-octets\" : \"64721394\" , \"/srl_nokia-interfaces:interface/statistics/out-unicast-packets\" : \"105876\" } } Event format after { \"name\" : \"default\" , \"timestamp\" : 1607291271894072397 , \"tags\" : { \"interface_name\" : \"mgmt0\" , \"source\" : \"172.23.23.2:57400\" , \"subscription-name\" : \"default\" }, \"values\" : { \"carrier-transitions\" : \"1\" , \"in-broadcast-packets\" : \"3797\" , \"in-error-packets\" : \"0\" , \"in-fcs-error-packets\" : \"0\" , \"in-multicast-packets\" : \"288033\" , \"in-octets\" : \"65382630\" , \"in-unicast-packets\" : \"107154\" , \"out-broadcast-packets\" : \"614\" , \"out-error-packets\" : \"0\" , \"out-multicast-packets\" : \"11\" , \"out-octets\" : \"64721394\" , \"out-unicast-packets\" : \"105876\" } }","title":"path-base"},{"location":"user_guide/event_processors/event_strings/#split","text":"processors : # processor name sample-processor : # processor type event-strings : value-names : - \".*\" transforms : # strings function name - split : on : \"name\" split-on : \"/\" join-with : \"_\" ignore-first : 1 Event format before { \"name\" : \"default\" , \"timestamp\" : 1607291271894072397 , \"tags\" : { \"interface_name\" : \"mgmt0\" , \"source\" : \"172.23.23.2:57400\" , \"subscription-name\" : \"default\" }, \"values\" : { \"/srl_nokia-interfaces:interface/statistics/carrier-transitions\" : \"1\" , \"/srl_nokia-interfaces:interface/statistics/in-broadcast-packets\" : \"3797\" , \"/srl_nokia-interfaces:interface/statistics/in-error-packets\" : \"0\" , \"/srl_nokia-interfaces:interface/statistics/in-fcs-error-packets\" : \"0\" , \"/srl_nokia-interfaces:interface/statistics/in-multicast-packets\" : \"288033\" , \"/srl_nokia-interfaces:interface/statistics/in-octets\" : \"65382630\" , \"/srl_nokia-interfaces:interface/statistics/in-unicast-packets\" : \"107154\" , \"/srl_nokia-interfaces:interface/statistics/out-broadcast-packets\" : \"614\" , \"/srl_nokia-interfaces:interface/statistics/out-error-packets\" : \"0\" , \"/srl_nokia-interfaces:interface/statistics/out-multicast-packets\" : \"11\" , \"/srl_nokia-interfaces:interface/statistics/out-octets\" : \"64721394\" , \"/srl_nokia-interfaces:interface/statistics/out-unicast-packets\" : \"105876\" } } Event format after { \"name\" : \"default\" , \"timestamp\" : 1607291271894072397 , \"tags\" : { \"interface_name\" : \"mgmt0\" , \"source\" : \"172.23.23.2:57400\" , \"subscription-name\" : \"default\" }, \"values\" : { \"statistics_carrier-transitions\" : \"1\" , \"statistics_in-broadcast-packets\" : \"3797\" , \"statistics_in-error-packets\" : \"0\" , \"statistics_in-fcs-error-packets\" : \"0\" , \"statistics_in-multicast-packets\" : \"288033\" , \"statistics_in-octets\" : \"65382630\" , \"statistics_in-unicast-packets\" : \"107154\" , \"statistics_out-broadcast-packets\" : \"614\" , \"statistics_out-error-packets\" : \"0\" , \"statistics_out-multicast-packets\" : \"11\" , \"statistics_out-octets\" : \"64721394\" , \"statistics_out-unicast-packets\" : \"105876\" } }","title":"split"},{"location":"user_guide/event_processors/event_strings/#multiple-transforms","text":"processors : # processor name sample-processor : # processor type event-strings : value-names : - \".*\" transforms : # strings function name - path-base : apply-on : \"name\" - title : apply-on : \"name\" - replace : apply-on : \"name\" old : \"-\" new : \"_\" Event format before { \"name\" : \"default\" , \"timestamp\" : 1607291271894072397 , \"tags\" : { \"interface_name\" : \"mgmt0\" , \"source\" : \"172.23.23.2:57400\" , \"subscription-name\" : \"default\" }, \"values\" : { \"/srl_nokia-interfaces:interface/statistics/carrier-transitions\" : \"1\" , \"/srl_nokia-interfaces:interface/statistics/in-broadcast-packets\" : \"3797\" , \"/srl_nokia-interfaces:interface/statistics/in-error-packets\" : \"0\" , \"/srl_nokia-interfaces:interface/statistics/in-fcs-error-packets\" : \"0\" , \"/srl_nokia-interfaces:interface/statistics/in-multicast-packets\" : \"288033\" , \"/srl_nokia-interfaces:interface/statistics/in-octets\" : \"65382630\" , \"/srl_nokia-interfaces:interface/statistics/in-unicast-packets\" : \"107154\" , \"/srl_nokia-interfaces:interface/statistics/out-broadcast-packets\" : \"614\" , \"/srl_nokia-interfaces:interface/statistics/out-error-packets\" : \"0\" , \"/srl_nokia-interfaces:interface/statistics/out-multicast-packets\" : \"11\" , \"/srl_nokia-interfaces:interface/statistics/out-octets\" : \"64721394\" , \"/srl_nokia-interfaces:interface/statistics/out-unicast-packets\" : \"105876\" } } Event format after { \"name\" : \"default\" , \"timestamp\" : 1607291271894072397 , \"tags\" : { \"interface_name\" : \"mgmt0\" , \"source\" : \"172.23.23.2:57400\" , \"subscription-name\" : \"default\" }, \"values\" : { \"Carrier_transitions\" : \"1\" , \"In_broadcast_packets\" : \"3797\" , \"In_error_packets\" : \"0\" , \"In_fcs_error_packets\" : \"0\" , \"In_multicast_packets\" : \"288033\" , \"In_octets\" : \"65382630\" , \"In_unicast_packets\" : \"107154\" , \"Out_broadcast_packets\" : \"614\" , \"Out_error_packets\" : \"0\" , \"Out_multicast_packets\" : \"11\" , \"Out_octets\" : \"64721394\" , \"Out_unicast_packets\" : \"105876\" } }","title":"multiple transforms"},{"location":"user_guide/event_processors/event_to_tag/","text":"The event-to-tag processor, moves a value matching one of the regular expressions from the values section to the tags section. It's possible to keep the value under values section after moving it. Examples # processors : # processor name sample-processor : # processor type event-to-tag : value-names : - \".*-state$\" Event format before { \"name\" : \"default\" , \"timestamp\" : 1607305284170936330 , \"tags\" : { \"interface_name\" : \"ethernet-1/1\" , \"source\" : \"172.23.23.2:57400\" , \"subscription-name\" : \"default\" }, \"values\" : { \"/srl_nokia-interfaces:interface/admin-state\" : \"disable\" , \"/srl_nokia-interfaces:interface/ifindex\" : 54 , \"/srl_nokia-interfaces:interface/last-change\" : \"2020-11-20T05:52:21.459Z\" , \"/srl_nokia-interfaces:interface/oper-down-reason\" : \"port-admin-disabled\" , \"/srl_nokia-interfaces:interface/oper-state\" : \"down\" } } Event format after { \"name\" : \"default\" , \"timestamp\" : 1607305284170936330 , \"tags\" : { \"interface_name\" : \"ethernet-1/1\" , \"source\" : \"172.23.23.2:57400\" , \"subscription-name\" : \"default\" , \"/srl_nokia-interfaces:interface/admin-state\" : \"disable\" , \"/srl_nokia-interfaces:interface/oper-state\" : \"down\" }, \"values\" : { \"/srl_nokia-interfaces:interface/ifindex\" : 54 , \"/srl_nokia-interfaces:interface/last-change\" : \"2020-11-20T05:52:21.459Z\" , \"/srl_nokia-interfaces:interface/oper-down-reason\" : \"port-admin-disabled\" } }","title":"To Tag"},{"location":"user_guide/event_processors/event_to_tag/#examples","text":"processors : # processor name sample-processor : # processor type event-to-tag : value-names : - \".*-state$\" Event format before { \"name\" : \"default\" , \"timestamp\" : 1607305284170936330 , \"tags\" : { \"interface_name\" : \"ethernet-1/1\" , \"source\" : \"172.23.23.2:57400\" , \"subscription-name\" : \"default\" }, \"values\" : { \"/srl_nokia-interfaces:interface/admin-state\" : \"disable\" , \"/srl_nokia-interfaces:interface/ifindex\" : 54 , \"/srl_nokia-interfaces:interface/last-change\" : \"2020-11-20T05:52:21.459Z\" , \"/srl_nokia-interfaces:interface/oper-down-reason\" : \"port-admin-disabled\" , \"/srl_nokia-interfaces:interface/oper-state\" : \"down\" } } Event format after { \"name\" : \"default\" , \"timestamp\" : 1607305284170936330 , \"tags\" : { \"interface_name\" : \"ethernet-1/1\" , \"source\" : \"172.23.23.2:57400\" , \"subscription-name\" : \"default\" , \"/srl_nokia-interfaces:interface/admin-state\" : \"disable\" , \"/srl_nokia-interfaces:interface/oper-state\" : \"down\" }, \"values\" : { \"/srl_nokia-interfaces:interface/ifindex\" : 54 , \"/srl_nokia-interfaces:interface/last-change\" : \"2020-11-20T05:52:21.459Z\" , \"/srl_nokia-interfaces:interface/oper-down-reason\" : \"port-admin-disabled\" } }","title":"Examples"},{"location":"user_guide/event_processors/event_trigger/","text":"The event-trigger processor takes event messages as input and triggers a list of actions (sequentially) if a configured condition evaluates to true . The condition is evaluated using the the Golang implementation of jq with the event message as a json input. jq tutorial jq manual jq playground Examples of conditions: The below expression checks if the value named counter1 has a value higher than 90 .values [ \"counter1\" ] > 90 This expression checks if the event name is sub1 , that the tag source is equal to r1:57400 .name == \"sub1\" and .tags [ \"source\" ] == \"r1:57400\" The trigger can be monitored over a configurable window of time (default 1 minute), during which only a certain number of occurrences (default 1) trigger the actions execution. The action types availabe can be found here processors : # processor name my_trigger_proc : # # processor type event-trigger : # trigger condition condition : '.values[\"counter1\"] > 90' # minimum number of condition occurrences within the configured window # required to trigger the action min-occurrences : 1 # max number of times the action is triggered within the configured window max-occurrences : 1 # window of time during which max-occurrences need to # be reached in order to trigger the action window : 60s # async, bool. default false. # If true the trigger is executed in the background and the triggering # message is passed to the next procesor. Otherwise it blocks until the trigger returns async : false # a dictionary of variables that is passed to the actions # and can be accessed in the actions templates using `.Vars` vars : # path to a file containing variables passed to the actions # the variable in the `vars` field override the ones read from the file. vars-file : # list of actions to be executed actions : - counter_alert Examples # Alerting when a threshold is crossed # The below example triggers an HTTP GET to http://remote-server:p8080/${router_name} if the value of counter \"counter1\" crosses 90 twice within 2 minutes. processors : my_trigger_proc : event-trigger : condition : '.values[\"counter1\"] > 90' min-occurrences : 1 max-occurrences : 2 window : 120s async : true actions : - alert actions : alert : name : alert type : http method : POST url : http://remote-server:8080/{{ index .Tags \"source\" }} headers : content-type : application/text timeout : 5s body : '\"counter1\" crossed threshold, value={{ index .Values \"counter1\" }}' Enabling backup interface # The below example shows a trigger that enables a router interface if another interface's operational status changes to \"down\". processors : interface_watch : # event-trigger : debug : true condition : '(.tags.interface_name == \"ethernet-1/1\" or .tags.interface_name == \"ethernet-1/2\") and .values[\"/srl_nokia-interfaces:interface/oper-state\"] == \"down\"' actions : - enable_interface actions : enable_interface : name : my_gnmi_action type : gnmi rpc : set target : '{{ index .Event.Tags \"source\" }}' paths : - | {{ $interfaceName := \"\" }} {{ if eq ( index .Event.Tags \"interface_name\" ) \"ethernet-1/1\"}} {{$interfaceName = \"ethernet-1/2\"}} {{ else if eq ( index E.vent.Tags \"interface_name\" ) \"ethernet-1/2\"}} {{$interfaceName = \"ethernet-1/1\"}} {{end}} /interface[name={{$interfaceName}}]/admin-state values : - \"enable\" encoding : json_ietf debug : true Clone a network topology and deploy it using containerlab # Using lldp neighbor information it's possible to build a containerlab topology using gnmic actions. In the below configuration file, an event processor called clone-topology is defined. When triggered it runs a series of actions to gather information (chassis type, lldp neighbors, configuration,...) from the defined targets. It then builds a containerlab topology from a defined template and the gathered info, writes it to a file and runs a clab deploy command. username : admin password : admin skip-verify : true encoding : json_ietf # log: true targets : srl1 : srl2 : srl3 : processors : clone-topology : event-trigger : # debug: true actions : - chassis - lldp - read_config - write_config - clab_topo - deploy_topo actions : chassis : name : chassis type : gnmi target : all rpc : sub encoding : json_ietf #debug: true format : event paths : - /platform/chassis/type lldp : name : lldp type : gnmi target : all rpc : sub encoding : json_ietf #debug: true format : event paths : - /system/lldp/interface[name=ethernet-*] read_config : name : read_config type : gnmi target : all rpc : get data-type : config encoding : json_ietf #debug: true paths : - / write_config : name : write_config type : template template : | {{- range $n, $m := .Env.read_config }} {{- $filename := print $n \".json\"}} {{ file.Write $filename (index $m 0 \"updates\" 0 \"values\" \"\" | data.ToJSONPretty \" \" ) }} {{- end }} #debug: true clab_topo : name : clab_topo type : template # debug: true output : gnmic.clab.yaml template : | name: gNMIc-action-generated topology: defaults: kind: srl kinds: srl: image: ghcr.io/nokia/srlinux:latest nodes: {{- range $n, $m := .Env.lldp }} {{- $type := index $.Env.chassis $n 0 0 \"values\" \"/srl_nokia-platform:platform/srl_nokia-platform-chassis:chassis/type\" }} {{- $type = $type | strings.ReplaceAll \"7220 IXR-D1\" \"ixrd1\" }} {{- $type = $type | strings.ReplaceAll \"7220 IXR-D2\" \"ixrd2\" }} {{- $type = $type | strings.ReplaceAll \"7220 IXR-D3\" \"ixrd3\" }} {{- $type = $type | strings.ReplaceAll \"7250 IXR-6\" \"ixr6\" }} {{- $type = $type | strings.ReplaceAll \"7250 IXR-10\" \"ixr10\" }} {{- $type = $type | strings.ReplaceAll \"7220 IXR-H1\" \"ixrh1\" }} {{- $type = $type | strings.ReplaceAll \"7220 IXR-H2\" \"ixrh2\" }} {{- $type = $type | strings.ReplaceAll \"7220 IXR-H3\" \"ixrh3\" }} {{ $n | strings.TrimPrefix \"clab-\" }}: type: {{ $type }} startup-config: {{ print $n \".json\"}} {{- end }} links: {{- range $n, $m := .Env.lldp }} {{- range $rsp := $m }} {{- range $ev := $rsp }} {{- if index $ev.values \"/srl_nokia-system:system/srl_nokia-lldp:lldp/interface/neighbor/system-name\" }} {{- $node1 := $ev.tags.source | strings.TrimPrefix \"clab-\" }} {{- $iface1 := $ev.tags.interface_name | strings.ReplaceAll \"ethernet-\" \"e\" | strings.ReplaceAll \"/\" \"-\" }} {{- $node2 := index $ev.values \"/srl_nokia-system:system/srl_nokia-lldp:lldp/interface/neighbor/system-name\" }} {{- $iface2 := index $ev.values \"/srl_nokia-system:system/srl_nokia-lldp:lldp/interface/neighbor/port-id\" | strings.ReplaceAll \"ethernet-\" \"e\" | strings.ReplaceAll \"/\" \"-\" }} {{- if lt $node1 $node2 }} - endpoints: [\"{{ $node1 }}:{{ $iface1 }}\", \"{{ $node2 }}:{{ $iface2 }}\"] {{- end }} {{- end }} {{- end }} {{- end }} {{- end }} deploy_topo : name : deploy_topo type : script command : sudo clab dep -t gnmic.clab.yaml --reconfigure debug : true The above described processor can be triggered with the below command: gnmic --config clone.yaml get --path /system/name --processor clone-topology","title":"Trigger"},{"location":"user_guide/event_processors/event_trigger/#examples","text":"","title":"Examples"},{"location":"user_guide/event_processors/event_trigger/#alerting-when-a-threshold-is-crossed","text":"The below example triggers an HTTP GET to http://remote-server:p8080/${router_name} if the value of counter \"counter1\" crosses 90 twice within 2 minutes. processors : my_trigger_proc : event-trigger : condition : '.values[\"counter1\"] > 90' min-occurrences : 1 max-occurrences : 2 window : 120s async : true actions : - alert actions : alert : name : alert type : http method : POST url : http://remote-server:8080/{{ index .Tags \"source\" }} headers : content-type : application/text timeout : 5s body : '\"counter1\" crossed threshold, value={{ index .Values \"counter1\" }}'","title":"Alerting when a threshold is crossed"},{"location":"user_guide/event_processors/event_trigger/#enabling-backup-interface","text":"The below example shows a trigger that enables a router interface if another interface's operational status changes to \"down\". processors : interface_watch : # event-trigger : debug : true condition : '(.tags.interface_name == \"ethernet-1/1\" or .tags.interface_name == \"ethernet-1/2\") and .values[\"/srl_nokia-interfaces:interface/oper-state\"] == \"down\"' actions : - enable_interface actions : enable_interface : name : my_gnmi_action type : gnmi rpc : set target : '{{ index .Event.Tags \"source\" }}' paths : - | {{ $interfaceName := \"\" }} {{ if eq ( index .Event.Tags \"interface_name\" ) \"ethernet-1/1\"}} {{$interfaceName = \"ethernet-1/2\"}} {{ else if eq ( index E.vent.Tags \"interface_name\" ) \"ethernet-1/2\"}} {{$interfaceName = \"ethernet-1/1\"}} {{end}} /interface[name={{$interfaceName}}]/admin-state values : - \"enable\" encoding : json_ietf debug : true","title":"Enabling backup interface"},{"location":"user_guide/event_processors/event_trigger/#clone-a-network-topology-and-deploy-it-using-containerlab","text":"Using lldp neighbor information it's possible to build a containerlab topology using gnmic actions. In the below configuration file, an event processor called clone-topology is defined. When triggered it runs a series of actions to gather information (chassis type, lldp neighbors, configuration,...) from the defined targets. It then builds a containerlab topology from a defined template and the gathered info, writes it to a file and runs a clab deploy command. username : admin password : admin skip-verify : true encoding : json_ietf # log: true targets : srl1 : srl2 : srl3 : processors : clone-topology : event-trigger : # debug: true actions : - chassis - lldp - read_config - write_config - clab_topo - deploy_topo actions : chassis : name : chassis type : gnmi target : all rpc : sub encoding : json_ietf #debug: true format : event paths : - /platform/chassis/type lldp : name : lldp type : gnmi target : all rpc : sub encoding : json_ietf #debug: true format : event paths : - /system/lldp/interface[name=ethernet-*] read_config : name : read_config type : gnmi target : all rpc : get data-type : config encoding : json_ietf #debug: true paths : - / write_config : name : write_config type : template template : | {{- range $n, $m := .Env.read_config }} {{- $filename := print $n \".json\"}} {{ file.Write $filename (index $m 0 \"updates\" 0 \"values\" \"\" | data.ToJSONPretty \" \" ) }} {{- end }} #debug: true clab_topo : name : clab_topo type : template # debug: true output : gnmic.clab.yaml template : | name: gNMIc-action-generated topology: defaults: kind: srl kinds: srl: image: ghcr.io/nokia/srlinux:latest nodes: {{- range $n, $m := .Env.lldp }} {{- $type := index $.Env.chassis $n 0 0 \"values\" \"/srl_nokia-platform:platform/srl_nokia-platform-chassis:chassis/type\" }} {{- $type = $type | strings.ReplaceAll \"7220 IXR-D1\" \"ixrd1\" }} {{- $type = $type | strings.ReplaceAll \"7220 IXR-D2\" \"ixrd2\" }} {{- $type = $type | strings.ReplaceAll \"7220 IXR-D3\" \"ixrd3\" }} {{- $type = $type | strings.ReplaceAll \"7250 IXR-6\" \"ixr6\" }} {{- $type = $type | strings.ReplaceAll \"7250 IXR-10\" \"ixr10\" }} {{- $type = $type | strings.ReplaceAll \"7220 IXR-H1\" \"ixrh1\" }} {{- $type = $type | strings.ReplaceAll \"7220 IXR-H2\" \"ixrh2\" }} {{- $type = $type | strings.ReplaceAll \"7220 IXR-H3\" \"ixrh3\" }} {{ $n | strings.TrimPrefix \"clab-\" }}: type: {{ $type }} startup-config: {{ print $n \".json\"}} {{- end }} links: {{- range $n, $m := .Env.lldp }} {{- range $rsp := $m }} {{- range $ev := $rsp }} {{- if index $ev.values \"/srl_nokia-system:system/srl_nokia-lldp:lldp/interface/neighbor/system-name\" }} {{- $node1 := $ev.tags.source | strings.TrimPrefix \"clab-\" }} {{- $iface1 := $ev.tags.interface_name | strings.ReplaceAll \"ethernet-\" \"e\" | strings.ReplaceAll \"/\" \"-\" }} {{- $node2 := index $ev.values \"/srl_nokia-system:system/srl_nokia-lldp:lldp/interface/neighbor/system-name\" }} {{- $iface2 := index $ev.values \"/srl_nokia-system:system/srl_nokia-lldp:lldp/interface/neighbor/port-id\" | strings.ReplaceAll \"ethernet-\" \"e\" | strings.ReplaceAll \"/\" \"-\" }} {{- if lt $node1 $node2 }} - endpoints: [\"{{ $node1 }}:{{ $iface1 }}\", \"{{ $node2 }}:{{ $iface2 }}\"] {{- end }} {{- end }} {{- end }} {{- end }} {{- end }} deploy_topo : name : deploy_topo type : script command : sudo clab dep -t gnmic.clab.yaml --reconfigure debug : true The above described processor can be triggered with the below command: gnmic --config clone.yaml get --path /system/name --processor clone-topology","title":"Clone a network topology and deploy it using containerlab"},{"location":"user_guide/event_processors/event_value_tag/","text":"The event-value-tag processor applies specific values from event messages to tags of other messages, if event tag names match. Each gNMI subscribe Response Update in a gNMI subscribe Response Notification is transformed into an Event Message Additionally, if you are using an output cache, all gNMI subscribe Response Update messages are converted to Events on flush. The event-value-tag processor is used to extract Values as tags to apply to other Events that have the same K:V tag pairs from the original event message, without merging events with different timestamps. processors : # processor name intf-description : # processor-type event-value-tag : # name of the value to match. Usually a specific gNMI path value-name : \"/interfaces/interface/state/description\" # if set, use instead of the value name for tag tag-name : \"description\" # if true, remove value from original event when copying consume : false debug : false Event format before [ { \"name\" : \"sub1\" , \"timestamp\" : 1 , \"tags\" : { \"source\" : \"leaf1:6030\" , \"subscription-name\" : \"sub1\" , \"interface_name\" : \"Ethernet1\" }, \"values\" : { \"/interfaces/interface/status/counters/in-octets\" : 100 } }, { \"name\" : \"sub1\" , \"timestamp\" : 200 , \"tags\" : { \"source\" : \"leaf1:6030\" , \"subscription-name\" : \"sub1\" , \"interface_name\" : \"Ethernet1\" }, \"values\" : { \"/interfaces/interface/status/counters/out-octets\" : 100 } }, { \"name\" : \"sub1\" , \"timestamp\" : 200 , \"tags\" : { \"source\" : \"leaf1:6030\" , \"subscription-name\" : \"sub1\" , \"interface_name\" : \"Ethernet1\" }, \"values\" : { \"/interfaces/interface/status/description\" : \"Uplink\" } } ] Event format after [ { \"name\" : \"sub1\" , \"timestamp\" : 1 , \"tags\" : { \"source\" : \"leaf1:6030\" , \"subscription-name\" : \"sub1\" , \"interface_name\" : \"Ethernet1\" , \"description\" : \"Uplink\" }, \"values\" : { \"/interfaces/interface/status/counters/in-octets\" : 100 } }, { \"name\" : \"sub1\" , \"timestamp\" : 200 , \"tags\" : { \"source\" : \"leaf1:6030\" , \"subscription-name\" : \"sub1\" , \"interface_name\" : \"Ethernet1\" , \"description\" : \"Uplink\" }, \"values\" : { \"/interfaces/interface/status/counters/out-octets\" : 100 } }, { \"name\" : \"sub1\" , \"timestamp\" : 200 , \"tags\" : { \"source\" : \"leaf1:6030\" , \"subscription-name\" : \"sub1\" , \"interface_name\" : \"Ethernet1\" }, \"values\" : { \"/interfaces/interface/status/description\" : \"Uplink\" } } ] bgp-description : event-value-tag : value-name : \"neighbor_description\" consume : true Event format before [ { \"name\" : \"sub2\" , \"timestamp\" : 1615284691523204299 , \"tags\" : { \"neighbor_peer-address\" : \"2002::1:1:1:1\" , \"network-instance_name\" : \"default\" , \"source\" : \"leaf1:57400\" , \"subscription-name\" : \"sub2\" }, \"values\" : { \"bgp_neighbor_sent_messages_queue_depth\" : 0 , \"bgp_neighbor_sent_messages_total_messages\" : \"423\" , \"bgp_neighbor_sent_messages_total_non_updates\" : \"415\" , \"bgp_neighbor_sent_messages_total_updates\" : \"8\" } }, { \"name\" : \"sub2\" , \"timestamp\" : 1615284691523204299 , \"tags\" : { \"neighbor_peer-address\" : \"2002::1:1:1:1\" , \"network-instance_name\" : \"default\" , \"source\" : \"leaf1:57400\" , \"subscription-name\" : \"sub2\" }, \"values\" : { \"neighbor_description\" : \"PeerRouter\" } } ] Event format after [ { \"name\" : \"sub2\" , \"timestamp\" : 1615284691523204299 , \"tags\" : { \"neighbor_peer-address\" : \"2002::1:1:1:1\" , \"network-instance_name\" : \"default\" , \"source\" : \"leaf1:57400\" , \"subscription-name\" : \"sub2\" \"neighbor_description\" : \"PeerRouter\" }, \"values\" : { \"bgp_neighbor_sent_messages_queue_depth\" : 0 , \"bgp_neighbor_sent_messages_total_messages\" : \"423\" , \"bgp_neighbor_sent_messages_total_non_updates\" : \"415\" , \"bgp_neighbor_sent_messages_total_updates\" : \"8\" , } }, { \"name\" : \"sub2\" , \"timestamp\" : 1615284691523204299 , \"tags\" : { \"neighbor_peer-address\" : \"2002::1:1:1:1\" , \"network-instance_name\" : \"default\" , \"source\" : \"leaf1:57400\" , \"subscription-name\" : \"sub2\" }, \"values\" : {} } ]","title":"Value Tag"},{"location":"user_guide/event_processors/event_write/","text":"The event-write processor, writes a message that has a value or a tag matching one of the configured regular expressions to stdout , stderr or to a file. A custom separator (used between written messages) can be configured, it defaults to \\n processors : # processor name write-processor : # processor type event-write : # jq expression, if evaluated to true, the message is written to dst condition : # list of regular expressions to be matched against the tags names, if matched, the message is written to dst tag-names : # list of regular expressions to be matched against the tags values, if matched, the message is written to dst tags : # list of regular expressions to be matched against the values names, if matched, the message is written to dst value-names : # list of regular expressions to be matched against the values, if matched, the message is written to dst values : # path to the destination file dst : # separator to be written between messages separator : # indent to use when marshaling the event message to json indent : Examples # processors : # processor name write-processor : # processor type event-write : value-names : - \".\" dst : file.log separator : \"\\n####\\n\" indent : \" \" $ cat file.log { \"name\" : \"sub1\" , \"timestamp\" : 1607582483868459381 , \"tags\" : { \"interface_name\" : \"ethernet-1/1\" , \"source\" : \"172.20.20.5:57400\" , \"subscription-name\" : \"sub1\" } , \"values\" : { \"/srl_nokia-interfaces:interface/statistics/carrier-transitions\" : \"1\" , \"/srl_nokia-interfaces:interface/statistics/in-broadcast-packets\" : \"22\" , \"/srl_nokia-interfaces:interface/statistics/in-error-packets\" : \"0\" , \"/srl_nokia-interfaces:interface/statistics/in-fcs-error-packets\" : \"0\" , \"/srl_nokia-interfaces:interface/statistics/in-multicast-packets\" : \"8694\" , \"/srl_nokia-interfaces:interface/statistics/in-octets\" : \"1740350\" , \"/srl_nokia-interfaces:interface/statistics/in-unicast-packets\" : \"17\" , \"/srl_nokia-interfaces:interface/statistics/out-broadcast-packets\" : \"22\" , \"/srl_nokia-interfaces:interface/statistics/out-error-packets\" : \"0\" , \"/srl_nokia-interfaces:interface/statistics/out-multicast-packets\" : \"8696\" , \"/srl_nokia-interfaces:interface/statistics/out-octets\" : \"1723262\" , \"/srl_nokia-interfaces:interface/statistics/out-unicast-packets\" : \"17\" } } #### { \"name\" : \"sub1\" , \"timestamp\" : 1607582483868459381 , \"tags\" : { \"interface_name\" : \"ethernet-1/1\" , \"source\" : \"172.20.20.5:57400\" , \"subscription-name\" : \"sub1\" } , \"values\" : { \"/srl_nokia-interfaces:interface/statistics/carrier-transitions\" : \"1\" , \"/srl_nokia-interfaces:interface/statistics/in-broadcast-packets\" : \"22\" , \"/srl_nokia-interfaces:interface/statistics/in-error-packets\" : \"0\" , \"/srl_nokia-interfaces:interface/statistics/in-fcs-error-packets\" : \"0\" , \"/srl_nokia-interfaces:interface/statistics/in-multicast-packets\" : \"8694\" , \"/srl_nokia-interfaces:interface/statistics/in-octets\" : \"1740350\" , \"/srl_nokia-interfaces:interface/statistics/in-unicast-packets\" : \"17\" , \"/srl_nokia-interfaces:interface/statistics/out-broadcast-packets\" : \"22\" , \"/srl_nokia-interfaces:interface/statistics/out-error-packets\" : \"0\" , \"/srl_nokia-interfaces:interface/statistics/out-multicast-packets\" : \"8696\" , \"/srl_nokia-interfaces:interface/statistics/out-octets\" : \"1723262\" , \"/srl_nokia-interfaces:interface/statistics/out-unicast-packets\" : \"17\" } } ####","title":"Write"},{"location":"user_guide/event_processors/event_write/#examples","text":"processors : # processor name write-processor : # processor type event-write : value-names : - \".\" dst : file.log separator : \"\\n####\\n\" indent : \" \" $ cat file.log { \"name\" : \"sub1\" , \"timestamp\" : 1607582483868459381 , \"tags\" : { \"interface_name\" : \"ethernet-1/1\" , \"source\" : \"172.20.20.5:57400\" , \"subscription-name\" : \"sub1\" } , \"values\" : { \"/srl_nokia-interfaces:interface/statistics/carrier-transitions\" : \"1\" , \"/srl_nokia-interfaces:interface/statistics/in-broadcast-packets\" : \"22\" , \"/srl_nokia-interfaces:interface/statistics/in-error-packets\" : \"0\" , \"/srl_nokia-interfaces:interface/statistics/in-fcs-error-packets\" : \"0\" , \"/srl_nokia-interfaces:interface/statistics/in-multicast-packets\" : \"8694\" , \"/srl_nokia-interfaces:interface/statistics/in-octets\" : \"1740350\" , \"/srl_nokia-interfaces:interface/statistics/in-unicast-packets\" : \"17\" , \"/srl_nokia-interfaces:interface/statistics/out-broadcast-packets\" : \"22\" , \"/srl_nokia-interfaces:interface/statistics/out-error-packets\" : \"0\" , \"/srl_nokia-interfaces:interface/statistics/out-multicast-packets\" : \"8696\" , \"/srl_nokia-interfaces:interface/statistics/out-octets\" : \"1723262\" , \"/srl_nokia-interfaces:interface/statistics/out-unicast-packets\" : \"17\" } } #### { \"name\" : \"sub1\" , \"timestamp\" : 1607582483868459381 , \"tags\" : { \"interface_name\" : \"ethernet-1/1\" , \"source\" : \"172.20.20.5:57400\" , \"subscription-name\" : \"sub1\" } , \"values\" : { \"/srl_nokia-interfaces:interface/statistics/carrier-transitions\" : \"1\" , \"/srl_nokia-interfaces:interface/statistics/in-broadcast-packets\" : \"22\" , \"/srl_nokia-interfaces:interface/statistics/in-error-packets\" : \"0\" , \"/srl_nokia-interfaces:interface/statistics/in-fcs-error-packets\" : \"0\" , \"/srl_nokia-interfaces:interface/statistics/in-multicast-packets\" : \"8694\" , \"/srl_nokia-interfaces:interface/statistics/in-octets\" : \"1740350\" , \"/srl_nokia-interfaces:interface/statistics/in-unicast-packets\" : \"17\" , \"/srl_nokia-interfaces:interface/statistics/out-broadcast-packets\" : \"22\" , \"/srl_nokia-interfaces:interface/statistics/out-error-packets\" : \"0\" , \"/srl_nokia-interfaces:interface/statistics/out-multicast-packets\" : \"8696\" , \"/srl_nokia-interfaces:interface/statistics/out-octets\" : \"1723262\" , \"/srl_nokia-interfaces:interface/statistics/out-unicast-packets\" : \"17\" } } ####","title":"Examples"},{"location":"user_guide/event_processors/intro/","text":"The event processors provide an easy way to configure a set of functions in order to transform an event message that will be be written to a specific output. While the event format is the de facto format used by gNMIc in case the output is influxdb or prometheus , it can be used with any other output type. Transforming the received gNMI message is sometimes needed to accomodate the output system ( converting types, complying with name constraints,...), or simply filtering out values that you are not interested on. The event format # The event format is produced by gNMIc from the gNMI Notification messages received within a gNMI subscribe response update, it contains 5 fields: name : A string field populated by the subscription name, it is used as the measurement name in case of influxdb output or as a part of the metric name in case of prometheus output. timestamp : An int64 field containing the timestamp received within the gnmi Update. tags : A map of string keys and string values. The keys and values are extracted from the keys in the gNMI PathElement keys. gNMIc adds the subscription name and the target name/address. values : A map of string keys and generic values. The keys are build from a xpath representation of the gNMI path without the keys, while the values are extracted from the gNMI Node values . deletes : A string list built from the delete field of the gNMI Notification message . Defining an event processor # Event processors are defined under the section processors in gNMIc configuration file. Each processor is identified by a name, under which we specify the processor type as well as additional fields specific to each type. Note Processors names are case insensitive All processors support a debug field that enables extra debug log messages to help troubleshoot the processor transformation. Below is an example of an event-delete processor, which deletes all values with a name containing multicast or broadcast processors : # processor name my-processor : # processor type event-delete : value-names : - \".*multicast.*\" - \".*broadcast.*\" Linking an event processor to an output # Once the needed event processors are defined under section processors , they can be linked to the desired output(s) in the same file. Each output can be configured with different event processors allowing flexibility in the way the same data is written to different outputs. A list of event processors names can be added under an output configuration, the processors will apply in the order they are configured. In the below example, 3 event processors are configured and linked to output1 of type influxdb . The first processor converts all value to integer if possible. The second deletes tags with name starting with subscription-name . Finally the third deletes values with name ending with out-unicast-packets . outputs : output1 : type : influxdb url : http://localhost:8086 bucket : telemetry token : srl:srl batch-size : 1000 flush-timer : 10s event-processors : - proc-convert-integer - proc-delete-tag-name - proc-delete-value-name processors : proc-convert-integer : event-convert : value-names : - \".*\" type : int proc-delete-tag-name : event-delete : tag-names : - \"^subscription-name\" proc-delete-value-name : event-delete : value-names : - \".*out-unicast-packets\"","title":"Introduction"},{"location":"user_guide/event_processors/intro/#the-event-format","text":"The event format is produced by gNMIc from the gNMI Notification messages received within a gNMI subscribe response update, it contains 5 fields: name : A string field populated by the subscription name, it is used as the measurement name in case of influxdb output or as a part of the metric name in case of prometheus output. timestamp : An int64 field containing the timestamp received within the gnmi Update. tags : A map of string keys and string values. The keys and values are extracted from the keys in the gNMI PathElement keys. gNMIc adds the subscription name and the target name/address. values : A map of string keys and generic values. The keys are build from a xpath representation of the gNMI path without the keys, while the values are extracted from the gNMI Node values . deletes : A string list built from the delete field of the gNMI Notification message .","title":"The event format"},{"location":"user_guide/event_processors/intro/#defining-an-event-processor","text":"Event processors are defined under the section processors in gNMIc configuration file. Each processor is identified by a name, under which we specify the processor type as well as additional fields specific to each type. Note Processors names are case insensitive All processors support a debug field that enables extra debug log messages to help troubleshoot the processor transformation. Below is an example of an event-delete processor, which deletes all values with a name containing multicast or broadcast processors : # processor name my-processor : # processor type event-delete : value-names : - \".*multicast.*\" - \".*broadcast.*\"","title":"Defining an event processor"},{"location":"user_guide/event_processors/intro/#linking-an-event-processor-to-an-output","text":"Once the needed event processors are defined under section processors , they can be linked to the desired output(s) in the same file. Each output can be configured with different event processors allowing flexibility in the way the same data is written to different outputs. A list of event processors names can be added under an output configuration, the processors will apply in the order they are configured. In the below example, 3 event processors are configured and linked to output1 of type influxdb . The first processor converts all value to integer if possible. The second deletes tags with name starting with subscription-name . Finally the third deletes values with name ending with out-unicast-packets . outputs : output1 : type : influxdb url : http://localhost:8086 bucket : telemetry token : srl:srl batch-size : 1000 flush-timer : 10s event-processors : - proc-convert-integer - proc-delete-tag-name - proc-delete-value-name processors : proc-convert-integer : event-convert : value-names : - \".*\" type : int proc-delete-tag-name : event-delete : tag-names : - \"^subscription-name\" proc-delete-value-name : event-delete : value-names : - \".*out-unicast-packets\"","title":"Linking an event processor to an output"},{"location":"user_guide/golang_package/gnmi_options/","text":"The package github.com/karimra/gnmic/api exposes a set of api.GNMIOption that can be used with api.NewGetRequest(...api.GNMIOption) GNMIOption , api.NewSetRequest(...api.GNMIOption) GNMIOption or api.NewSubscribeRequest(...api.GNMIOption) GNMIOption to create a gNMI Request. // Version sets the provided gNMI version string in a gnmi.CapabilityResponse message. func Version ( v string ) func ( msg proto . Message ) error // SupportedEncoding creates an GNMIOption that sets the provided encodings as supported encodings in a gnmi.CapabilitiesResponse func SupportedEncoding ( encodings ... string ) func ( msg proto . Message ) error // SupportedModel creates an GNMIOption that sets the provided name, org and version as a supported model in a gnmi.CapabilitiesResponse. func SupportedModel ( name , org , version string ) func ( msg proto . Message ) error // Extension creates a GNMIOption that applies the supplied gnmi_ext.Extension to the provided // proto.Message. func Extension ( ext * gnmi_ext . Extension ) func ( msg proto . Message ) error // Prefix creates a GNMIOption that creates a *gnmi.Path and adds it to the supplied // proto.Message (as a Path Prefix). // The proto.Message can be a *gnmi.GetRequest, *gnmi.SetRequest or a *gnmi.SubscribeRequest with RequestType Subscribe. func Prefix ( prefix string ) func ( msg proto . Message ) error // Target creates a GNMIOption that set the gnmi Prefix target to the supplied string value. // The proto.Message can be a *gnmi.GetRequest, *gnmi.SetRequest or a *gnmi.SubscribeRequest with RequestType Subscribe. func Target ( target string ) func ( msg proto . Message ) error // Path creates a GNMIOption that creates a *gnmi.Path and adds it to the supplied proto.Message // which can be a *gnmi.GetRequest, *gnmi.SetRequest or a *gnmi.Subscription. func Path ( path string ) func ( msg proto . Message ) error // Encoding creates a GNMIOption that adds the encoding type to the supplied proto.Message // which can be a *gnmi.GetRequest, *gnmi.SetRequest or a *gnmi.SubscribeRequest with RequestType Subscribe. func Encoding ( encoding string ) func ( msg proto . Message ) error // EncodingJSON creates a GNMIOption that sets the encoding type to JSON in a gnmi.GetRequest or // gnmi.SubscribeRequest. func EncodingJSON () func ( msg proto . Message ) error // EncodingBytes creates a GNMIOption that sets the encoding type to BYTES in a gnmi.GetRequest or // gnmi.SubscribeRequest. func EncodingBytes () func ( msg proto . Message ) error // EncodingPROTO creates a GNMIOption that sets the encoding type to PROTO in a gnmi.GetRequest or // gnmi.SubscribeRequest. func EncodingPROTO () func ( msg proto . Message ) error // EncodingASCII creates a GNMIOption that sets the encoding type to ASCII in a gnmi.GetRequest or // gnmi.SubscribeRequest. func EncodingASCII () func ( msg proto . Message ) error // EncodingJSON_IETF creates a GNMIOption that sets the encoding type to JSON_IETF in a gnmi.GetRequest or // gnmi.SubscribeRequest. func EncodingJSON_IETF () func ( msg proto . Message ) error // EncodingCustom creates a GNMIOption that adds the encoding type to the supplied proto.Message // which can be a *gnmi.GetRequest, *gnmi.SetRequest or a *gnmi.SubscribeRequest with RequestType Subscribe. // Unlike Encoding, this GNMIOption does not validate if the provided encoding is defined by the gNMI spec. func EncodingCustom ( enc int ) func ( msg proto . Message ) error // DataType creates a GNMIOption that adds the data type to the supplied proto.Message // which must be a *gnmi.GetRequest. func DataType ( datat string ) func ( msg proto . Message ) error // DataTypeALL creates a GNMIOption that sets the gnmi.GetRequest data type to ALL func DataTypeALL () func ( msg proto . Message ) error // DataTypeCONFIG creates a GNMIOption that sets the gnmi.GetRequest data type to CONFIG func DataTypeCONFIG () func ( msg proto . Message ) error // DataTypeSTATE creates a GNMIOption that sets the gnmi.GetRequest data type to STATE func DataTypeSTATE () func ( msg proto . Message ) error // DataTypeOPERATIONAL creates a GNMIOption that sets the gnmi.GetRequest data type to OPERATIONAL func DataTypeOPERATIONAL () func ( msg proto . Message ) error // UseModel creates a GNMIOption that add a gnmi.DataModel to a gnmi.GetRequest or gnmi.SubscribeRequest // based on the name, org and version strings provided. func UseModel ( name , org , version string ) func ( msg proto . Message ) error // Update creates a GNMIOption that creates a *gnmi.Update message and adds it to the supplied proto.Message, // the supplied message must be a *gnmi.SetRequest. func Update ( opts ... GNMIOption ) func ( msg proto . Message ) error // Replace creates a GNMIOption that creates a *gnmi.Update message and adds it to the supplied proto.Message. // the supplied message must be a *gnmi.SetRequest. func Replace ( opts ... GNMIOption ) func ( msg proto . Message ) error // Value creates a GNMIOption that creates a *gnmi.TypedValue and adds it to the supplied proto.Message. // the supplied message must be a *gnmi.Update. // If a map is supplied as `data interface{}` it has to be a map[string]interface{}. func Value ( data interface {}, encoding string ) func ( msg proto . Message ) error // Delete creates a GNMIOption that creates a *gnmi.Path and adds it to the supplied proto.Message. // the supplied message must be a *gnmi.SetRequest. The *gnmi.Path is added the .Delete list. func Delete ( path string ) func ( msg proto . Message ) error // SubscriptionListMode creates a GNMIOption that sets the SubscribeRequest Mode. // The variable mode must be one of \"once\", \"poll\" or \"stream\". // The supplied proto.Message must be a *gnmi.SubscribeRequest with RequestType Subscribe. func SubscriptionListMode ( mode string ) func ( msg proto . Message ) error // SubscriptionListModeSTREAM creates a GNMIOption that sets the Subscription List Mode to STREAM func SubscriptionListModeSTREAM () func ( msg proto . Message ) error // SubscriptionListModeONCE creates a GNMIOption that sets the Subscription List Mode to ONCE func SubscriptionListModeONCE () func ( msg proto . Message ) error // SubscriptionListModePOLL creates a GNMIOption that sets the Subscription List Mode to POLL func SubscriptionListModePOLL () func ( msg proto . Message ) error // Qos creates a GNMIOption that sets the QosMarking field in a *gnmi.SubscribeRequest with RequestType Subscribe. func Qos ( qos uint32 ) func ( msg proto . Message ) error // UseAliases creates a GNMIOption that sets the UsesAliases field in a *gnmi.SubscribeRequest with RequestType Subscribe. func UseAliases ( b bool ) func ( msg proto . Message ) error // AllowAggregation creates a GNMIOption that sets the AllowAggregation field in a *gnmi.SubscribeRequest with RequestType Subscribe. func AllowAggregation ( b bool ) func ( msg proto . Message ) error // UpdatesOnly creates a GNMIOption that sets the UpdatesOnly field in a *gnmi.SubscribeRequest with RequestType Subscribe. func UpdatesOnly ( b bool ) func ( msg proto . Message ) error // UpdatesOnly creates a GNMIOption that creates a *gnmi.Subscription based on the supplied GNMIOption(s) and adds it the // supplied proto.Message which must be of type *gnmi.SubscribeRequest with RequestType Subscribe. func Subscription ( opts ... GNMIOption ) func ( msg proto . Message ) error // SubscriptionMode creates a GNMIOption that sets the Subscription mode in a proto.Message of type *gnmi.Subscription. func SubscriptionMode ( mode string ) func ( msg proto . Message ) error // SubscriptionModeTARGET_DEFINED creates a GNMIOption that sets the subscription mode to TARGET_DEFINED func SubscriptionModeTARGET_DEFINED () func ( msg proto . Message ) error // SubscriptionModeON_CHANGE creates a GNMIOption that sets the subscription mode to ON_CHANGE func SubscriptionModeON_CHANGE () func ( msg proto . Message ) error // SubscriptionModeSAMPLE creates a GNMIOption that sets the subscription mode to SAMPLE func SubscriptionModeSAMPLE () func ( msg proto . Message ) error // SampleInterval creates a GNMIOption that sets the SampleInterval in a proto.Message of type *gnmi.Subscription. func SampleInterval ( d time . Duration ) func ( msg proto . Message ) error // HeartbeatInterval creates a GNMIOption that sets the HeartbeatInterval in a proto.Message of type *gnmi.Subscription. func HeartbeatInterval ( d time . Duration ) func ( msg proto . Message ) error // SuppressRedundant creates a GNMIOption that sets the SuppressRedundant in a proto.Message of type *gnmi.Subscription. func SuppressRedundant ( s bool ) func ( msg proto . Message ) error // Notification creates a GNMIOption that builds a gnmi.Notification from the supplied GNMIOptions and adds it // to the supplied proto.Message func Notification ( opts ... GNMIOption ) func ( msg proto . Message ) error // Timestamp sets the supplied timestamp in a gnmi.Notification message func Timestamp ( t int64 ) func ( msg proto . Message ) error // TimestampNow is the same as Timestamp(time.Now().UnixNano()) func TimestampNow () func ( msg proto . Message ) error // Alias sets the supplied alias value in a gnmi.Notification message func Alias ( alias string ) func ( msg proto . Message ) error // Atomic sets the .Atomic field in a gnmi.Notification message func Atomic ( b bool ) func ( msg proto . Message ) error // UpdateResult creates a GNMIOption that creates a gnmi.UpdateResult and adds it to // a proto.Message of type gnmi.SetResponse. func UpdateResult ( opts ... GNMIOption ) func ( msg proto . Message ) error // Operation creates a GNMIOption that sets the gnmi.UpdateResult_Operation // value in a gnmi.UpdateResult. func Operation ( oper string ) func ( msg proto . Message ) error // OperationINVALID creates a GNMIOption that sets the gnmi.SetResponse Operation to INVALID func OperationINVALID () func ( msg proto . Message ) error // OperationDELETE creates a GNMIOption that sets the gnmi.SetResponse Operation to DELETE func OperationDELETE () func ( msg proto . Message ) error // OperationREPLACE creates a GNMIOption that sets the gnmi.SetResponse Operation to REPLACE func OperationREPLACE () func ( msg proto . Message ) error // OperationUPDATE creates a GNMIOption that sets the gnmi.SetResponse Operation to UPDATE func OperationUPDATE () func ( msg proto . Message ) error","title":"gNMI Options"},{"location":"user_guide/golang_package/intro/","text":"gnmic ( github.com/karimra/gnmic/api ) can be imported as a dependency in your Golang programs. It acts as a wrapper around the openconfig/gnmi package providing a user friendly API to create a target and easily craft gNMI requests. Creating gNMI requests # Get Request # func NewGetRequest ( opts ... GNMIOption ) ( * gnmi . GetRequest , error ) The below 2 snippets create a Get Request with 2 paths, json_ietf encoding and data type STATE Using github.com/karimra/gnmic/api getReq , err := api . NewGetRequest ( api . Encoding ( \"json_ietf\" ), api . DataType ( \"state\" ), api . Path ( \"interface/statistics\" ), api . Path ( \"interface/subinterface/statistics\" ), ) // check error Using github.com/openconfig/gnmi getReq := & gnmi . GetRequest { Path : [] * gnmi . Path { { Elem : [] * gnmi . PathElem { { Name : \"interface\" }, { Name : \"statistics\" }, }, }, { Elem : [] * gnmi . PathElem { { Name : \"interface\" }, { Name : \"subinterface\" }, { Name : \"statistics\" }, }, }, }, Type : gnmi . GetRequest_STATE , Encoding : gnmi . Encoding_JSON_IETF , } Set Request # func NewSetRequest ( opts ... GNMIOption ) ( * gnmi . SetRequest , error ) The below 2 snippets create a Set Request with one two updates, one replace and one delete messages: Using github.com/karimra/gnmic/api setReq , err := api . NewSetRequest ( api . Update ( api . Path ( \"/system/name/host-name\" ), api . Value ( \"srl2\" , \"json_ietf\" ), ), api . Update ( api . Path ( \"/system/gnmi-server/unix-socket/admin-state\" ), api . Value ( \"enable\" , \"json_ietf\" ), ), api . Replace ( api . Path ( \"/network-instance[name=default]/admin-state\" ), api . Value ( \"enable\" , \"json_ietf\" ), ), api . Delete ( \"/interface[name=ethernet-1/1]/admin-state\" ), ) // check error Using github.com/openconfig/gnmi setReq := & gnmi . SetRequest { Update : [] * gnmi . Update { { Path : & gnmi . Path { Elem : [] * gnmi . PathElem { { Name : \"system\" }, { Name : \"name\" }, { Name : \"host-name\" }, }, }, Val : & gnmi . TypedValue { Value : & gnmi . TypedValue_JsonIetfVal { JsonIetfVal : [] byte ( \"\\\"srl2\\\"\" ), }, }, }, { Path : & gnmi . Path { Elem : [] * gnmi . PathElem { { Name : \"system\" }, { Name : \"gnmi-server\" }, { Name : \"unix-socket\" }, { Name : \"admin-state\" }, }, }, Val : & gnmi . TypedValue { Value : & gnmi . TypedValue_JsonIetfVal { JsonIetfVal : [] byte ( \"\\\"enable\\\"\" ), }, }, }, }, Replace : [] * gnmi . Update { { Path : & gnmi . Path { Elem : [] * gnmi . PathElem { { Name : \"network-instance\" , Key : map [ string ] string { \"name\" : \"default\" , }, }, { Name : \"admin-state\" , }, }, }, Val : & gnmi . TypedValue { Value : & gnmi . TypedValue_JsonIetfVal { JsonIetfVal : [] byte ( \"\\\"enable\\\"\" ), }, }, }, }, Delete : [] * gnmi . Path { { Elem : [] * gnmi . PathElem { { Name : \"interface\" , Key : map [ string ] string { \"name\" : \"ethernet-1/1\" , }, }, { Name : \"admin-state\" , }, }, }, }, } Subscribe Request # Create a Subscribe Request func NewSubscribeRequest ( opts ... GNMIOption ) ( * gnmi . SubscribeRequest , error ) Create a Subscribe Poll Request func NewSubscribePollRequest ( opts ... GNMIOption ) * gnmi . SubscribeRequest The below 2 snippets create a stream subscribe request with 2 paths, json_ietf encoding and a sample interval of 10 seconds: Using github.com/karimra/gnmic/api subReq , err := api . NewSubscribeRequest ( api . Encoding ( \"json_ietf\" ), api . SubscriptionListMode ( \"stream\" ), api . Subscription ( api . Path ( \"interface/statistics\" ), api . SubscriptionMode ( \"sample\" ), api . SampleInterval ( \"10s\" ), ), api . Subscription ( api . Path ( \"interface/subinterface/statistics\" ), api . SubscriptionMode ( \"sample\" ), api . SampleInterval ( \"10s\" ), ), ) // check error Using github.com/openconfig/gnmi subReq := & gnmi . SubscribeRequest_Subscribe { Subscribe : & gnmi . SubscriptionList { Subscription : [] * gnmi . Subscription { { Path : & gnmi . Path { Elem : [] * gnmi . PathElem { { Name : \"interface\" }, { Name : \"statistics\" }, }, }, Mode : gnmi . SubscriptionMode_SAMPLE , SampleInterval : uint64 ( 10 * time . Second ), }, { Path : & gnmi . Path { Elem : [] * gnmi . PathElem { { Name : \"interface\" }, { Name : \"subinterface\" }, { Name : \"statistics\" }, }, }, Mode : gnmi . SubscriptionMode_SAMPLE , SampleInterval : uint64 ( 10 * time . Second ), }, }, Mode : gnmi . SubscriptionList_STREAM , Encoding : gnmi . Encoding_JSON_IETF , }, } Creating Targets # A target can be created using func NewTarget(opts ...TargetOption) (*target.Target, error) . The full list of api.TargetOption can be found here tg , err := api . NewTarget ( api . Name ( \"srl1\" ), api . Address ( \"10.0.0.1:57400\" ), api . Username ( \"admin\" ), api . Password ( \"admin\" ), api . SkipVerify ( true ), ) // check error Once a Target is created, Multiple functions are available to run the desired RPCs, check the examples here","title":"Introduction"},{"location":"user_guide/golang_package/intro/#creating-gnmi-requests","text":"","title":"Creating gNMI requests"},{"location":"user_guide/golang_package/intro/#get-request","text":"func NewGetRequest ( opts ... GNMIOption ) ( * gnmi . GetRequest , error ) The below 2 snippets create a Get Request with 2 paths, json_ietf encoding and data type STATE Using github.com/karimra/gnmic/api getReq , err := api . NewGetRequest ( api . Encoding ( \"json_ietf\" ), api . DataType ( \"state\" ), api . Path ( \"interface/statistics\" ), api . Path ( \"interface/subinterface/statistics\" ), ) // check error Using github.com/openconfig/gnmi getReq := & gnmi . GetRequest { Path : [] * gnmi . Path { { Elem : [] * gnmi . PathElem { { Name : \"interface\" }, { Name : \"statistics\" }, }, }, { Elem : [] * gnmi . PathElem { { Name : \"interface\" }, { Name : \"subinterface\" }, { Name : \"statistics\" }, }, }, }, Type : gnmi . GetRequest_STATE , Encoding : gnmi . Encoding_JSON_IETF , }","title":"Get Request"},{"location":"user_guide/golang_package/intro/#set-request","text":"func NewSetRequest ( opts ... GNMIOption ) ( * gnmi . SetRequest , error ) The below 2 snippets create a Set Request with one two updates, one replace and one delete messages: Using github.com/karimra/gnmic/api setReq , err := api . NewSetRequest ( api . Update ( api . Path ( \"/system/name/host-name\" ), api . Value ( \"srl2\" , \"json_ietf\" ), ), api . Update ( api . Path ( \"/system/gnmi-server/unix-socket/admin-state\" ), api . Value ( \"enable\" , \"json_ietf\" ), ), api . Replace ( api . Path ( \"/network-instance[name=default]/admin-state\" ), api . Value ( \"enable\" , \"json_ietf\" ), ), api . Delete ( \"/interface[name=ethernet-1/1]/admin-state\" ), ) // check error Using github.com/openconfig/gnmi setReq := & gnmi . SetRequest { Update : [] * gnmi . Update { { Path : & gnmi . Path { Elem : [] * gnmi . PathElem { { Name : \"system\" }, { Name : \"name\" }, { Name : \"host-name\" }, }, }, Val : & gnmi . TypedValue { Value : & gnmi . TypedValue_JsonIetfVal { JsonIetfVal : [] byte ( \"\\\"srl2\\\"\" ), }, }, }, { Path : & gnmi . Path { Elem : [] * gnmi . PathElem { { Name : \"system\" }, { Name : \"gnmi-server\" }, { Name : \"unix-socket\" }, { Name : \"admin-state\" }, }, }, Val : & gnmi . TypedValue { Value : & gnmi . TypedValue_JsonIetfVal { JsonIetfVal : [] byte ( \"\\\"enable\\\"\" ), }, }, }, }, Replace : [] * gnmi . Update { { Path : & gnmi . Path { Elem : [] * gnmi . PathElem { { Name : \"network-instance\" , Key : map [ string ] string { \"name\" : \"default\" , }, }, { Name : \"admin-state\" , }, }, }, Val : & gnmi . TypedValue { Value : & gnmi . TypedValue_JsonIetfVal { JsonIetfVal : [] byte ( \"\\\"enable\\\"\" ), }, }, }, }, Delete : [] * gnmi . Path { { Elem : [] * gnmi . PathElem { { Name : \"interface\" , Key : map [ string ] string { \"name\" : \"ethernet-1/1\" , }, }, { Name : \"admin-state\" , }, }, }, }, }","title":"Set Request"},{"location":"user_guide/golang_package/intro/#subscribe-request","text":"Create a Subscribe Request func NewSubscribeRequest ( opts ... GNMIOption ) ( * gnmi . SubscribeRequest , error ) Create a Subscribe Poll Request func NewSubscribePollRequest ( opts ... GNMIOption ) * gnmi . SubscribeRequest The below 2 snippets create a stream subscribe request with 2 paths, json_ietf encoding and a sample interval of 10 seconds: Using github.com/karimra/gnmic/api subReq , err := api . NewSubscribeRequest ( api . Encoding ( \"json_ietf\" ), api . SubscriptionListMode ( \"stream\" ), api . Subscription ( api . Path ( \"interface/statistics\" ), api . SubscriptionMode ( \"sample\" ), api . SampleInterval ( \"10s\" ), ), api . Subscription ( api . Path ( \"interface/subinterface/statistics\" ), api . SubscriptionMode ( \"sample\" ), api . SampleInterval ( \"10s\" ), ), ) // check error Using github.com/openconfig/gnmi subReq := & gnmi . SubscribeRequest_Subscribe { Subscribe : & gnmi . SubscriptionList { Subscription : [] * gnmi . Subscription { { Path : & gnmi . Path { Elem : [] * gnmi . PathElem { { Name : \"interface\" }, { Name : \"statistics\" }, }, }, Mode : gnmi . SubscriptionMode_SAMPLE , SampleInterval : uint64 ( 10 * time . Second ), }, { Path : & gnmi . Path { Elem : [] * gnmi . PathElem { { Name : \"interface\" }, { Name : \"subinterface\" }, { Name : \"statistics\" }, }, }, Mode : gnmi . SubscriptionMode_SAMPLE , SampleInterval : uint64 ( 10 * time . Second ), }, }, Mode : gnmi . SubscriptionList_STREAM , Encoding : gnmi . Encoding_JSON_IETF , }, }","title":"Subscribe Request"},{"location":"user_guide/golang_package/intro/#creating-targets","text":"A target can be created using func NewTarget(opts ...TargetOption) (*target.Target, error) . The full list of api.TargetOption can be found here tg , err := api . NewTarget ( api . Name ( \"srl1\" ), api . Address ( \"10.0.0.1:57400\" ), api . Username ( \"admin\" ), api . Password ( \"admin\" ), api . SkipVerify ( true ), ) // check error Once a Target is created, Multiple functions are available to run the desired RPCs, check the examples here","title":"Creating Targets"},{"location":"user_guide/golang_package/target_options/","text":"The package github.com/karimra/gnmic/api exposes a set of api.TargetOption that can be used with api.NewTarget(...api.TargetOption) TargetOption to create target.Target . // Name sets the target name. func Name ( name string ) TargetOption // Address sets the target address. // This Option can be set multiple times. func Address ( addr string ) TargetOption // Username sets the target Username. func Username ( username string ) TargetOption // Password sets the target Password. func Password ( password string ) TargetOption // Timeout sets the gNMI client creation timeout. func Timeout ( timeout time . Duration ) TargetOption // Insecure sets the option to create a gNMI client with an // insecure gRPC connection func Insecure ( i bool ) TargetOption // SkipVerify sets the option to create a gNMI client with a // secure gRPC connection without verifying the target's certificates. func SkipVerify ( i bool ) TargetOption // TLSCA sets that path towards the TLS certificate authority file. func TLSCA ( tlsca string ) TargetOption // TLSCert sets that path towards the TLS certificate file. func TLSCert ( cert string ) TargetOption // TLSKey sets that path towards the TLS key file. func TLSKey ( key string ) TargetOption // TLSMinVersion sets the TLS minimum version used during the TLS handshake. func TLSMinVersion ( v string ) TargetOption // TLSMaxVersion sets the TLS maximum version used during the TLS handshake. func TLSMaxVersion ( v string ) TargetOption // TLSVersion sets the desired TLS version used during the TLS handshake. func TLSVersion ( v string ) TargetOption // LogTLSSecret, if set to true, // enables logging of the TLS master key. func LogTLSSecret ( b bool ) TargetOption // Gzip, if set to true, // adds gzip compression to the gRPC connection. func Gzip ( b bool ) TargetOption // Token sets the per RPC credentials for all RPC calls. func Token ( token string ) TargetOption","title":"Target Options"},{"location":"user_guide/golang_package/examples/capabilities/","text":"The below snippet shows how to create a target, send a Capabilities Request and print the response. package main import ( \"context\" \"fmt\" \"log\" \"github.com/karimra/gnmic/api\" \"google.golang.org/protobuf/encoding/prototext\" ) func main () { // create a target tg , err := api . NewTarget ( api . Name ( \"srl1\" ), api . Address ( \"10.0.0.1:57400\" ), api . Username ( \"admin\" ), api . Password ( \"admin\" ), api . SkipVerify ( true ), ) if err != nil { log . Fatal ( err ) } ctx , cancel := context . WithCancel ( context . Background ()) defer cancel () // create a gNMI client err = tg . CreateGNMIClient ( ctx ) if err != nil { log . Fatal ( err ) } defer tg . Close () // send a gNMI capabilities request to the created target capResp , err := tg . Capabilities ( ctx ) if err != nil { log . Fatal ( err ) } fmt . Println ( prototext . Format ( capResp )) }","title":"Capabilities"},{"location":"user_guide/golang_package/examples/get/","text":"The below snippet shows how to create a target, send a Get Request and print the response. package main import ( \"context\" \"fmt\" \"log\" \"github.com/karimra/gnmic/api\" \"google.golang.org/protobuf/encoding/prototext\" ) func main () { // create a target tg , err := api . NewTarget ( api . Name ( \"srl1\" ), api . Address ( \"10.0.0.1:57400\" ), api . Username ( \"admin\" ), api . Password ( \"admin\" ), api . SkipVerify ( true ), ) if err != nil { log . Fatal ( err ) } ctx , cancel := context . WithCancel ( context . Background ()) defer cancel () // create a gNMI client err = tg . CreateGNMIClient ( ctx ) if err != nil { log . Fatal ( err ) } defer tg . Close () // create a GetRequest getReq , err := api . NewGetRequest ( api . Path ( \"/system/name\" ), api . Encoding ( \"json_ietf\" )) if err != nil { log . Fatal ( err ) } fmt . Println ( prototext . Format ( getReq )) // send the created gNMI GetRequest to the created target getResp , err := tg . Get ( ctx , getReq ) if err != nil { log . Fatal ( err ) } fmt . Println ( prototext . Format ( getResp )) }","title":"Get"},{"location":"user_guide/golang_package/examples/set/","text":"The below snippet shows how to create a target, send a Set Request and print the reponse. package main import ( \"context\" \"fmt\" \"log\" \"github.com/karimra/gnmic/api\" \"google.golang.org/protobuf/encoding/prototext\" ) func main () { // create a target tg , err := api . NewTarget ( api . Name ( \"srl1\" ), api . Address ( \"10.0.0.1:57400\" ), api . Username ( \"admin\" ), api . Password ( \"admin\" ), api . SkipVerify ( true ), ) if err != nil { log . Fatal ( err ) } ctx , cancel := context . WithCancel ( context . Background ()) defer cancel () err = tg . CreateGNMIClient ( ctx ) if err != nil { log . Fatal ( err ) } defer tg . Close () // create a gNMI SetRequest setReq , err := api . NewSetRequest ( api . Update ( api . Path ( \"/system/name/host-name\" ), api . Value ( \"srl2\" , \"json_ietf\" )), ) if err != nil { log . Fatal ( err ) } fmt . Println ( prototext . Format ( setReq )) // send the created gNMI SetRequest to the created target setResp , err := tg . Set ( ctx , setReq ) if err != nil { log . Fatal ( err ) } fmt . Println ( prototext . Format ( setResp )) }","title":"Set"},{"location":"user_guide/golang_package/examples/subscribe/","text":"The below snippet shows how to create a target and a Subscribe Request. It then starts a Stream subscription with 10s interval and listens to Responses and errors. package main import ( \"context\" \"fmt\" \"log\" \"time\" \"github.com/karimra/gnmic/api\" \"google.golang.org/protobuf/encoding/prototext\" ) func main () { // create a target tg , err := api . NewTarget ( api . Name ( \"srl1\" ), api . Address ( \"srl1:57400\" ), api . Username ( \"admin\" ), api . Password ( \"admin\" ), api . SkipVerify ( true ), ) if err != nil { log . Fatal ( err ) } ctx , cancel := context . WithCancel ( context . Background ()) defer cancel () err = tg . CreateGNMIClient ( ctx ) if err != nil { log . Fatal ( err ) } defer tg . Close () // create a gNMI subscribeRequest subReq , err := api . NewSubscribeRequest ( api . Encoding ( \"json_ietf\" ), api . SubscriptionListMode ( \"stream\" ), api . Subscription ( api . Path ( \"system/name\" ), api . SubscriptionMode ( \"sample\" ), api . SampleInterval ( 10 * time . Second ), )) if err != nil { log . Fatal ( err ) } fmt . Println ( prototext . Format ( subReq )) // start the subscription go tg . Subscribe ( ctx , subReq , \"sub1\" ) // start a goroutine that will stop the subscription after x seconds go func () { select { case <- ctx . Done (): return case <- time . After ( 42 * time . Second ): tg . StopSubscription ( \"sub1\" ) } }() subRspChan , subErrChan := tg . ReadSubscriptions () for { select { case rsp := <- subRspChan : fmt . Println ( prototext . Format ( rsp . Response )) case tgErr := <- subErrChan : log . Fatalf ( \"subscription %q stopped: %v\" , tgErr . SubscriptionName , tgErr . Err ) } } }","title":"Subcribe"},{"location":"user_guide/inputs/input_intro/","text":"gnmic supports various Inputs to consume gnmi data, transform it and ultimately export it to one or multiple Outputs. The purpose of gnmic 's Inputs is to build a gnmi data pipeline by enabling the ingestion and export of gnmi data that was exported by gnmic 's outputs upstream. Currently supported input types: NATS messaging system NATS Streaming messaging bus (STAN) Kafka messaging bus Defining Inputs and matching Outputs # To define an Input a user needs to fill in the inputs section in the configuration file. Each Input is defined by its name ( input1 in the example below), a type field which determines the type of input to be created ( nats , stan , kafka ) and various other configuration fields which depend on the Input type. Note Inputs names are case insensitive All Input types have an outputs field, under which the user can defined the downstream destination(s) of the consumed data. This way, data consumed once, can be exported multiple times. Info The same gnmic instance can act as gNMI collector, input and output simultaneously. Example: # part of gnmic config file inputs : input1 : type : nats # input type # # other config fields depending on the input type # outputs : - output1 - output2 Inputs use cases # Clustering # Using gnmic Inputs, the user can aggregate all the collected data into one instance of gnmic that can make it available to a downstream off the shelf tool,typically Prometheus. Data reuse # Collect data once and use it multiple times. By chaining multiple instances of gnmic the user can process the same stream of data in different ways. A different set of event processors can be applied on the data stream before being exported to its intended outputs.","title":"Introduction"},{"location":"user_guide/inputs/input_intro/#defining-inputs-and-matching-outputs","text":"To define an Input a user needs to fill in the inputs section in the configuration file. Each Input is defined by its name ( input1 in the example below), a type field which determines the type of input to be created ( nats , stan , kafka ) and various other configuration fields which depend on the Input type. Note Inputs names are case insensitive All Input types have an outputs field, under which the user can defined the downstream destination(s) of the consumed data. This way, data consumed once, can be exported multiple times. Info The same gnmic instance can act as gNMI collector, input and output simultaneously. Example: # part of gnmic config file inputs : input1 : type : nats # input type # # other config fields depending on the input type # outputs : - output1 - output2","title":"Defining Inputs and matching Outputs"},{"location":"user_guide/inputs/input_intro/#inputs-use-cases","text":"","title":"Inputs use cases"},{"location":"user_guide/inputs/input_intro/#clustering","text":"Using gnmic Inputs, the user can aggregate all the collected data into one instance of gnmic that can make it available to a downstream off the shelf tool,typically Prometheus.","title":"Clustering"},{"location":"user_guide/inputs/input_intro/#data-reuse","text":"Collect data once and use it multiple times. By chaining multiple instances of gnmic the user can process the same stream of data in different ways. A different set of event processors can be applied on the data stream before being exported to its intended outputs.","title":"Data reuse"},{"location":"user_guide/inputs/kafka_input/","text":"When using Kafka as input, gnmic consumes data from a specific Kafka topic in event or proto format. Multiple consumers can be created per gnmic instance ( num-workers ). All the workers join the same Kafka consumer group ( group-id ) in order to load share the messages between the workers. Multiple instances of gnmic with the same Kafka input can be used to effectively consume the exported messages in parallel The Kafka input will export the received messages to the list of outputs configured under its outputs section. inputs : input1 : # string, required, specifies the type of input type : kafka # Kafka subscriber name # If left empty, it will be populated with the string from flag --instance-name appended with `--kafka-cons`. # If --instance-name is also empty, a random name is generated in the format `gnmic-$uuid` # note that each kafka worker (consumer) will get name=$name-$index name : \"\" # Kafka SASL configuration sasl : # SASL user name user : # SASL password password : # SASL mechanism: PLAIN, SCRAM-SHA-256, SCRAM-SHA-512 and OAUTHBEARER are supported mechanism : # token url for OAUTHBEARER SASL mechanism token-url : # string, comma separated Kafka servers addresses address : localhost:9092 # string, comma separated topics the Kafka consumer group consumes messages from. topics : telemetry # consumer group all gnmic Kafka input workers join, # so that Kafka server can load share the messages between them. Defaults to `gnmic-consumers` group-id : gnmic-consumers # duration, the timeout used to detect consumer failures when using Kafka's group management facility. # If no heartbeats are received by the broker before the expiration of this session timeout, # then the broker will remove this consumer from the group and initiate a rebalance. session-timeout : 10s # duration, the expected time between heartbeats to the consumer coordinator when using Kafka's group # management facilities. heartbeat-interval : 3s # duration, wait time before reconnection attempts after any error recovery-wait-time : 2s # string, kafka version, defaults to 2.5.0 version : # string, consumed message expected format, one of: proto, event format : event # bool, enables extra logging debug : false # integer, number of kafka consumers to be created num-workers : 1 # list of processors to apply on the message when received, # only applies if format is 'event' event-processors : # []string, list of named outputs to export data to. # Must be configured under root level `outputs` section outputs :","title":"Kafka"},{"location":"user_guide/inputs/nats_input/","text":"When using NATS as input, gnmic consumes data from a specific NATS subject in event or proto format. Multiple consumers can be created per gnmic instance ( num-workers ). All the workers join the same NATS queue group ( queue ) in order to load share the messages between the workers. Multiple instances of gnmic with the same NATS input can be used to effectively consume the exported messages in parallel The NATS input will export the received messages to the list of outputs configured under its outputs section. inputs : input1 : # string, required, specifies the type of input type : nats # NATS subscriber name # If left empty, it will be populated with the string from flag --instance-name appended with `--nats-sub`. # If --instance-name is also empty, a random name is generated in the format `gnmic-$uuid` # note that each nats worker (subscriber) will get name=$name-$index name : \"\" # string, comma separated NATS servers addresses address : localhost:4222 # The subject name gnmic NATS consumers subscribe to. subject : telemetry # subscribe queue group all gnmic NATS input workers join, # so that NATS server can load share the messages between them. queue : # string, NATS username username : # string, NATS password password : # duration, wait time before reconnection attempts connect-time-wait : 2s # string, consumed message expected format, one of: proto, event format : event # bool, enables extra logging debug : false # integer, number of nats consumers to be created num-workers : 1 # integer, sets the size of the local buffer where received # NATS messages are stored before being sent to outputs. # This value is set per worker. Defaults to 100 messages buffer-size : 100 # list of processors to apply on the message when received, # only applies if format is 'event' event-processors : # []string, list of named outputs to export data to. # Must be configured under root level `outputs` section outputs :","title":"NATS"},{"location":"user_guide/inputs/stan_input/","text":"When using STAN as input, gnmic consumes data from a specific STAN subject in event or proto format. Multiple consumers can be created per gnmic instance ( num-workers ). All the workers join the same STAN queue group ( queue ) in order to load share the messages between the workers. Multiple instances of gnmic with the same STAN input can be used to effectively consume the exported messages in parallel The STAN input will export the received messages to the list of outputs configured under its outputs section. inputs : input1 : # string, required, specifies the type of input type : stan # STAN subscriber name # If left empty, it will be populated with the string from flag --instance-name appended with `--stan-sub`. # If --instance-name is also empty, a random name is generated in the format `gnmic-$uuid` # note that each stan worker (subscriber) will get name=$name-$index name : \"\" # string, comma separated STAN servers addresses address : localhost:4222 # The subject name gnmic STAN consumers subscribe to. subject : telemetry # subscribe queue group all gnmic STAN input workers join, # so that STAN server can load share the messages between them. queue : # string, STAN username username : # string, STAN password password : # duration, wait time before reconnection attempts connect-time-wait : 2s # string, the STAN cluster name. defaults to test-cluster cluster-name : # integer, interval (in seconds) at which # a connection sends a PING to the server. min=1 ping-interval : # integer, number of PINGs without a response # before the connection is considered lost. min=2 ping-retry : # string, consumed message expected format, one of: proto, event format : event # bool, enables extra logging debug : false # integer, number of stan consumers to be created num-workers : 1 # list of processors to apply on the message when received, # only applies if format is 'event' event-processors : # []string, list of named outputs to export data to. # Must be configured under root level `outputs` section outputs :","title":"STAN"},{"location":"user_guide/outputs/file_output/","text":"gnmic supports exporting subscription updates to multiple local files A file output can be defined using the below format in gnmic config file under outputs section: outputs : output1 : # required type : file # filename to write telemetry data to. # will be ignored if `file-type` is set filename : /path/to/filename # file-type, stdout or stderr. # overwrites `filename` file-type : # stdout or stderr # string, message formatting, json, protojson, prototext, event format : # string, one of `overwrite`, `if-not-present`, `` # This field allows populating/changing the value of Prefix.Target in the received message. # if set to ``, nothing changes # if set to `overwrite`, the target value is overwritten using the template configured under `target-template` # if set to `if-not-present`, the target value is populated only if it is empty, still using the `target-template` add-target : # string, a GoTemplate that allow for the customization of the target field in Prefix.Target. # it applies only if the previous field `add-target` is not empty. # if left empty, it defaults to: # {{- if index . \"subscription-target\" -}} # {{ index . \"subscription-target\" }} # {{- else -}} # {{ index . \"source\" | host }} # {{- end -}}` # which will set the target to the value configured under `subscription.$subscription-name.target` if any, # otherwise it will set it to the target name stripped of the port number (if present) target-template : # string, a GoTemplate that is executed using the received gNMI message as input. # the template execution is the last step before the data is written to the file, # First the received message is formatted according to the `format` field above, then the `event-processors` are applied if any # then finally the msg-template is executed. msg-template : # boolean, if true the message timestamp is changed to current time override-timestamps : # boolean, format the output in indented form with every element on a new line. multiline : # string, indent specifies the set of indentation characters to use in a multiline formatted output indent : # string, separator is the set of characters to write between messages, defaults to new line separator : # integer, specifies the maximum number of allowed concurrent file writes concurrency-limit : 1000 # boolean, enables the collection and export (via prometheus) of output specific metrics enable-metrics : false # list of processors to apply on the message before writing event-processors : The file output can be used to write to file on the disk, to stdout or to stderr. For a disk file, a file name is required. For stdout or stderr, only file-type is required.","title":"File"},{"location":"user_guide/outputs/gnmi_output/","text":"gnmic supports acting as a gNMI Server to expose the subscribed telemetry data to a gNMI Client using the Subcribe RPC, or to act as a gateway for Get and Set RPCs. Configuration # outputs : output1 : # required type : gnmi # gNMI server address, either a TCP socket or UNIX socket. # In the latter case, the prefix `unix:///` should be present. address : \":57400\" # maximum number of active subscriptions. max-subscriptions : 64 # maximum number of ongoing Get/Set RPCs. max-unary-rpc : 64 # boolean, if true, the gNMI server will run in secure mode # but will not verify the client certificate against the available certificate chain. skip-verify : false # string, path to the CA certificate file, this will be used to verify the clients certificates, if `skip-verify` is false ca-file : # string, server certificate file. # if both `cert-file` and `key-file` are empty, and `skip-verify` is true or `ca-file` is set, # the server will run with self signed certificates. cert-file : # string, server key file. # if both `cert-file` and `key-file` are empty, and `skip-verify` is true or `ca-file` is set, # the server will run with self signed certificates. key-file : # string, a GoTemplate that allow for the customization of the target field in Prefix.Target. # it applies only if the returned Prefix.Target is empty. # if left empty, it defaults to: # `{{- if index . \"subscription-target\" -}} # {{ index . \"subscription-target\" }} # {{- else -}} # {{ index . \"source\" | host }} # {{- end -}}` # which will set the target to the value configured under `subscription.$subscription-name.target` if any, # otherwise it will set it to the target name stripped of the port number (if present). target-template : # boolean, enables extra logging for the gNMI Server debug : false # boolean, enables the collection and export (via prometheus) of output specific metrics enable-metrics : false Insecure Mode # By default, the server runs in insecure mode, as long as skip-verify is false and none of ca-file , cert-file and key-file are set. Secure Mode # To run this gNMI server in secure mode, there are a few options: Using self signed certificates, without client certificate verification: skip-verify : true Using self signed certificates, with client certificate verification: # a valid CA certificate to verify the client provided certificates ca-file : /path/to/caFile Using CA provided certificates, without client certificate verification: skip-verify : true # a valid server certificate cert-file : /path/to/server-cert # a valid server key key-file : /path/to/server-key Using CA provided certificates, with client certificate verification: # a valid CA certificate to verify the client provided certificates ca-file : /path/to/caFile # a valid server certificate cert-file : /path/to/server-cert # a valid server key key-file : /path/to/server-key Supported RPCs # This gNMI Server supports Get , Set and Subscribe RPCs. gNMI Subscribe RPC # The server keeps a cache of gNMI notifications synched with the configured targets based on the configured subscriptions. This means that a client cannot get updates about a leaf that gNMIc did not subscribe to upstream. As soon as there is an update to the cache, the added gNMI notification is sent to all the client which subscription matches the new notification. Clients can subscribe to specific target using the gNMI Prefix Target field, leaving the Target field empty or setting it to * is equivalent to subscribing to all known targets. gNMI Get RPC # The server supports the gNMI Get RPC. It relies on the Prefix.Target field to select the target(s) to relay the received GetRequest to. If Prefix.Target is empty or is equal to * , a Get RPC is performed for all known targets. The received GetRequest is cloned, enriched with each target name and sent to the corresponding destination. Comma separated target names are also supported and allow to select a list of specific targets to send the Get RPC to. Once all GetResponses are received back successfully, the notifications contained in each GetResponse are combined into a single GetResponse with their Prefix.Target populated, if empty. The resulting GetResponse is then returned to the gNMI client. If one of the RPCs fails, an error with status code Internal(13) is returned to the client. If the Get Request has the origin field set to gnmic , the request is performed against the internal server configuration. Currently only the path targets is supported. gnmic -a localhost:57400 --skip-verify get --path gnmic:/targets [ { \"timestamp\" : 1626759382486891218 , \"time\" : \"2021-07-20T13:36:22.486891218+08:00\" , \"prefix\" : \"gnmic:targets[name=clab-gw-srl1:57400]\" , \"updates\" : [ { \"Path\" : \"address\" , \"values\" : { \"address\" : \"clab-gw-srl1:57400\" } }, { \"Path\" : \"username\" , \"values\" : { \"username\" : \"admin\" } }, { \"Path\" : \"insecure\" , \"values\" : { \"insecure\" : \"false\" } }, { \"Path\" : \"skip-verify\" , \"values\" : { \"skip-verify\" : \"true\" } }, { \"Path\" : \"timeout\" , \"values\" : { \"timeout\" : \"10s\" } } ] }, { \"timestamp\" : 1626759382486900697 , \"time\" : \"2021-07-20T13:36:22.486900697+08:00\" , \"prefix\" : \"gnmic:targets[name=clab-gw-srl2:57400]\" , \"updates\" : [ { \"Path\" : \"address\" , \"values\" : { \"address\" : \"clab-gw-srl2:57400\" } }, { \"Path\" : \"username\" , \"values\" : { \"username\" : \"admin\" } }, { \"Path\" : \"insecure\" , \"values\" : { \"insecure\" : \"false\" } }, { \"Path\" : \"skip-verify\" , \"values\" : { \"skip-verify\" : \"true\" } }, { \"Path\" : \"timeout\" , \"values\" : { \"timeout\" : \"10s\" } } ] } ] gNMI Set RPC # The gNMI server supports the gNMI Set RPC. Just like in the case of Get RPC, the server relies on the Prefix.Target field to select the target(s) to relay the received SetRequest to. If Prefix.Target is empty or is equal to * , a Set RPC is performed for all known targets. The received SetRequest is cloned, enriched with each target name and sent to the corresponding destination. Comma separated target names are also supported and allow to select a list of specific targets to send the Set RPC to. Once all SetResponses are received back successfully, the UpdateResult s from each response are merged into a single SetResponse, with the addition of the target name set in Path.Target . This is not compliant with the gNMI specification which stipulates that the Target field should only be present in Prefix Paths The resulting SetResponse is then returned to the gNMI client. If one of the RPCs fails, an error with status code Internal(13) is returned to the client.","title":"gNMI Server"},{"location":"user_guide/outputs/gnmi_output/#configuration","text":"outputs : output1 : # required type : gnmi # gNMI server address, either a TCP socket or UNIX socket. # In the latter case, the prefix `unix:///` should be present. address : \":57400\" # maximum number of active subscriptions. max-subscriptions : 64 # maximum number of ongoing Get/Set RPCs. max-unary-rpc : 64 # boolean, if true, the gNMI server will run in secure mode # but will not verify the client certificate against the available certificate chain. skip-verify : false # string, path to the CA certificate file, this will be used to verify the clients certificates, if `skip-verify` is false ca-file : # string, server certificate file. # if both `cert-file` and `key-file` are empty, and `skip-verify` is true or `ca-file` is set, # the server will run with self signed certificates. cert-file : # string, server key file. # if both `cert-file` and `key-file` are empty, and `skip-verify` is true or `ca-file` is set, # the server will run with self signed certificates. key-file : # string, a GoTemplate that allow for the customization of the target field in Prefix.Target. # it applies only if the returned Prefix.Target is empty. # if left empty, it defaults to: # `{{- if index . \"subscription-target\" -}} # {{ index . \"subscription-target\" }} # {{- else -}} # {{ index . \"source\" | host }} # {{- end -}}` # which will set the target to the value configured under `subscription.$subscription-name.target` if any, # otherwise it will set it to the target name stripped of the port number (if present). target-template : # boolean, enables extra logging for the gNMI Server debug : false # boolean, enables the collection and export (via prometheus) of output specific metrics enable-metrics : false","title":"Configuration"},{"location":"user_guide/outputs/gnmi_output/#insecure-mode","text":"By default, the server runs in insecure mode, as long as skip-verify is false and none of ca-file , cert-file and key-file are set.","title":"Insecure Mode"},{"location":"user_guide/outputs/gnmi_output/#secure-mode","text":"To run this gNMI server in secure mode, there are a few options: Using self signed certificates, without client certificate verification: skip-verify : true Using self signed certificates, with client certificate verification: # a valid CA certificate to verify the client provided certificates ca-file : /path/to/caFile Using CA provided certificates, without client certificate verification: skip-verify : true # a valid server certificate cert-file : /path/to/server-cert # a valid server key key-file : /path/to/server-key Using CA provided certificates, with client certificate verification: # a valid CA certificate to verify the client provided certificates ca-file : /path/to/caFile # a valid server certificate cert-file : /path/to/server-cert # a valid server key key-file : /path/to/server-key","title":"Secure Mode"},{"location":"user_guide/outputs/gnmi_output/#supported-rpcs","text":"This gNMI Server supports Get , Set and Subscribe RPCs.","title":"Supported RPCs"},{"location":"user_guide/outputs/gnmi_output/#gnmi-subscribe-rpc","text":"The server keeps a cache of gNMI notifications synched with the configured targets based on the configured subscriptions. This means that a client cannot get updates about a leaf that gNMIc did not subscribe to upstream. As soon as there is an update to the cache, the added gNMI notification is sent to all the client which subscription matches the new notification. Clients can subscribe to specific target using the gNMI Prefix Target field, leaving the Target field empty or setting it to * is equivalent to subscribing to all known targets.","title":"gNMI Subscribe RPC"},{"location":"user_guide/outputs/gnmi_output/#gnmi-get-rpc","text":"The server supports the gNMI Get RPC. It relies on the Prefix.Target field to select the target(s) to relay the received GetRequest to. If Prefix.Target is empty or is equal to * , a Get RPC is performed for all known targets. The received GetRequest is cloned, enriched with each target name and sent to the corresponding destination. Comma separated target names are also supported and allow to select a list of specific targets to send the Get RPC to. Once all GetResponses are received back successfully, the notifications contained in each GetResponse are combined into a single GetResponse with their Prefix.Target populated, if empty. The resulting GetResponse is then returned to the gNMI client. If one of the RPCs fails, an error with status code Internal(13) is returned to the client. If the Get Request has the origin field set to gnmic , the request is performed against the internal server configuration. Currently only the path targets is supported. gnmic -a localhost:57400 --skip-verify get --path gnmic:/targets [ { \"timestamp\" : 1626759382486891218 , \"time\" : \"2021-07-20T13:36:22.486891218+08:00\" , \"prefix\" : \"gnmic:targets[name=clab-gw-srl1:57400]\" , \"updates\" : [ { \"Path\" : \"address\" , \"values\" : { \"address\" : \"clab-gw-srl1:57400\" } }, { \"Path\" : \"username\" , \"values\" : { \"username\" : \"admin\" } }, { \"Path\" : \"insecure\" , \"values\" : { \"insecure\" : \"false\" } }, { \"Path\" : \"skip-verify\" , \"values\" : { \"skip-verify\" : \"true\" } }, { \"Path\" : \"timeout\" , \"values\" : { \"timeout\" : \"10s\" } } ] }, { \"timestamp\" : 1626759382486900697 , \"time\" : \"2021-07-20T13:36:22.486900697+08:00\" , \"prefix\" : \"gnmic:targets[name=clab-gw-srl2:57400]\" , \"updates\" : [ { \"Path\" : \"address\" , \"values\" : { \"address\" : \"clab-gw-srl2:57400\" } }, { \"Path\" : \"username\" , \"values\" : { \"username\" : \"admin\" } }, { \"Path\" : \"insecure\" , \"values\" : { \"insecure\" : \"false\" } }, { \"Path\" : \"skip-verify\" , \"values\" : { \"skip-verify\" : \"true\" } }, { \"Path\" : \"timeout\" , \"values\" : { \"timeout\" : \"10s\" } } ] } ]","title":"gNMI Get RPC"},{"location":"user_guide/outputs/gnmi_output/#gnmi-set-rpc","text":"The gNMI server supports the gNMI Set RPC. Just like in the case of Get RPC, the server relies on the Prefix.Target field to select the target(s) to relay the received SetRequest to. If Prefix.Target is empty or is equal to * , a Set RPC is performed for all known targets. The received SetRequest is cloned, enriched with each target name and sent to the corresponding destination. Comma separated target names are also supported and allow to select a list of specific targets to send the Set RPC to. Once all SetResponses are received back successfully, the UpdateResult s from each response are merged into a single SetResponse, with the addition of the target name set in Path.Target . This is not compliant with the gNMI specification which stipulates that the Target field should only be present in Prefix Paths The resulting SetResponse is then returned to the gNMI client. If one of the RPCs fails, an error with status code Internal(13) is returned to the client.","title":"gNMI Set RPC"},{"location":"user_guide/outputs/influxdb_output/","text":"gnmic supports exporting subscription updates to influxDB time series database An influxdb output can be defined using the below format in gnmic config file under outputs section: outputs : output1 : # required type : influxdb # influxDB server address url : http://localhost:8086 # empty if using influxdb1.8.x org : myOrg # string in the form database/retention-policy. Skip retention policy for the default on bucket : telemetry # influxdb 1.8.x use a string in the form: \"username:password\" token : # number of points to buffer before writing to the server batch-size : 1000 # flush period after which the buffer is written to the server whether the batch_size is reached or not flush-timer : 10s # if true, the influxdb client will use gzip compression in write requests. use-gzip : false # if true, the influxdb client will use a secure connection to the server. enable-tls : false # boolean, if true the message timestamp is changed to current time override-timestamps : false # server health check period, used to recover from server connectivity failure health-check-period : 30s # enable debug debug : false # string, one of `overwrite`, `if-not-present`, `` # This field allows populating/changing the value of Prefix.Target in the received message. # if set to ``, nothing changes # if set to `overwrite`, the target value is overwritten using the template configured under `target-template` # if set to `if-not-present`, the target value is populated only if it is empty, still using the `target-template` add-target : # string, a GoTemplate that allow for the customization of the target field in Prefix.Target. # it applies only if the previous field `add-target` is not empty. # if left empty, it defaults to: # {{- if index . \"subscription-target\" -}} # {{ index . \"subscription-target\" }} # {{- else -}} # {{ index . \"source\" | host }} # {{- end -}}` # which will set the target to the value configured under `subscription.$subscription-name.target` if any, # otherwise it will set it to the target name stripped of the port number (if present) target-template : # NOT IMPLEMENTED boolean, enables the collection and export (via prometheus) of output specific metrics enable-metrics : false # list of processors to apply on the message before writing event-processors : [] # cache, if present enables the influxdb output to cache received updates and write them all together # at `cache-flush-timer` expiry. cache : # duration, if > 0, enables the expiry of values written to the cache. expiration : 0s # debug, if true enable extra logging debug : false # cache-flush-timer cache-flush-timer : 5s gnmic uses the event format to generate the measurements written to influxdb","title":"InfluxDB"},{"location":"user_guide/outputs/jetstream_output/","text":"gnmic supports exporting subscription updates NATS Jetstream servers. A Jetstream output can be defined using the below format in gnmic config file under outputs section: configuration # outputs : output1 : # required type : jetstream # NATS publisher name # if left empty, this field is populated with the output name used as output ID (output1 in this example). # If the flag --instance-name is not empty, the full name will be '$(instance-name)-$(name). # note that each jetstream worker (publisher) will get a client name=$name-$index name : \"\" # Comma separated NATS servers address : localhost:4222 # string, stream name to write update to, # if `create-stream` is set, it will be created # # may not contain spaces, tabs, period (.), greater than (>) or asterisk (*) stream : # defines stream parameters that gNMIc will create on the target jetstream server(s) create-stream : # string, stream description description : created by gNMIc # string list, list of subjects allowed on the stream # defaults to `.create-stream.$name.>` subjects : # string, one of `memory`, `file`. # defines the storage type to use for the stream. # defaults to `memory` storage : # int64, max number of messages in the stream. max-msgs : # int64, max bytes the stream may contain. max-bytes : # duration, max age of any message in the stream. max-age : # int32, maximum message size max-msg-size : # string, one of `static`, `subscription.target`, `subscription.target.path` # or `subscription.target.pathKeys`. # Defines the subject format. # `static`: # all updates will be written to the subject name set under `outputs.$output_name.subject` # `subscription.target`: # updates from each subscription, target will be written # to subject $subscription_name.$target_name # `subscription.target.path`: # updates from a certain subscription, target and path # will be written to subject $subscription_name.$target_name.$path. # The path is built by joining the gNMI path pathElements with a dot (.). # e.g: /interface[name=ethernet-1/1]/statistics/in-octets # --> interface.statistics.in-octets # `subscription.target.pathKeys`: # updates from a certain subscription, a certain target and a certain path # will be written to subject $subscription_name.$target_name.$path. # The path is built by joining the gNMI path pathElements and Keys with a dot (.). # e.g: /interface[name=ethernet-1/1]/statistics/in-octets # --> interface.{name=ethernet-1/1}.statistics.in-octets subject-format : static # If a subject-format is `static`, gnmic will publish all subscriptions updates # to a single subject configured under this field. Defaults to 'telemetry' subject : telemetry # TLS configuration tls : # string, path to CA certificates file ca-file : # string, path to client certificate file cert-file : # string, path to client key file key-file : # boolean, if true, the client does not verify the server certificates skip-verify : # NATS username username : # NATS password password : # wait time before reconnection attempts connect-time-wait : 2s # Exported message format, one of: proto, prototext, protojson, json, event format : event # string, one of `overwrite`, `if-not-present`, `` # This field allows populating/changing the value of Prefix.Target in the received message. # if set to ``, nothing changes # if set to `overwrite`, the target value is overwritten using the template configured under `target-template` # if set to `if-not-present`, the target value is populated only if it is empty, still using the `target-template` add-target : # string, a GoTemplate that allow for the customization of the target field in Prefix.Target. # it applies only if the previous field `add-target` is not empty. # if left empty, it defaults to: # {{- if index . \"subscription-target\" -}} # {{ index . \"subscription-target\" }} # {{- else -}} # {{ index . \"source\" | host }} # {{- end -}}` # which will set the target to the value configured under `subscription.$subscription-name.target` if any, # otherwise it will set it to the target name stripped of the port number (if present) target-template : # string, a GoTemplate that is executed using the received gNMI message as input. # the template execution is the last step before the data is written to the file. # First the received message is formatted according to the `format` field above, then the `event-processors` are applied if any # then finally the msg-template is executed. msg-template : # boolean, if true the message timestamp is changed to current time override-timestamps : false # integer, number of nats publishers to be created num-workers : 1 # duration after which a message waiting to be handled by a worker gets discarded write-timeout : 5s # boolean, enables extra logging for the nats output debug : false # boolean, enables the collection and export (via prometheus) of output specific metrics enable-metrics : false # list of processors to apply to the message before writing event-processors : subject-format # The subject-format field is used to control how the received gNMI notifications are written into the configured stream. static # All notifications will be written to the subject name set under outputs.$output_name.subject subscription.target # Notifications from each subscription and target pair will be written to subject $subscription_name.$target_name subscription.target.path # Notifications from a subscription, target and path tuple will be written to subject subscription_name. subscription_name. target_name.$path. The path is built by joining the gNMI path pathElements with a period (.) . Notifications containing more than one update, will be expanded into multiple notifications with one update each. E.g: An update from target target1 and subscription sub1 containing path /interface[name=ethernet-1/1]/statistics/in-octets , will be written to subject: $stream_name.sub1.target1.interface.statistics.in-octets subscription.target.pathKeys # Updates from a certain subscription, a certain target and a certain path will be written to subject $subscription_name.$target_name.$path . The path is built by joining the gNMI path pathElements and Keys with a period (.) . Notifications containing more than one update, will be expanded into multiple notifications with one update each. E.g: An update from target target1 and subscription sub1 containing path /interface[name=ethernet-1/1]/statistics/in-octets , will be written to subject: $stream_name.sub1.target1.interface.{name=ethernet-1/1}.statistics.in-octets","title":"Jetstream"},{"location":"user_guide/outputs/jetstream_output/#configuration","text":"outputs : output1 : # required type : jetstream # NATS publisher name # if left empty, this field is populated with the output name used as output ID (output1 in this example). # If the flag --instance-name is not empty, the full name will be '$(instance-name)-$(name). # note that each jetstream worker (publisher) will get a client name=$name-$index name : \"\" # Comma separated NATS servers address : localhost:4222 # string, stream name to write update to, # if `create-stream` is set, it will be created # # may not contain spaces, tabs, period (.), greater than (>) or asterisk (*) stream : # defines stream parameters that gNMIc will create on the target jetstream server(s) create-stream : # string, stream description description : created by gNMIc # string list, list of subjects allowed on the stream # defaults to `.create-stream.$name.>` subjects : # string, one of `memory`, `file`. # defines the storage type to use for the stream. # defaults to `memory` storage : # int64, max number of messages in the stream. max-msgs : # int64, max bytes the stream may contain. max-bytes : # duration, max age of any message in the stream. max-age : # int32, maximum message size max-msg-size : # string, one of `static`, `subscription.target`, `subscription.target.path` # or `subscription.target.pathKeys`. # Defines the subject format. # `static`: # all updates will be written to the subject name set under `outputs.$output_name.subject` # `subscription.target`: # updates from each subscription, target will be written # to subject $subscription_name.$target_name # `subscription.target.path`: # updates from a certain subscription, target and path # will be written to subject $subscription_name.$target_name.$path. # The path is built by joining the gNMI path pathElements with a dot (.). # e.g: /interface[name=ethernet-1/1]/statistics/in-octets # --> interface.statistics.in-octets # `subscription.target.pathKeys`: # updates from a certain subscription, a certain target and a certain path # will be written to subject $subscription_name.$target_name.$path. # The path is built by joining the gNMI path pathElements and Keys with a dot (.). # e.g: /interface[name=ethernet-1/1]/statistics/in-octets # --> interface.{name=ethernet-1/1}.statistics.in-octets subject-format : static # If a subject-format is `static`, gnmic will publish all subscriptions updates # to a single subject configured under this field. Defaults to 'telemetry' subject : telemetry # TLS configuration tls : # string, path to CA certificates file ca-file : # string, path to client certificate file cert-file : # string, path to client key file key-file : # boolean, if true, the client does not verify the server certificates skip-verify : # NATS username username : # NATS password password : # wait time before reconnection attempts connect-time-wait : 2s # Exported message format, one of: proto, prototext, protojson, json, event format : event # string, one of `overwrite`, `if-not-present`, `` # This field allows populating/changing the value of Prefix.Target in the received message. # if set to ``, nothing changes # if set to `overwrite`, the target value is overwritten using the template configured under `target-template` # if set to `if-not-present`, the target value is populated only if it is empty, still using the `target-template` add-target : # string, a GoTemplate that allow for the customization of the target field in Prefix.Target. # it applies only if the previous field `add-target` is not empty. # if left empty, it defaults to: # {{- if index . \"subscription-target\" -}} # {{ index . \"subscription-target\" }} # {{- else -}} # {{ index . \"source\" | host }} # {{- end -}}` # which will set the target to the value configured under `subscription.$subscription-name.target` if any, # otherwise it will set it to the target name stripped of the port number (if present) target-template : # string, a GoTemplate that is executed using the received gNMI message as input. # the template execution is the last step before the data is written to the file. # First the received message is formatted according to the `format` field above, then the `event-processors` are applied if any # then finally the msg-template is executed. msg-template : # boolean, if true the message timestamp is changed to current time override-timestamps : false # integer, number of nats publishers to be created num-workers : 1 # duration after which a message waiting to be handled by a worker gets discarded write-timeout : 5s # boolean, enables extra logging for the nats output debug : false # boolean, enables the collection and export (via prometheus) of output specific metrics enable-metrics : false # list of processors to apply to the message before writing event-processors :","title":"configuration"},{"location":"user_guide/outputs/jetstream_output/#subject-format","text":"The subject-format field is used to control how the received gNMI notifications are written into the configured stream.","title":"subject-format"},{"location":"user_guide/outputs/jetstream_output/#static","text":"All notifications will be written to the subject name set under outputs.$output_name.subject","title":"static"},{"location":"user_guide/outputs/jetstream_output/#subscriptiontarget","text":"Notifications from each subscription and target pair will be written to subject $subscription_name.$target_name","title":"subscription.target"},{"location":"user_guide/outputs/jetstream_output/#subscriptiontargetpath","text":"Notifications from a subscription, target and path tuple will be written to subject subscription_name. subscription_name. target_name.$path. The path is built by joining the gNMI path pathElements with a period (.) . Notifications containing more than one update, will be expanded into multiple notifications with one update each. E.g: An update from target target1 and subscription sub1 containing path /interface[name=ethernet-1/1]/statistics/in-octets , will be written to subject: $stream_name.sub1.target1.interface.statistics.in-octets","title":"subscription.target.path"},{"location":"user_guide/outputs/jetstream_output/#subscriptiontargetpathkeys","text":"Updates from a certain subscription, a certain target and a certain path will be written to subject $subscription_name.$target_name.$path . The path is built by joining the gNMI path pathElements and Keys with a period (.) . Notifications containing more than one update, will be expanded into multiple notifications with one update each. E.g: An update from target target1 and subscription sub1 containing path /interface[name=ethernet-1/1]/statistics/in-octets , will be written to subject: $stream_name.sub1.target1.interface.{name=ethernet-1/1}.statistics.in-octets","title":"subscription.target.pathKeys"},{"location":"user_guide/outputs/kafka_output/","text":"gnmic supports exporting subscription updates to multiple Apache Kafka brokers/clusters simultaneously Configuration sample # A Kafka output can be defined using the below format in gnmic config file under outputs section: outputs : output1 : # required type : kafka # kafka client name. # if left empty, this field is populated with the output name used as output ID (output1 in this example). # the full name will be '$(name)-kafka-prod'. # If the flag --instance-name is not empty, the full name will be '$(instance-name)-$(name)-kafka-prod. # note that each kafka worker (producer) will get client name=$name-$index name : \"\" # Comma separated brokers addresses address : localhost:9092 # Kafka topic name topic : telemetry # Kafka SASL configuration sasl : # SASL user name user : # SASL password password : # SASL mechanism: PLAIN, SCRAM-SHA-256, SCRAM-SHA-512 and OAUTHBEARER are supported mechanism : # token url for OAUTHBEARER SASL mechanism token-url : # Kafka TLS config tls : # path to certificate authority file, this will be used to verify the kafka server certificate ca-file : # path to client certificate file. cert-file : # path to client key file. key-file : # boolean, controls whether a client verifies the server's certificate chain and host name # if set to true, the kafka client accepts any certificate presented by the server and any host name in that certificate skip-verify : # The total number of times to retry sending a message max-retry : 2 # Kafka connection timeout timeout : 5s # Wait time to reestablish the kafka producer connection after a failure recovery-wait-time : 10s # Exported msg format, json, protojson, prototext, proto, event format : event # string, one of `overwrite`, `if-not-present`, `` # This field allows populating/changing the value of Prefix.Target in the received message. # if set to ``, nothing changes # if set to `overwrite`, the target value is overwritten using the template configured under `target-template` # if set to `if-not-present`, the target value is populated only if it is empty, still using the `target-template` add-target : # string, a GoTemplate that allows for the customization of the target field in Prefix.Target. # it applies only if the previous field `add-target` is not empty. # if left empty, it defaults to: # {{- if index . \"subscription-target\" -}} # {{ index . \"subscription-target\" }} # {{- else -}} # {{ index . \"source\" | host }} # {{- end -}}` # which will set the target to the value configured under `subscription.$subscription-name.target` if any, # otherwise it will set it to the target name stripped of the port number (if present) target-template : # string, a GoTemplate that is executed using the received gNMI message as input. # the template execution is the last step before the data is written to the file, # First the received message is formatted according to the `format` field above, then the `event-processors` are applied if any # then finally the msg-template is executed. msg-template : # boolean, if true the message timestamp is changed to current time override-timestamps : false # Number of kafka producers to be created num-workers : 1 # (bool) enable debug debug : false # (int) number of messages to buffer before being picked up by the workers buffer-size : 0 # (bool) enables the collection and export (via prometheus) of output specific metrics enable-metrics : false # list of processors to apply on the message before writing event-processors : Currently all subscriptions updates (all targets and all subscriptions) are published to the defined topic name Kafka Security protocol # Kafka clients can operate with 4 security protocols , their configuration is controlled via both .tls and .sasl fields under the output config. Security Protocol Description Configuration PLAINTEXT Un-authenticated, non-encrypted channel .tls and .sasl are NOT present SASL_PLAINTEXT SASL authenticated, non-encrypted channel only .sasl is present SASL_SSL SASL authenticated, SSL channel both .tls and .sasl are present SSL SSL channel only .tls is present Security Configuration Examples # PLAINTEXT outputs : output1 : type : kafka topic : my_kafka_topic # other fields # no tls and no sasl fields SASL_PLAINTEXT outputs : output1 : type : kafka topic : my_kafka_topic sasl : user : admin password : secret # other fields # no tls field SASL_SSL Example1: Without server certificate verification outputs : output1 : type : kafka topic : my_kafka_topic sasl : user : admin password : secret tls : skip-verify : true # other fields # ... Example2: With server certificate verification outputs : output1 : type : kafka topic : my_kafka_topic sasl : user : admin password : secret tls : ca-file : /path/to/ca-file # other fields # ... Example3: With client certificates outputs : output1 : type : kafka topic : my_kafka_topic sasl : user : admin password : secret tls : cert-file : /path/to/cert-file key-file : /path/to/cert-file # other fields # ... Example4: With both server certificate verification and client certificates outputs : output1 : type : kafka topic : my_kafka_topic sasl : user : admin password : secret tls : cert-file : /path/to/cert-file key-file : /path/to/cert-file ca-file : /path/to/ca-file # other fields # ... SSL Example1: Without server certificate verification outputs : output1 : type : kafka topic : my_kafka_topic tls : skip-verify : true # other fields # no sasl field Example2: With server certificate verification outputs : output1 : type : kafka topic : my_kafka_topic tls : ca-file : /path/to/ca-file # other fields # no sasl field Example3: With client certificates outputs : output1 : type : kafka topic : my_kafka_topic tls : cert-file : /path/to/cert-file key-file : /path/to/cert-file # other fields # no sasl field Example4: With both server certificate verification and client certificates outputs : output1 : type : kafka topic : my_kafka_topic tls : cert-file : /path/to/cert-file key-file : /path/to/cert-file ca-file : /path/to/ca-file # other fields # no sasl field Kafka Output Metrics # When a Prometheus server is enabled, gnmic kafka output exposes 4 prometheus metrics, 3 Counters and 1 Gauge: number_of_kafka_msgs_sent_success_total : Number of msgs successfully sent by gnmic kafka output. This Counter is labeled with the kafka producerID number_of_written_kafka_bytes_total : Number of bytes written by gnmic kafka output. This Counter is labeled with the kafka producerID number_of_kafka_msgs_sent_fail_total : Number of failed msgs sent by gnmic kafka output. This Counter is labeled with the kafka producerID as well as the failure reason msg_send_duration_ns : gnmic kafka output send duration in nanoseconds. This Gauge is labeled with the kafka producerID","title":"Kafka"},{"location":"user_guide/outputs/kafka_output/#configuration-sample","text":"A Kafka output can be defined using the below format in gnmic config file under outputs section: outputs : output1 : # required type : kafka # kafka client name. # if left empty, this field is populated with the output name used as output ID (output1 in this example). # the full name will be '$(name)-kafka-prod'. # If the flag --instance-name is not empty, the full name will be '$(instance-name)-$(name)-kafka-prod. # note that each kafka worker (producer) will get client name=$name-$index name : \"\" # Comma separated brokers addresses address : localhost:9092 # Kafka topic name topic : telemetry # Kafka SASL configuration sasl : # SASL user name user : # SASL password password : # SASL mechanism: PLAIN, SCRAM-SHA-256, SCRAM-SHA-512 and OAUTHBEARER are supported mechanism : # token url for OAUTHBEARER SASL mechanism token-url : # Kafka TLS config tls : # path to certificate authority file, this will be used to verify the kafka server certificate ca-file : # path to client certificate file. cert-file : # path to client key file. key-file : # boolean, controls whether a client verifies the server's certificate chain and host name # if set to true, the kafka client accepts any certificate presented by the server and any host name in that certificate skip-verify : # The total number of times to retry sending a message max-retry : 2 # Kafka connection timeout timeout : 5s # Wait time to reestablish the kafka producer connection after a failure recovery-wait-time : 10s # Exported msg format, json, protojson, prototext, proto, event format : event # string, one of `overwrite`, `if-not-present`, `` # This field allows populating/changing the value of Prefix.Target in the received message. # if set to ``, nothing changes # if set to `overwrite`, the target value is overwritten using the template configured under `target-template` # if set to `if-not-present`, the target value is populated only if it is empty, still using the `target-template` add-target : # string, a GoTemplate that allows for the customization of the target field in Prefix.Target. # it applies only if the previous field `add-target` is not empty. # if left empty, it defaults to: # {{- if index . \"subscription-target\" -}} # {{ index . \"subscription-target\" }} # {{- else -}} # {{ index . \"source\" | host }} # {{- end -}}` # which will set the target to the value configured under `subscription.$subscription-name.target` if any, # otherwise it will set it to the target name stripped of the port number (if present) target-template : # string, a GoTemplate that is executed using the received gNMI message as input. # the template execution is the last step before the data is written to the file, # First the received message is formatted according to the `format` field above, then the `event-processors` are applied if any # then finally the msg-template is executed. msg-template : # boolean, if true the message timestamp is changed to current time override-timestamps : false # Number of kafka producers to be created num-workers : 1 # (bool) enable debug debug : false # (int) number of messages to buffer before being picked up by the workers buffer-size : 0 # (bool) enables the collection and export (via prometheus) of output specific metrics enable-metrics : false # list of processors to apply on the message before writing event-processors : Currently all subscriptions updates (all targets and all subscriptions) are published to the defined topic name","title":"Configuration sample"},{"location":"user_guide/outputs/kafka_output/#kafka-security-protocol","text":"Kafka clients can operate with 4 security protocols , their configuration is controlled via both .tls and .sasl fields under the output config. Security Protocol Description Configuration PLAINTEXT Un-authenticated, non-encrypted channel .tls and .sasl are NOT present SASL_PLAINTEXT SASL authenticated, non-encrypted channel only .sasl is present SASL_SSL SASL authenticated, SSL channel both .tls and .sasl are present SSL SSL channel only .tls is present","title":"Kafka Security protocol"},{"location":"user_guide/outputs/kafka_output/#security-configuration-examples","text":"PLAINTEXT outputs : output1 : type : kafka topic : my_kafka_topic # other fields # no tls and no sasl fields SASL_PLAINTEXT outputs : output1 : type : kafka topic : my_kafka_topic sasl : user : admin password : secret # other fields # no tls field SASL_SSL Example1: Without server certificate verification outputs : output1 : type : kafka topic : my_kafka_topic sasl : user : admin password : secret tls : skip-verify : true # other fields # ... Example2: With server certificate verification outputs : output1 : type : kafka topic : my_kafka_topic sasl : user : admin password : secret tls : ca-file : /path/to/ca-file # other fields # ... Example3: With client certificates outputs : output1 : type : kafka topic : my_kafka_topic sasl : user : admin password : secret tls : cert-file : /path/to/cert-file key-file : /path/to/cert-file # other fields # ... Example4: With both server certificate verification and client certificates outputs : output1 : type : kafka topic : my_kafka_topic sasl : user : admin password : secret tls : cert-file : /path/to/cert-file key-file : /path/to/cert-file ca-file : /path/to/ca-file # other fields # ... SSL Example1: Without server certificate verification outputs : output1 : type : kafka topic : my_kafka_topic tls : skip-verify : true # other fields # no sasl field Example2: With server certificate verification outputs : output1 : type : kafka topic : my_kafka_topic tls : ca-file : /path/to/ca-file # other fields # no sasl field Example3: With client certificates outputs : output1 : type : kafka topic : my_kafka_topic tls : cert-file : /path/to/cert-file key-file : /path/to/cert-file # other fields # no sasl field Example4: With both server certificate verification and client certificates outputs : output1 : type : kafka topic : my_kafka_topic tls : cert-file : /path/to/cert-file key-file : /path/to/cert-file ca-file : /path/to/ca-file # other fields # no sasl field","title":"Security Configuration Examples"},{"location":"user_guide/outputs/kafka_output/#kafka-output-metrics","text":"When a Prometheus server is enabled, gnmic kafka output exposes 4 prometheus metrics, 3 Counters and 1 Gauge: number_of_kafka_msgs_sent_success_total : Number of msgs successfully sent by gnmic kafka output. This Counter is labeled with the kafka producerID number_of_written_kafka_bytes_total : Number of bytes written by gnmic kafka output. This Counter is labeled with the kafka producerID number_of_kafka_msgs_sent_fail_total : Number of failed msgs sent by gnmic kafka output. This Counter is labeled with the kafka producerID as well as the failure reason msg_send_duration_ns : gnmic kafka output send duration in nanoseconds. This Gauge is labeled with the kafka producerID","title":"Kafka Output Metrics"},{"location":"user_guide/outputs/nats_output/","text":"gnmic supports exporting subscription updates to multiple NATS servers/clusters simultaneously A NATS output can be defined using the below format in gnmic config file under outputs section: outputs : output1 : # required type : nats # NATS publisher name # if left empty, this field is populated with the output name used as output ID (output1 in this example). # the full name will be '$(name)-nats-pub'. # If the flag --instance-name is not empty, the full name will be '$(instance-name)-$(name)-nats-pub. # note that each nats worker (publisher) will get client name=$name-$index name : \"\" # Comma separated NATS servers address : localhost:4222 # This prefix is used to to build the subject name for each target/subscription subject-prefix : telemetry # If a subject-prefix is not specified, gnmic will publish all subscriptions updates to a single subject configured under this field. Defaults to 'telemetry' subject : telemetry # NATS username username : # NATS password password : # wait time before reconnection attempts connect-time-wait : 2s # Exported message format, one of: proto, prototext, protojson, json, event format : json # string, one of `overwrite`, `if-not-present`, `` # This field allows populating/changing the value of Prefix.Target in the received message. # if set to ``, nothing changes # if set to `overwrite`, the target value is overwritten using the template configured under `target-template` # if set to `if-not-present`, the target value is populated only if it is empty, still using the `target-template` add-target : # string, a GoTemplate that allow for the customization of the target field in Prefix.Target. # it applies only if the previous field `add-target` is not empty. # if left empty, it defaults to: # {{- if index . \"subscription-target\" -}} # {{ index . \"subscription-target\" }} # {{- else -}} # {{ index . \"source\" | host }} # {{- end -}}` # which will set the target to the value configured under `subscription.$subscription-name.target` if any, # otherwise it will set it to the target name stripped of the port number (if present) target-template : # string, a GoTemplate that is executed using the received gNMI message as input. # the template execution is the last step before the data is written to the file, # First the received message is formatted according to the `format` field above, then the `event-processors` are applied if any # then finally the msg-template is executed. msg-template : # boolean, if true the message timestamp is changed to current time override-timestamps : false # integer, number of nats publishers to be created num-workers : 1 # duration after which a message waiting to be handled by a worker gets discarded write-timeout : 5s # boolean, enables extra logging for the nats output debug : false # boolean, enables the collection and export (via prometheus) of output specific metrics enable-metrics : false # list of processors to apply on the message before writing event-processors : Using subject config value, a user can specify the NATS subject to which to send all subscriptions updates for all targets If a user wants to separate updates by targets and by subscriptions, subject-prefix can be used. if subject-prefix is specified subject is ignored. gnmic takes advantage of NATS subject hierarchy by publishing gNMI subscription updates to a separate subject per target per subscription. The NATS subject name is built out of the subject-prefix , name under the target definition and subscription-name resulting in the following format: subject-prefix.name.subscription-name e.g: for a target router1 , a subscription name port-stats and subject-prefix telemetry the subject name will be telemetry.router1.port-stats If the target name is an IP address, or a hostname (meaning potentially contains . ), the . characters are replaced with a - e.g: for a target 172.17.0.100:57400 , the previous subject name becomes telemetry.172-17-0-100:57400.port-stats This way a user can subscribe to different subsets of updates by tweaking the subject name: \"telemetry.>\" gets all updates sent to NATS by all targets, all subscriptions \"telemetry.router1.>\" gets all NATS updates for target router1 \"telemetry.*.port-stats\" gets all updates from subscription port-stats, for all targets","title":"NATS"},{"location":"user_guide/outputs/output_intro/","text":"In the context of gnmi subscriptions (on top of terminal output) gnmic supports multiple output options: Local file NATS messaging system NATS Streaming messaging bus (STAN) Kafka messaging bus InfluxDB Time Series Database Prometheus Server UDP Server TCP Server These outputs can be mixed and matched at will with the different gnmi subscribe targets. With multiple outputs defined in the configuration file you can collect once and export the subscriptions updates to multiple locations formatted differently. Defining outputs # To define an output a user needs to create the outputs section in the configuration file: # part of ~/gnmic.yml config file outputs : output1 : type : file # output type file-type : stdout # or stderr format : json output2 : type : file filename : /path/to/localFile.log format : protojson output3 : type : nats # output type address : 127.0.0.1:4222 # comma separated nats servers addresses subject-prefix : telemetry # format : event output4 : type : file filename : /path/to/localFile.log format : json output5 : type : stan # output type address : 127.0.0.1:4223 # comma separated nats streaming servers addresses subject : telemetry # cluster-name : test-cluster # format : proto output6 : type : kafka # output type address : localhost:9092 # comma separated kafka brokers addresses topic : telemetry # kafka topic format : proto output7 : type : stan # output type address : 127.0.0.1:4223 # comma separated nats streaming servers addresses subject : telemetry cluster-name : test-cluster Note Outputs names are case insensitive Output formats # Different formats are supported for all outputs Format/output proto protojson prototext json event File NATS / STAN Kafka UDP / TCP InfluxDB NA NA NA NA NA Prometheus NA NA NA NA NA Formats examples # protojson { \"update\" : { \"timestamp\" : \"1595491618677407414\" , \"prefix\" : { \"elem\" : [ { \"name\" : \"configure\" }, { \"name\" : \"system\" } ] }, \"update\" : [ { \"path\" : { \"elem\" : [ { \"name\" : \"name\" } ] }, \"val\" : { \"stringVal\" : \"sr123\" } } ] } } prototext update : { timestamp : 1595491704850352047 prefix : { elem : { name : \"configure\" } elem : { name : \"system\" } } update : { path : { elem : { name : \"name\" } } val : { string_val : \"sr123\" } } } json { \"source\" : \"172.17.0.100:57400\" , \"subscription-name\" : \"sub1\" , \"timestamp\" : 1595491557144228652 , \"time\" : \"2020-07-23T16:05:57.144228652+08:00\" , \"prefix\" : \"configure/system\" , \"updates\" : [ { \"Path\" : \"name\" , \"values\" : { \"name\" : \"sr123\" } } ] } event [ { \"name\" : \"sub1\" , \"timestamp\" : 1595491586073072000 , \"tags\" : { \"source\" : \"172.17.0.100:57400\" , \"subscription-name\" : \"sub1\" }, \"values\" : { \"/configure/system/name\" : \"sr123\" } } ] Binding outputs # Once the outputs are defined, they can be flexibly associated with the targets. # part of ~/gnmic.yml config file targets : router1.lab.com : username : admin password : secret outputs : - output1 - output3 router2.lab.com : username : gnmi password : telemetry outputs : - output2 - output3 - output4","title":"Introduction"},{"location":"user_guide/outputs/output_intro/#defining-outputs","text":"To define an output a user needs to create the outputs section in the configuration file: # part of ~/gnmic.yml config file outputs : output1 : type : file # output type file-type : stdout # or stderr format : json output2 : type : file filename : /path/to/localFile.log format : protojson output3 : type : nats # output type address : 127.0.0.1:4222 # comma separated nats servers addresses subject-prefix : telemetry # format : event output4 : type : file filename : /path/to/localFile.log format : json output5 : type : stan # output type address : 127.0.0.1:4223 # comma separated nats streaming servers addresses subject : telemetry # cluster-name : test-cluster # format : proto output6 : type : kafka # output type address : localhost:9092 # comma separated kafka brokers addresses topic : telemetry # kafka topic format : proto output7 : type : stan # output type address : 127.0.0.1:4223 # comma separated nats streaming servers addresses subject : telemetry cluster-name : test-cluster Note Outputs names are case insensitive","title":"Defining outputs"},{"location":"user_guide/outputs/output_intro/#output-formats","text":"Different formats are supported for all outputs Format/output proto protojson prototext json event File NATS / STAN Kafka UDP / TCP InfluxDB NA NA NA NA NA Prometheus NA NA NA NA NA","title":"Output formats"},{"location":"user_guide/outputs/output_intro/#formats-examples","text":"protojson { \"update\" : { \"timestamp\" : \"1595491618677407414\" , \"prefix\" : { \"elem\" : [ { \"name\" : \"configure\" }, { \"name\" : \"system\" } ] }, \"update\" : [ { \"path\" : { \"elem\" : [ { \"name\" : \"name\" } ] }, \"val\" : { \"stringVal\" : \"sr123\" } } ] } } prototext update : { timestamp : 1595491704850352047 prefix : { elem : { name : \"configure\" } elem : { name : \"system\" } } update : { path : { elem : { name : \"name\" } } val : { string_val : \"sr123\" } } } json { \"source\" : \"172.17.0.100:57400\" , \"subscription-name\" : \"sub1\" , \"timestamp\" : 1595491557144228652 , \"time\" : \"2020-07-23T16:05:57.144228652+08:00\" , \"prefix\" : \"configure/system\" , \"updates\" : [ { \"Path\" : \"name\" , \"values\" : { \"name\" : \"sr123\" } } ] } event [ { \"name\" : \"sub1\" , \"timestamp\" : 1595491586073072000 , \"tags\" : { \"source\" : \"172.17.0.100:57400\" , \"subscription-name\" : \"sub1\" }, \"values\" : { \"/configure/system/name\" : \"sr123\" } } ]","title":"Formats examples"},{"location":"user_guide/outputs/output_intro/#binding-outputs","text":"Once the outputs are defined, they can be flexibly associated with the targets. # part of ~/gnmic.yml config file targets : router1.lab.com : username : admin password : secret outputs : - output1 - output3 router2.lab.com : username : gnmi password : telemetry outputs : - output2 - output3 - output4","title":"Binding outputs"},{"location":"user_guide/outputs/prometheus_output/","text":"gnmic supports exposing gnmi updates on a prometheus server, for a prometheus client to scrape. A Prometheus output can be defined using the below format in gnmic config file under outputs section: outputs : output1 : type : prometheus # require # address to listen on for incoming scrape requests listen : :9804 # path to query to get the metrics path : /metrics # maximum lifetime of metrics in the local cache, # # a zero value defaults to 60s, a negative duration (e.g: -1s) disables the expiration expiration : 60s # a string to be used as the metric namespace metric-prefix : \"\" # a boolean, if true the subscription name will be appended to the metric name after the prefix append-subscription-name : false # boolean, if true the message timestamp is changed to current time override-timestamps : false # a boolean, enables exporting timestamps received from the gNMI target as part of the metrics export-timestamps : false # a boolean, enables setting string type values as prometheus metric labels. strings-as-labels : false # a boolean, if set to true, the received gNMI notifications are stored in a cache. # the prometheus metrics are generated at the time a prometheus server sends scrape request. # this behavior allows the processors (if defined) to be run on all the generated events at once. # this mode uses more resource compared to the default one, but offers more flexibility when it comes # to manipulating the data to customize the returned metrics using event-processors. gnmi-cache : false # duration, scrape request timeout. # this timer is started when a scrape request is received, # if it is reached, the metrics generation/collection is stopped. timeout : 10s # enable debug for prometheus output debug : false # string, one of `overwrite`, `if-not-present`, `` # This field allows populating/changing the value of Prefix.Target in the received message. # if set to ``, nothing changes # if set to `overwrite`, the target value is overwritten using the template configured under `target-template` # if set to `if-not-present`, the target value is populated only if it is empty, still using the `target-template` add-target : # string, a GoTemplate that allow for the customization of the target field in Prefix.Target. # it applies only if the previous field `add-target` is not empty. # if left empty, it defaults to: # {{- if index . \"subscription-target\" -}} # {{ index . \"subscription-target\" }} # {{- else -}} # {{ index . \"source\" | host }} # {{- end -}}` # which will set the target to the value configured under `subscription.$subscription-name.target` if any, # otherwise it will set it to the target name stripped of the port number (if present) target-template : # list of processors to apply on the message before writing event-processors : # Enables Consul service registration service-registration : # Consul server address, default to localhost:8500 address : # Consul Data center, defaults to dc1 datacenter : # Consul username, to be used as part of HTTP basicAuth username : # Consul password, to be used as part of HTTP basicAuth password : # Consul Token, is used to provide a per-request ACL token which overrides the agent's default token token : # Prometheus service check interval, for both http and TTL Consul checks, # defaults to 5s check-interval : # Maximum number of failed checks before the service is deleted by Consul # defaults to 3 max-fail : # Consul service name name : # List of tags to be added to the service registration, # if available, the instance-name and cluster-name will be added as tags, # in the format: gnmic-instance=$instance-name and gnmic-cluster=$cluster-name tags : # bool, enables http service check on top of the TTL check enable-http-check : # string, if enable-http-check is true, this field can be used to specify the http endpoint to be used to the check # if provided, this filed with be prepended with 'http://' (if not already present), # and appended with the value in 'path' field. # if not specified, it will be derived from the fields 'listen' and 'path' http-check-address : # if set to true, the gnmic instance will try to ac quire a lock before registering the prometheus output in consul. # this allows to register a single instance of the cluster in consul. # if the instance which acquired the lock fails, one of the remaining ones will take over. use-lock : false gnmic creates the prometheus metric name and its labels from the subscription name, the gnmic path and the value name. Metric Generation # The below diagram shows an example of a prometheus metric generation from a gnmi update Metric Naming # The metric name starts with the string configured under metric-prefix . Then if append-subscription-name is true , the subscription-name as specified in gnmic configuration file is appended. The resulting string is followed by the gNMI path stripped of its keys if there are any. All non-alphanumeric characters are replaced with an underscore \" _ \" The 3 strings are then joined with an underscore \" _ \" If further customization of the metric name is required, the processors can be used to transform the metric name. For example, a gNMI update from subscription port-stats with path: /interfaces/interface [ name = 1 /1/1 ] /subinterfaces/subinterface [ index = 0 ] /state/counters/in-octets is exposed as a metric named: gnmic_port_stats_interfaces_interface_subinterfaces_subinterface_state_counters_in_octets Metric Labels # The metrics labels are generated from the subscription metadata (e.g: subscription-name and source ) and the keys present in the gNMI path elements. For the previous example the labels would be: { interface_name = \"1/1/1\" ,subinterface_index = 0 ,source = \" $routerIP :Port\" ,subscription_name = \"port-stats\" } Service Registration # gnmic supports prometheus_output service registration via Consul . It allows prometheus to dynamically discover new instances of gnmic exposing a prometheus server ready for scraping via its service discovery feature . If the configuration section service-registration is present under the output definition, gnmic will register the prometheus_output service in Consul . Configuration Example # The below configuration, registers a service name gnmic-prom-srv with IP=10.1.1.1 and port=9804 # gnmic.yaml outputs : output1 : type : prometheus listen : 10.1.1.1:9804 path : /metrics service-registration : address : consul-agent.local:8500 name : gnmic-prom-srv This allows running multiple instances of gnmic with minimal configuration changes by using prometheus service discovery feature . Simplified scrape configuration in the prometheus client: # prometheus.yaml scrape_configs : - job_name : 'gnmic' scrape_interval : 10s consul_sd_configs : - server : $CONSUL_ADDRESS services : - $service_name Service Name and ID # The $service_name to be discovered by prometheus is configured under outputs.$output_name.service-registration.name . If the service registration name field is not present, the name prometheus-${output_name} will be used. In both cases the service ID will be prometheus-${output_name}-${instance_name} . Service Checks # gnmic registers the service in Consul with a ttl check enabled by default: ttl : gnmic periodically updates the service definition in Consul . The goal is to allow Consul to detect a same instance restarting with a different service name. If service-registration.enable-http-check is true , an http check is added: http : Consul periodically scrapes the prometheus server endpoint to check its availability. # gnmic.yaml outputs : output1 : type : prometheus listen : 10.1.1.1:9804 path : /metrics service-registration : address : consul-agent.local:8500 name : gnmic-prom-srv enable-http-check : true Note that for the http check to work properly, a reachable address ( IP or name ) should be specified under listen . Otherwise, a reachable address should be added under service-registration.http-check-address .","title":"Scrape Based (Pull)"},{"location":"user_guide/outputs/prometheus_output/#metric-generation","text":"The below diagram shows an example of a prometheus metric generation from a gnmi update","title":"Metric Generation"},{"location":"user_guide/outputs/prometheus_output/#metric-naming","text":"The metric name starts with the string configured under metric-prefix . Then if append-subscription-name is true , the subscription-name as specified in gnmic configuration file is appended. The resulting string is followed by the gNMI path stripped of its keys if there are any. All non-alphanumeric characters are replaced with an underscore \" _ \" The 3 strings are then joined with an underscore \" _ \" If further customization of the metric name is required, the processors can be used to transform the metric name. For example, a gNMI update from subscription port-stats with path: /interfaces/interface [ name = 1 /1/1 ] /subinterfaces/subinterface [ index = 0 ] /state/counters/in-octets is exposed as a metric named: gnmic_port_stats_interfaces_interface_subinterfaces_subinterface_state_counters_in_octets","title":"Metric Naming"},{"location":"user_guide/outputs/prometheus_output/#metric-labels","text":"The metrics labels are generated from the subscription metadata (e.g: subscription-name and source ) and the keys present in the gNMI path elements. For the previous example the labels would be: { interface_name = \"1/1/1\" ,subinterface_index = 0 ,source = \" $routerIP :Port\" ,subscription_name = \"port-stats\" }","title":"Metric Labels"},{"location":"user_guide/outputs/prometheus_output/#service-registration","text":"gnmic supports prometheus_output service registration via Consul . It allows prometheus to dynamically discover new instances of gnmic exposing a prometheus server ready for scraping via its service discovery feature . If the configuration section service-registration is present under the output definition, gnmic will register the prometheus_output service in Consul .","title":"Service Registration"},{"location":"user_guide/outputs/prometheus_output/#configuration-example","text":"The below configuration, registers a service name gnmic-prom-srv with IP=10.1.1.1 and port=9804 # gnmic.yaml outputs : output1 : type : prometheus listen : 10.1.1.1:9804 path : /metrics service-registration : address : consul-agent.local:8500 name : gnmic-prom-srv This allows running multiple instances of gnmic with minimal configuration changes by using prometheus service discovery feature . Simplified scrape configuration in the prometheus client: # prometheus.yaml scrape_configs : - job_name : 'gnmic' scrape_interval : 10s consul_sd_configs : - server : $CONSUL_ADDRESS services : - $service_name","title":"Configuration Example"},{"location":"user_guide/outputs/prometheus_output/#service-name-and-id","text":"The $service_name to be discovered by prometheus is configured under outputs.$output_name.service-registration.name . If the service registration name field is not present, the name prometheus-${output_name} will be used. In both cases the service ID will be prometheus-${output_name}-${instance_name} .","title":"Service Name and ID"},{"location":"user_guide/outputs/prometheus_output/#service-checks","text":"gnmic registers the service in Consul with a ttl check enabled by default: ttl : gnmic periodically updates the service definition in Consul . The goal is to allow Consul to detect a same instance restarting with a different service name. If service-registration.enable-http-check is true , an http check is added: http : Consul periodically scrapes the prometheus server endpoint to check its availability. # gnmic.yaml outputs : output1 : type : prometheus listen : 10.1.1.1:9804 path : /metrics service-registration : address : consul-agent.local:8500 name : gnmic-prom-srv enable-http-check : true Note that for the http check to work properly, a reachable address ( IP or name ) should be specified under listen . Otherwise, a reachable address should be added under service-registration.http-check-address .","title":"Service Checks"},{"location":"user_guide/outputs/prometheus_write_output/","text":"gnmic supports writing metrics to Prometheus using its remote write API . gNMIc 's prometheus remote write can be used to push metrics to a variety of monitoring systems like Mimir , CortexMetrics , VictoriaMetrics , Thanos ... A Prometheus write output can be defined using the below format in gnmic config file under outputs section: outputs : output1 : # required type : prometheus_write # url to push metrics towards, scheme is required url : http://<grafana-mimir-addr>:9009/api/v1/push # a map of string:string, # custom HTTP headers to be sent along with each remote write request. headers : # sets the `Authorization` header on every remote write request with the # configured username and password. authentication : username : password : # sets the `Authorization` header with type `.authorization.type` and the token value. authorization : type : Bearer credentials : <token string> # TLS configuration tls : # string, path to CA certificates file ca-file : # string, path to client certificate file cert-file : # string, path to client key file key-file : # boolean, if true, the client does not verify the server certificates skip-verify : # duration, defaults to 10s, time interval between write requests interval : 10s # integer, defaults to 1000. # Buffer size for time series to be sent to the remote system. # metrics are sent to the remote system every `.interval` or when the buffer is full. Whichever one is reached first. buffer-size : 1000 # integer, defaults to 500, sets the maximum number of timeSeries per write request to remote. max-time-series-per-write : 500 # integer, defaults to 0 # number of retries per write, retries will have a back off of 100ms. max-retries : 0 # metadata configuration metadata : # boolean, # if true, metrics metadata is sent. include : false # duration, defaults to 60s. # Applies if `metadata.include` is set to true # Interval after which all metadata entries are sent to the remote write address interval : 60s # integer, defaults to 500 # applies if `metadata.include` is set to true # Max number of metadata entries per write request. max-entries-per-write : 500 # string, to be used as the metric namespace metric-prefix : \"\" # boolean, if true the subscription name will be appended to the metric name after the prefix append-subscription-name : false # boolean, enables setting string type values as prometheus metric labels. strings-as-labels : false # duration, defaults to 10s # Push request timeout. timeout : 10s # boolean, defaults to false # Enables debug for prometheus write output. debug : false # string, one of `overwrite`, `if-not-present`, `` # This field allows populating/changing the value of Prefix.Target in the received message. # if set to ``, nothing changes # if set to `overwrite`, the target value is overwritten using the template configured under `target-template` # if set to `if-not-present`, the target value is populated only if it is empty, still using the `target-template` add-target : # string, a GoTemplate that allow for the customization of the target field in Prefix.Target. # it applies only if the previous field `add-target` is not empty. # if left empty, it defaults to: # {{- if index . \"subscription-target\" -}} # {{ index . \"subscription-target\" }} # {{- else -}} # {{ index . \"source\" | host }} # {{- end -}}` # which will set the target to the value configured under `subscription.$subscription-name.target` if any, # otherwise it will set it to the target name stripped of the port number (if present) target-template : # list of processors to apply on the message before writing event-processors : gnmic creates the prometheus metric name and its labels from the subscription name, the gnmic path and the value name. Metric Generation # The below diagram shows an example of a prometheus metric generation from a gnmi update Metric Naming # The metric name starts with the string configured under metric-prefix . Then if append-subscription-name is true , the subscription-name as specified in gnmic configuration file is appended. The resulting string is followed by the gNMI path stripped of its keys if there are any. All non-alphanumeric characters are replaced with an underscore \" _ \" The 3 strings are then joined with an underscore \" _ \" If further customization of the metric name is required, the processors can be used to transform the metric name. For example, a gNMI update from subscription port-stats with path: /interfaces/interface [ name = 1 /1/1 ] /subinterfaces/subinterface [ index = 0 ] /state/counters/in-octets is exposed as a metric named: gnmic_port_stats_interfaces_interface_subinterfaces_subinterface_state_counters_in_octets Metric Labels # The metrics labels are generated from the subscription metadata (e.g: subscription-name and source ) and the keys present in the gNMI path elements. For the previous example the labels would be: { interface_name = \"1/1/1\" ,subinterface_index = 0 ,source = \" $routerIP :Port\" ,subscription_name = \"port-stats\" }","title":"Remote Write (Push)"},{"location":"user_guide/outputs/prometheus_write_output/#metric-generation","text":"The below diagram shows an example of a prometheus metric generation from a gnmi update","title":"Metric Generation"},{"location":"user_guide/outputs/prometheus_write_output/#metric-naming","text":"The metric name starts with the string configured under metric-prefix . Then if append-subscription-name is true , the subscription-name as specified in gnmic configuration file is appended. The resulting string is followed by the gNMI path stripped of its keys if there are any. All non-alphanumeric characters are replaced with an underscore \" _ \" The 3 strings are then joined with an underscore \" _ \" If further customization of the metric name is required, the processors can be used to transform the metric name. For example, a gNMI update from subscription port-stats with path: /interfaces/interface [ name = 1 /1/1 ] /subinterfaces/subinterface [ index = 0 ] /state/counters/in-octets is exposed as a metric named: gnmic_port_stats_interfaces_interface_subinterfaces_subinterface_state_counters_in_octets","title":"Metric Naming"},{"location":"user_guide/outputs/prometheus_write_output/#metric-labels","text":"The metrics labels are generated from the subscription metadata (e.g: subscription-name and source ) and the keys present in the gNMI path elements. For the previous example the labels would be: { interface_name = \"1/1/1\" ,subinterface_index = 0 ,source = \" $routerIP :Port\" ,subscription_name = \"port-stats\" }","title":"Metric Labels"},{"location":"user_guide/outputs/stan_output/","text":"gnmic supports exporting subscription updates to multiple NATS Streaming (STAN) servers/clusters simultaneously A STAN output can be defined using the below format in gnmic config file under outputs section: outputs : output1 : type : stan # required # comma separated STAN servers address : localhost:4222 # stan subject subject : telemetry # stan subject prefix, the subject prefix is built the same way as for NATS output subject-prefix : telemetry # STAN username username : # STAN password password : # STAN publisher name # if left empty, this field is populated with the output name used as output ID (output1 in this example). # the full name will be '$(name)-stan-pub'. # If the flag --instance-name is not empty, the full name will be '$(instance-name)-$(name)-stan-pub. # note that each stan worker (publisher) will get client name=$name-$index name : \"\" # cluster name, mandatory cluster-name : test-cluster # STAN ping interval ping-interval : 5 # STAN ping retry ping-retry : 2 # string, message marshaling format, one of: proto, prototext, protojson, json, event format : event # string, one of `overwrite`, `if-not-present`, `` # This field allows populating/changing the value of Prefix.Target in the received message. # if set to ``, nothing changes # if set to `overwrite`, the target value is overwritten using the template configured under `target-template` # if set to `if-not-present`, the target value is populated only if it is empty, still using the `target-template` add-target : # string, a GoTemplate that allow for the customization of the target field in Prefix.Target. # it applies only if the previous field `add-target` is not empty. # if left empty, it defaults to: # {{- if index . \"subscription-target\" -}} # {{ index . \"subscription-target\" }} # {{- else -}} # {{ index . \"source\" | host }} # {{- end -}}` # which will set the target to the value configured under `subscription.$subscription-name.target` if any, # otherwise it will set it to the target name stripped of the port number (if present) target-template : # boolean, if true the message timestamp is changed to current time override-timestamps : false # duration to wait before re establishing a lost connection to a stan server recovery-wait-time : 2s # integer, number of stan publishers to be created num-workers : 1 # boolean, enables extra logging for the STAN output debug : false # duration after which a message waiting to be handled by a worker gets discarded write-timeout : 10s # boolean, enables the collection and export (via prometheus) of output specific metrics enable-metrics : false # list of processors to apply on the message before writing event-processors : Using subject config value a user can specify the STAN subject to which to send all subscriptions updates for all targets If a user wants to separate updates by targets and by subscriptions, subject-prefix can be used. if subject-prefix is specified subject is ignored.","title":"STAN"},{"location":"user_guide/outputs/tcp_output/","text":"gnmic supports exporting subscription updates to a TCP server A TCP output can be defined using the below format in gnmic config file under outputs section: outputs : output1 : # required type : tcp # a UDP server address address : IPAddress:Port # maximum sending rate, e.g: 1ns, 10ms rate : 10ms # number of messages to buffer in case of sending failure buffer-size : # export format. json, protobuf, prototext, protojson, event format : json # string, one of `overwrite`, `if-not-present`, `` # This field allows populating/changing the value of Prefix.Target in the received message. # if set to ``, nothing changes # if set to `overwrite`, the target value is overwritten using the template configured under `target-template` # if set to `if-not-present`, the target value is populated only if it is empty, still using the `target-template` add-target : # string, a GoTemplate that allow for the customization of the target field in Prefix.Target. # it applies only if the previous field `add-target` is not empty. # if left empty, it defaults to: # {{- if index . \"subscription-target\" -}} # {{ index . \"subscription-target\" }} # {{- else -}} # {{ index . \"source\" | host }} # {{- end -}}` # which will set the target to the value configured under `subscription.$subscription-name.target` if any, # otherwise it will set it to the target name stripped of the port number (if present) target-template : # boolean, if true the message timestamp is changed to current time override-timestamps : false # enable TCP keepalive and specify the timer, e.g: 1s, 30s keep-alive : # time duration to wait before re-dial in case there is a failure retry-interval : # NOT IMPLEMENTED boolean, enables the collection and export (via prometheus) of output specific metricss enable-metrics : false # list of processors to apply on the message before writing event-processors : A TCP output can be used to export data to an ELK stack, using Logstash TCP input","title":"TCP"},{"location":"user_guide/outputs/udp_output/","text":"gnmic supports exporting subscription updates to a UDP server A UDP output can be defined using the below format in gnmic config file under outputs section: outputs : output1 : # required type : udp # a UDP server address address : IPAddress:Port # maximum sending rate, e.g: 1ns, 10ms rate : 10ms # number of messages to buffer in case of sending failure buffer-size : # export format. json, protobuf, prototext, protojson, event format : json # string, one of `overwrite`, `if-not-present`, `` # This field allows populating/changing the value of Prefix.Target in the received message. # if set to ``, nothing changes # if set to `overwrite`, the target value is overwritten using the template configured under `target-template` # if set to `if-not-present`, the target value is populated only if it is empty, still using the `target-template` add-target : # string, a GoTemplate that allow for the customization of the target field in Prefix.Target. # it applies only if the previous field `add-target` is not empty. # if left empty, it defaults to: # {{- if index . \"subscription-target\" -}} # {{ index . \"subscription-target\" }} # {{- else -}} # {{ index . \"source\" | host }} # {{- end -}}` # which will set the target to the value configured under `subscription.$subscription-name.target` if any, # otherwise it will set it to the target name stripped of the port number (if present) target-template : # boolean, if true the message timestamp is changed to current time override-timestamps : false # time duration to wait before re-dial in case there is a failure retry-interval : # NOT IMPLEMENTED boolean, enables the collection and export (via prometheus) of output specific metrics enable-metrics : false # list of processors to apply on the message before writing event-processors : A UDP output can be used to export data to an ELK stack, using Logstash UDP input","title":"UDP"},{"location":"user_guide/target_discovery/consul_discovery/","text":"The Consul target loader discovers gNMI targets registered as service instances in a Consul Server. The loader watches services registered in Consul defined by a service name and optionally a set of tags. Services watch # When at least one service name is set, gNMIc consul loader will watch the instances registered under that service name and build a target configuration using the service ID as the target name and the registered address and port as the target address. The remaining configuration can be set under the service name definition. loader : type : consul services : - name : cluster1-gnmi-server config : insecure : true username : admin password : admin Configuration # loader : type : consul # address of the loader server address : localhost:8500 # Consul Data center, defaults to dc1 datacenter : dc1 # Consul username, to be used as part of HTTP basicAuth username : # Consul password, to be used as part of HTTP basicAuth password : # Consul Token, is used to provide a per-request ACL token which overrides the agent's default token token : # the key prefix to watch for targets configuration, defaults to \"gnmic/config/targets\" key-prefix : gnmic/config/targets # if true, registers consulLoader prometheus metrics with the provided # prometheus registry enable-metrics : false # list of services to watch and derive target configurations from. services : # name of the Consul service - name : # a list of strings to further filter the service instances tags : # configuration map to apply to target discovered from this service config : # list of actions to run on target discovery on-add : # list of actions to run on target removal on-delete : # variable dict to pass to actions to be run vars : # path to variable file, the variables defined will be passed to the actions to be run # values in this file will be overwritten by the ones defined in `vars` vars-file :","title":"Consul Discovery"},{"location":"user_guide/target_discovery/consul_discovery/#services-watch","text":"When at least one service name is set, gNMIc consul loader will watch the instances registered under that service name and build a target configuration using the service ID as the target name and the registered address and port as the target address. The remaining configuration can be set under the service name definition. loader : type : consul services : - name : cluster1-gnmi-server config : insecure : true username : admin password : admin","title":"Services watch"},{"location":"user_guide/target_discovery/consul_discovery/#configuration","text":"loader : type : consul # address of the loader server address : localhost:8500 # Consul Data center, defaults to dc1 datacenter : dc1 # Consul username, to be used as part of HTTP basicAuth username : # Consul password, to be used as part of HTTP basicAuth password : # Consul Token, is used to provide a per-request ACL token which overrides the agent's default token token : # the key prefix to watch for targets configuration, defaults to \"gnmic/config/targets\" key-prefix : gnmic/config/targets # if true, registers consulLoader prometheus metrics with the provided # prometheus registry enable-metrics : false # list of services to watch and derive target configurations from. services : # name of the Consul service - name : # a list of strings to further filter the service instances tags : # configuration map to apply to target discovered from this service config : # list of actions to run on target discovery on-add : # list of actions to run on target removal on-delete : # variable dict to pass to actions to be run vars : # path to variable file, the variables defined will be passed to the actions to be run # values in this file will be overwritten by the ones defined in `vars` vars-file :","title":"Configuration"},{"location":"user_guide/target_discovery/discovery_intro/","text":"Introduction # gnmic supports dynamic loading of gNMI targets from external systems. This feature allows adding and deleting gNMI targets without the need to restart gnmic . Depending on the discovery method, gnmic will either: Subscribe to changes on the remote system, Or poll the defined targets from the remote systems. When a change is detected, the new targets are added and the corresponding subscriptions are immediately established. The removed targets are deleted together with their subscriptions. Actions can be run on target discovery (on-add or on-delete), this can be useful to add initial configurations to target ahead of gNMI subscriptions or run checks before subscribing. In the case of on-add actions, Notes Only one discovery type is supported at a time. Target updates are not supported, delete and re-add is the way to update a target configuration. Discovery types # Four types of target discovery methods are supported: File Loader # Watches changes to a local file containing gNMI targets definitions. Consul Server Loader # Subscribes to Consul KV key prefix changes, the keys and their value represent a target configuration fields. Docker Engine Loader # Polls containers from a Docker Engine host matching some predefined criteria (docker filters). HTTP Loader # Queries an HTTP endpoint periodically, expected a well formatted JSON dict of targets configurations. Running actions on discovery # All actions support fields on-add and on-delete which take a list of predefined action names that will be run sequentially on target discovery or deletion. The below configuration example defines 3 actions configure_interfaces , configure_subinterfaces and configure_network_instance which will run when the docker loader discovers a target with label clab-node-kind=srl loader : type : docker filters : - containers : - label : clab-node-kind=srl config : skip-verify : true username : admin password : admin on-add : - configure_interfaces - configure_subinterfaces - configure_network_instances actions : configure_interfaces : name : configure_interfaces type : gnmi target : '{{ .Input }}' rpc : set encoding : json_ietf debug : true paths : - /interface[name=ethernet-1/1]/admin-state - /interface[name=ethernet-1/2]/admin-state values : - enable - enable configure_subinterfaces : name : configure_subinterfaces type : gnmi target : '{{ .Input }}' rpc : set encoding : json_ietf debug : true paths : - /interface[name=ethernet-1/1]/subinterface[index=0]/admin-state - /interface[name=ethernet-1/2]/subinterface[index=0]/admin-state values : - enable - enable configure_network_instances : name : configure_network_instances type : gnmi target : '{{ .Input }}' rpc : set encoding : json_ietf debug : true paths : - /network-instance[name=default]/admin-state - /network-instance[name=default]/interface - /network-instance[name=default]/interface values : - enable - '{\"name\": \"ethernet-1/1.0\"}' - '{\"name\": \"ethernet-1/2.0\"}'","title":"Introduction"},{"location":"user_guide/target_discovery/discovery_intro/#introduction","text":"gnmic supports dynamic loading of gNMI targets from external systems. This feature allows adding and deleting gNMI targets without the need to restart gnmic . Depending on the discovery method, gnmic will either: Subscribe to changes on the remote system, Or poll the defined targets from the remote systems. When a change is detected, the new targets are added and the corresponding subscriptions are immediately established. The removed targets are deleted together with their subscriptions. Actions can be run on target discovery (on-add or on-delete), this can be useful to add initial configurations to target ahead of gNMI subscriptions or run checks before subscribing. In the case of on-add actions, Notes Only one discovery type is supported at a time. Target updates are not supported, delete and re-add is the way to update a target configuration.","title":"Introduction"},{"location":"user_guide/target_discovery/discovery_intro/#discovery-types","text":"Four types of target discovery methods are supported:","title":"Discovery types"},{"location":"user_guide/target_discovery/discovery_intro/#file-loader","text":"Watches changes to a local file containing gNMI targets definitions.","title":"File Loader"},{"location":"user_guide/target_discovery/discovery_intro/#consul-server-loader","text":"Subscribes to Consul KV key prefix changes, the keys and their value represent a target configuration fields.","title":"Consul Server Loader"},{"location":"user_guide/target_discovery/discovery_intro/#docker-engine-loader","text":"Polls containers from a Docker Engine host matching some predefined criteria (docker filters).","title":"Docker Engine Loader"},{"location":"user_guide/target_discovery/discovery_intro/#http-loader","text":"Queries an HTTP endpoint periodically, expected a well formatted JSON dict of targets configurations.","title":"HTTP Loader"},{"location":"user_guide/target_discovery/discovery_intro/#running-actions-on-discovery","text":"All actions support fields on-add and on-delete which take a list of predefined action names that will be run sequentially on target discovery or deletion. The below configuration example defines 3 actions configure_interfaces , configure_subinterfaces and configure_network_instance which will run when the docker loader discovers a target with label clab-node-kind=srl loader : type : docker filters : - containers : - label : clab-node-kind=srl config : skip-verify : true username : admin password : admin on-add : - configure_interfaces - configure_subinterfaces - configure_network_instances actions : configure_interfaces : name : configure_interfaces type : gnmi target : '{{ .Input }}' rpc : set encoding : json_ietf debug : true paths : - /interface[name=ethernet-1/1]/admin-state - /interface[name=ethernet-1/2]/admin-state values : - enable - enable configure_subinterfaces : name : configure_subinterfaces type : gnmi target : '{{ .Input }}' rpc : set encoding : json_ietf debug : true paths : - /interface[name=ethernet-1/1]/subinterface[index=0]/admin-state - /interface[name=ethernet-1/2]/subinterface[index=0]/admin-state values : - enable - enable configure_network_instances : name : configure_network_instances type : gnmi target : '{{ .Input }}' rpc : set encoding : json_ietf debug : true paths : - /network-instance[name=default]/admin-state - /network-instance[name=default]/interface - /network-instance[name=default]/interface values : - enable - '{\"name\": \"ethernet-1/1.0\"}' - '{\"name\": \"ethernet-1/2.0\"}'","title":"Running actions on discovery"},{"location":"user_guide/target_discovery/docker_discovery/","text":"The Docker target loader allows discovering gNMI targets from Docker Engine hosts. It discovers containers as well as their gNMI address, based on a list of Docker filters One gNMI target is added per discovered container. Individual Target configurations are derived from the container exposed ports and labels, as well as the global configuration. Configuration # loader : # the loader type: docker type : docker # string, the docker daemon address, # leave empty to use the local docker daemon # possible values: # - unix:///var/run/docker.sock # - tcp://<docker_host>:port # - http://<docker_host>:port address : \"\" # duration, check interval for discovering # new docker containers, default: 30s interval : 30s # duration, the docker queries timeout, # defaults to half of `interval` if left unset or is invalid. timeout : 15s # time to wait before the fist docker query start-delay : 0s # bool, print loader debug statements. debug : false # if true, registers dockerLoader prometheus metrics with the provided # prometheus registry enable-metrics : false # containers, network filters: # see https://docs.docker.com/engine/reference/commandline/ps/#filtering # for the possible values. filters : # containers filters - containers : # containers returned by `docker ps -f \"label=clab-node-kind=srl\"` - label : clab-node-kind=srl # network filters network : # networks returned by `docker network ls -f \"label=containerlab\"` label : containerlab # gNMI port value for the containers discovered by this filter. # It can be a port value or a label name set on the container. # valid values: # `port: \"57400\"` # `port: \"label=gnmi-port\"` port : # target config for containers discovered by this filter. # These fields will override the matching global config fields. config : username : admin password : secret1 skip-verify : true # list of actions to run on target discovery on-add : # list of actions to run on target removal on-delete : # variable dict to pass to actions to be run vars : # path to variable file, the variables defined will be passed to the actions to be run # values in this file will be overwritten by the ones defined in `vars` vars-file : Filter fields explanation # containers : (Optional) A list of lists of docker filters used to select containers from the Docker Engine host. The docker filter status=running is implicitly added. If not set, all containers with status=running are selected. network : (Optional) A set of docker filters used to select the network to connect to the container. If not filter is set, all docker networks are considered. port : (Optional) This field is used to specify the gNMI port for the discovered containers. An integer can be specified in which case it will be used as the gNMI port for all discovered containers. Alternatively, a string in the format label=<label_name> can be set, where <label_name> is a docker label containing the gNMI port value. If no value is set, the global flag/value port is used. config : (Optional) A set of configuration parameters to be applied to all discovered targets by the container filter. The target config fields as defined here can be set, except name and address which are discovered by the loader. Examples # Simple1 # A simple docker loader with a single docker container filter. It loads all containers deployed with containerlab , in lab called lab1 . loader : type : docker filters : - containers : - label : containerlab=lab1 In the above example, gnmic docker loader connects to the local Docker Daemon. It will discover containers having label containerlab=lab1 and add them as gNMI targets. Default configuration applies to those added targets Simple2 # A simple docker loader with a single docker container filter. It loads all containers deployed with containerlab , having kind srl . loader : type : docker filters : - containers : - label : clab-node-kind=srl In the above example, gnmic docker loader connects to the local Docker Daemon. It will discover containers having label clab-node-kind=srl and add them as gNMI targets. Default configuration applies to those added targets Advanced Example # A more advanced docker loader, with 2 filers, custom networks, ports and target configuration. loader : type : docker address : unix:///var/run/docker.sock filters : # filter 1 - containers : # containers returned by `docker ps -f \"label=clab-node-kind=srl\"` - label : clab-node-kind=srl network : # networks returned by `docker network ls -f \"label=containerlab\"` label : containerlab port : \"57400\" config : username : admin password : secret1 skip-verify : true # filter 2 - containers : # containers returned by `docker ps -f \"label=clab-node-kind=ceos\"` - label : clab-node-kind=ceos # containers returned by `docker ps -f \"label=clab-node-kind=vr-sros\"` - label : clab-node-kind=vr-sros network : # networks returned by `docker network ls -f \"name=mgmt\"` name : mgmt # the value of label=gnmi-port exported by each container` port : \"label=gnmi-port\" config : username : admin password : secret2 insecure : true In the above example, gnmic docker loader connects to the docker daemon using the local unix socket address. It will discover 2 sets of containers matching 2 filters: Filter1: Containers with label clab-node-kind=srl . Use network with label containerlab to connect to them. The port number is the same for all containers and is set to 57400 . The config fields username: admin , password: secret1 and skip-verify: true will be applied to all the containers discovered by this filter. Filter2: Containers with labels clab-node-kind-ceos or clab-node-vr-sros Use network with name=mgmt to connect to them. Note that Docker returns all networks with names containing mgmt The port number is discovered from the label gnmi-port set on each container. The config fields username: admin , password: secret2 and insecure: true will be applied to all the containers discovered by this filter.","title":"Docker Discovery"},{"location":"user_guide/target_discovery/docker_discovery/#configuration","text":"loader : # the loader type: docker type : docker # string, the docker daemon address, # leave empty to use the local docker daemon # possible values: # - unix:///var/run/docker.sock # - tcp://<docker_host>:port # - http://<docker_host>:port address : \"\" # duration, check interval for discovering # new docker containers, default: 30s interval : 30s # duration, the docker queries timeout, # defaults to half of `interval` if left unset or is invalid. timeout : 15s # time to wait before the fist docker query start-delay : 0s # bool, print loader debug statements. debug : false # if true, registers dockerLoader prometheus metrics with the provided # prometheus registry enable-metrics : false # containers, network filters: # see https://docs.docker.com/engine/reference/commandline/ps/#filtering # for the possible values. filters : # containers filters - containers : # containers returned by `docker ps -f \"label=clab-node-kind=srl\"` - label : clab-node-kind=srl # network filters network : # networks returned by `docker network ls -f \"label=containerlab\"` label : containerlab # gNMI port value for the containers discovered by this filter. # It can be a port value or a label name set on the container. # valid values: # `port: \"57400\"` # `port: \"label=gnmi-port\"` port : # target config for containers discovered by this filter. # These fields will override the matching global config fields. config : username : admin password : secret1 skip-verify : true # list of actions to run on target discovery on-add : # list of actions to run on target removal on-delete : # variable dict to pass to actions to be run vars : # path to variable file, the variables defined will be passed to the actions to be run # values in this file will be overwritten by the ones defined in `vars` vars-file :","title":"Configuration"},{"location":"user_guide/target_discovery/docker_discovery/#filter-fields-explanation","text":"containers : (Optional) A list of lists of docker filters used to select containers from the Docker Engine host. The docker filter status=running is implicitly added. If not set, all containers with status=running are selected. network : (Optional) A set of docker filters used to select the network to connect to the container. If not filter is set, all docker networks are considered. port : (Optional) This field is used to specify the gNMI port for the discovered containers. An integer can be specified in which case it will be used as the gNMI port for all discovered containers. Alternatively, a string in the format label=<label_name> can be set, where <label_name> is a docker label containing the gNMI port value. If no value is set, the global flag/value port is used. config : (Optional) A set of configuration parameters to be applied to all discovered targets by the container filter. The target config fields as defined here can be set, except name and address which are discovered by the loader.","title":"Filter fields explanation"},{"location":"user_guide/target_discovery/docker_discovery/#examples","text":"","title":"Examples"},{"location":"user_guide/target_discovery/docker_discovery/#simple1","text":"A simple docker loader with a single docker container filter. It loads all containers deployed with containerlab , in lab called lab1 . loader : type : docker filters : - containers : - label : containerlab=lab1 In the above example, gnmic docker loader connects to the local Docker Daemon. It will discover containers having label containerlab=lab1 and add them as gNMI targets. Default configuration applies to those added targets","title":"Simple1"},{"location":"user_guide/target_discovery/docker_discovery/#simple2","text":"A simple docker loader with a single docker container filter. It loads all containers deployed with containerlab , having kind srl . loader : type : docker filters : - containers : - label : clab-node-kind=srl In the above example, gnmic docker loader connects to the local Docker Daemon. It will discover containers having label clab-node-kind=srl and add them as gNMI targets. Default configuration applies to those added targets","title":"Simple2"},{"location":"user_guide/target_discovery/docker_discovery/#advanced-example","text":"A more advanced docker loader, with 2 filers, custom networks, ports and target configuration. loader : type : docker address : unix:///var/run/docker.sock filters : # filter 1 - containers : # containers returned by `docker ps -f \"label=clab-node-kind=srl\"` - label : clab-node-kind=srl network : # networks returned by `docker network ls -f \"label=containerlab\"` label : containerlab port : \"57400\" config : username : admin password : secret1 skip-verify : true # filter 2 - containers : # containers returned by `docker ps -f \"label=clab-node-kind=ceos\"` - label : clab-node-kind=ceos # containers returned by `docker ps -f \"label=clab-node-kind=vr-sros\"` - label : clab-node-kind=vr-sros network : # networks returned by `docker network ls -f \"name=mgmt\"` name : mgmt # the value of label=gnmi-port exported by each container` port : \"label=gnmi-port\" config : username : admin password : secret2 insecure : true In the above example, gnmic docker loader connects to the docker daemon using the local unix socket address. It will discover 2 sets of containers matching 2 filters: Filter1: Containers with label clab-node-kind=srl . Use network with label containerlab to connect to them. The port number is the same for all containers and is set to 57400 . The config fields username: admin , password: secret1 and skip-verify: true will be applied to all the containers discovered by this filter. Filter2: Containers with labels clab-node-kind-ceos or clab-node-vr-sros Use network with name=mgmt to connect to them. Note that Docker returns all networks with names containing mgmt The port number is discovered from the label gnmi-port set on each container. The config fields username: admin , password: secret2 and insecure: true will be applied to all the containers discovered by this filter.","title":"Advanced Example"},{"location":"user_guide/target_discovery/file_discovery/","text":"gnmic is able to watch changes happening to a file that contains the gNMI targets configuration. The file can be located in the local file system or a remote one. In case of remote file, ftp , sftp , http(s) protocols are supported. The read timeout of remote files is set to half of the read interval Newly added targets are discovered and subscribed to. Deleted targets are moved from gNMIc's list and their subscriptions are terminated. Configuration # A file target loader can be configured in a couple of ways: using the --targets-file flag: gnmic --targets-file ./targets-config.yaml subscribe gnmic --targets-file sftp://user:pass@server.com/path/to/targets-file.yaml subscribe using the main configuration file: loader : type : file # path to the file path : ./targets-config.yaml # watch interval at which the file # is read again to determine if a target was added or deleted. interval : 30s # time to wait before the fist file read start-delay : 0s # if true, registers fileLoader prometheus metrics with the provided # prometheus registry enable-metrics : false # list of actions to run on target discovery on-add : # list of actions to run on target removal on-delete : # variable dict to pass to actions to be run vars : # path to variable file, the variables defined will be passed to the actions to be run # values in this file will be overwritten by the ones defined in `vars` vars-file : The --targets-file flag takes precedence over the loader configuration section. The targets file can be either a YAML or a JSON file (identified by its extension json, yaml or yml), and follows the same format as the main configuration file targets section. See here Examples # Local File # loader : type : file # path to the file path : ./targets-config.yaml # watch interval at which the file # is read again to determine if a target was added or deleted. interval : 30s # if true, registers fileLoader prometheus metrics with the provided # prometheus registry enable-metrics : false Remote File # SFTP remote file loader : type : file # path to the file path : sftp://user:pass@server.com/path/to/targets-file.yaml # watch interval at which the file # is read again to determine if a target was added or deleted. interval : 30s # if true, registers fileLoader prometheus metrics with the provided # prometheus registry enable-metrics : false FTP remote file loader : type : file # path to the file path : ftp://user:pass@server.com/path/to/targets-file.yaml # watch interval at which the file # is read again to determine if a target was added or deleted. interval : 30s # if true, registers fileLoader prometheus metrics with the provided # prometheus registry enable-metrics : false HTTP remote file loader : type : file # path to the file path : http://user:pass@server.com/path/to/targets-file.yaml # watch interval at which the file # is read again to determine if a target was added or deleted. interval : 30s # if true, registers fileLoader prometheus metrics with the provided # prometheus registry enable-metrics : false Targets file format # YAML 10.10.10.10 : username : admin insecure : true 10.10.10.11 : username : admin 10.10.10.12 : 10.10.10.13 : 10.10.10.14 : JSON { \"10.10.10.10\" : { \"username\" : \"admin\" , \"insecure\" : true }, \"10.10.10.11\" : { \"username\" : \"admin\" , }, \"10.10.10.12\" : {}, \"10.10.10.13\" : {}, \"10.10.10.14\" : {} } Just like the targets in the main configuration file, the missing configuration fields get filled with the global flags, the ENV variables first, the config file main section next and then the default values.","title":"File Discovery"},{"location":"user_guide/target_discovery/file_discovery/#configuration","text":"A file target loader can be configured in a couple of ways: using the --targets-file flag: gnmic --targets-file ./targets-config.yaml subscribe gnmic --targets-file sftp://user:pass@server.com/path/to/targets-file.yaml subscribe using the main configuration file: loader : type : file # path to the file path : ./targets-config.yaml # watch interval at which the file # is read again to determine if a target was added or deleted. interval : 30s # time to wait before the fist file read start-delay : 0s # if true, registers fileLoader prometheus metrics with the provided # prometheus registry enable-metrics : false # list of actions to run on target discovery on-add : # list of actions to run on target removal on-delete : # variable dict to pass to actions to be run vars : # path to variable file, the variables defined will be passed to the actions to be run # values in this file will be overwritten by the ones defined in `vars` vars-file : The --targets-file flag takes precedence over the loader configuration section. The targets file can be either a YAML or a JSON file (identified by its extension json, yaml or yml), and follows the same format as the main configuration file targets section. See here","title":"Configuration"},{"location":"user_guide/target_discovery/file_discovery/#examples","text":"","title":"Examples"},{"location":"user_guide/target_discovery/file_discovery/#local-file","text":"loader : type : file # path to the file path : ./targets-config.yaml # watch interval at which the file # is read again to determine if a target was added or deleted. interval : 30s # if true, registers fileLoader prometheus metrics with the provided # prometheus registry enable-metrics : false","title":"Local File"},{"location":"user_guide/target_discovery/file_discovery/#remote-file","text":"SFTP remote file loader : type : file # path to the file path : sftp://user:pass@server.com/path/to/targets-file.yaml # watch interval at which the file # is read again to determine if a target was added or deleted. interval : 30s # if true, registers fileLoader prometheus metrics with the provided # prometheus registry enable-metrics : false FTP remote file loader : type : file # path to the file path : ftp://user:pass@server.com/path/to/targets-file.yaml # watch interval at which the file # is read again to determine if a target was added or deleted. interval : 30s # if true, registers fileLoader prometheus metrics with the provided # prometheus registry enable-metrics : false HTTP remote file loader : type : file # path to the file path : http://user:pass@server.com/path/to/targets-file.yaml # watch interval at which the file # is read again to determine if a target was added or deleted. interval : 30s # if true, registers fileLoader prometheus metrics with the provided # prometheus registry enable-metrics : false","title":"Remote File"},{"location":"user_guide/target_discovery/file_discovery/#targets-file-format","text":"YAML 10.10.10.10 : username : admin insecure : true 10.10.10.11 : username : admin 10.10.10.12 : 10.10.10.13 : 10.10.10.14 : JSON { \"10.10.10.10\" : { \"username\" : \"admin\" , \"insecure\" : true }, \"10.10.10.11\" : { \"username\" : \"admin\" , }, \"10.10.10.12\" : {}, \"10.10.10.13\" : {}, \"10.10.10.14\" : {} } Just like the targets in the main configuration file, the missing configuration fields get filled with the global flags, the ENV variables first, the config file main section next and then the default values.","title":"Targets file format"},{"location":"user_guide/target_discovery/http_discovery/","text":"The HTTP target loader can be used to query targets configurations from a remote HTTP server. It expects a well formatted application/json body and a code 200 response. It supports secure connections, basic authentication using a username and password and/or Oauth2 token based authentication. Configuration # loader : type : http # resource URL, must include the http(s) schema url : # watch interval at which the HTTP endpoint is queried again # to determine if a target was added or deleted. interval : 60s # HTTP request timeout timeout : 50s # time to wait before the fist HTTP query start-delay : 0s # boolean, if true the client does not verify the server certificates skip-verify : false # path to a certificate authority that will be used to verify the # server certificates. Irrelevant if `skip-verify: true` ca-file : # path to client certificate file cert-file : # path to client key file key-file : # username to be used with basic authentication username : # password to be used with basic authentication password : # token to be used with Oauth2 token based authentication token : # if true, registers httpLoader prometheus metrics with the provided # prometheus registry enable-metrics : false # list of actions to run on target discovery on-add : # list of actions to run on target removal on-delete : # variable dict to pass to actions to be run vars : # path to variable file, the variables defined will be passed to the actions to be run # values in this file will be overwritten by the ones defined in `vars` vars-file :","title":"HTTP Discovery"},{"location":"user_guide/target_discovery/http_discovery/#configuration","text":"loader : type : http # resource URL, must include the http(s) schema url : # watch interval at which the HTTP endpoint is queried again # to determine if a target was added or deleted. interval : 60s # HTTP request timeout timeout : 50s # time to wait before the fist HTTP query start-delay : 0s # boolean, if true the client does not verify the server certificates skip-verify : false # path to a certificate authority that will be used to verify the # server certificates. Irrelevant if `skip-verify: true` ca-file : # path to client certificate file cert-file : # path to client key file key-file : # username to be used with basic authentication username : # password to be used with basic authentication password : # token to be used with Oauth2 token based authentication token : # if true, registers httpLoader prometheus metrics with the provided # prometheus registry enable-metrics : false # list of actions to run on target discovery on-add : # list of actions to run on target removal on-delete : # variable dict to pass to actions to be run vars : # path to variable file, the variables defined will be passed to the actions to be run # values in this file will be overwritten by the ones defined in `vars` vars-file :","title":"Configuration"}]}